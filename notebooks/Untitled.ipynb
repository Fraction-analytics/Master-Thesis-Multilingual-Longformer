{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94bec73ac7d49cd9535b9dc6c04e31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=694.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71e4ad4654649e0921c4b75df1a5f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d607c92072947baa05dd5a0d6f5b13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a071ba677904c42b504b005d7c3d38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def read_squad_files(path: str):\n",
    "    \"\"\"\n",
    "    Takes the path for a SQuAD formated json file\n",
    "    Returns a Huggingface datasets object similar to the one called form:\n",
    "    \n",
    "    ```\n",
    "    from dataset import load_dataset\n",
    "    load_dataset(\"squad\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "            \n",
    "    df = pd.DataFrame({\n",
    "        \"context\": contexts,\n",
    "        \"question\": questions,\n",
    "        \"answers\": answers,\n",
    "    })\n",
    "    return Dataset.from_pandas(df)\n",
    "    \n",
    "\n",
    "    \n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', do_lowercase=True, use_fast=True)\n",
    "\n",
    "\n",
    "train_dataset = read_squad_files('/workspace/data/trivia_squad/squad-wikipedia-train-4096.json')\n",
    "valid_dataset = read_squad_files('/workspace/data/trivia_squad/squad-wikipedia-dev-4096.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_alignement(context: str, answer):\n",
    "    \"\"\" Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here. \"\"\"\n",
    "    gold_text = answer[\"text\"][0]\n",
    "    start_idx = answer[\"answer_start\"][0]\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "        return start_idx, end_idx  # When the gold label position is good\n",
    "    elif context[start_idx - 1 : end_idx - 1] == gold_text:\n",
    "        return start_idx - 1, end_idx - 1  # When the gold label is off by one character\n",
    "    elif context[start_idx - 2 : end_idx - 2] == gold_text:\n",
    "        return start_idx - 2, end_idx - 2  # When the gold label is off by two character\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "\n",
    "def add_triviaqa_end_idx(context, answer):\n",
    "    #for answer, context in zip(answers, contexts):\n",
    "    gold_text = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "\n",
    "    # sometimes squad answers are off by a character or two – fix this\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "        end_idx = end_idx\n",
    "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "        start_idx = start_idx - 1\n",
    "        end_idx = end_idx - 1     # When the gold label is off by one character\n",
    "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "        start_idx = start_idx - 2\n",
    "        end_idx = end_idx - 2     # When the gold label is off by two characters\n",
    "    return start_idx, end_idx\n",
    "\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        padding=True,\n",
    "        #pad_to_max_length=True,   # TODO\n",
    "        #max_length=512,\n",
    "        truncation=True,\n",
    "    )\n",
    "    context_encodings = tokenizer.encode_plus(example[\"context\"])\n",
    "\n",
    "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methodes.\n",
    "    # this will give us the position of answer span in the context text\n",
    "    start_idx, end_idx = add_triviaqa_end_idx(example[\"context\"], example[\"answers\"])\n",
    "    start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "    end_positions_context = context_encodings.char_to_token(end_idx - 1)\n",
    "    \n",
    "    # FIXME: UGLY HACK because of XLM-R tokenization, works fine with monolingual\n",
    "    # 2 training examples returns incorrect positions\n",
    "    try:\n",
    "        # here we will compute the start and end position of the answer in the whole example\n",
    "        # as the example is encoded like this <s> question</s></s> context</s>\n",
    "        # and we know the postion of the answer in the context\n",
    "        # we can just find out the index of the sep token and then add that to position + 1 (+1 because there are two sep tokens)\n",
    "        # this will give us the position of the answer span in whole example\n",
    "        sep_idx = encodings[\"input_ids\"].index(tokenizer.sep_token_id)\n",
    "        start_positions = start_positions_context + sep_idx + 1\n",
    "        end_positions = end_positions_context + sep_idx + 1\n",
    "\n",
    "        if end_positions > 512:\n",
    "            start_positions, end_positions = 0, 0\n",
    "    \n",
    "    # Returned None for start or end position index\n",
    "    except:\n",
    "        start_positions = None\n",
    "        end_positions = None\n",
    "    \n",
    "    encodings.update(\n",
    "        {\n",
    "            \"start_positions\": start_positions,\n",
    "            \"end_positions\": end_positions,\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        }\n",
    "    )\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b374c440f448d897debb3c1d006766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1851594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "train_dataset = train_dataset.map(convert_to_features)\n",
    "print(f\"Took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "valid_dataset = valid_dataset.map(convert_to_features)\n",
    "print(f\"Took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the tensor type and the columns which the dataset should return\n",
    "columns = ['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "train_dataset.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset.set_format(type='torch', columns=columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "a=range(int(1e8))\n",
    "\n",
    "#method 3\n",
    "b = map(str, tqdm(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "trange(int(1e7), leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1851594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n"
     ]
    }
   ],
   "source": [
    "train = datasets.load_dataset(\"squad\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.137159099989727"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1851594/87599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
