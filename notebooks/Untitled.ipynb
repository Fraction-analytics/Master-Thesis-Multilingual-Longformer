{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empty-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:395] 2021-01-21 17:44:28,536 >> loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "[INFO|configuration_utils.py:431] 2021-01-21 17:44:28,539 >> Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1599] 2021-01-21 17:44:29,370 >> loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "[INFO|tokenization_utils_base.py:1599] 2021-01-21 17:44:29,371 >> loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-tokenizer.json from cache at /.cache/torch/transformers/2548f9b79ad6e35303efa08cc1d173b32a2727a8314ca7283ed4f61b3608721f.dd9d4117ae6562a3d1d4d19d203f216c41ba7968fc47c83bbd199df99dca4871\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import datasets as nlp\n",
    "from transformers import LongformerTokenizerFast\n",
    "from transformers import XLMRobertaTokenizerFast, AutoTokenizer\n",
    "from transformers import XLMRobertaForQuestionAnswering\n",
    "from transformers import RobertaForQuestionAnswering\n",
    "\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "\n",
    "hf_logging.enable_default_handler()\n",
    "hf_logging.set_verbosity_info()\n",
    "hf_logging.enable_explicit_format()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base', use_fast=True)\n",
    "#tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designing-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_alignement(context: str, answer):\n",
    "    \"\"\" Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here. \"\"\"\n",
    "    gold_text = answer[\"text\"][0]\n",
    "    start_idx = answer[\"answer_start\"][0]\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "        return start_idx, end_idx  # When the gold label position is good\n",
    "    elif context[start_idx - 1 : end_idx - 1] == gold_text:\n",
    "        return start_idx - 1, end_idx - 1  # When the gold label is off by one character\n",
    "    elif context[start_idx - 2 : end_idx - 2] == gold_text:\n",
    "        return start_idx - 2, end_idx - 2  # When the gold label is off by two character\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        pad_to_max_length=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "    )\n",
    "    context_encodings = tokenizer.encode_plus(example[\"context\"])\n",
    "\n",
    "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methodes.\n",
    "    # this will give us the position of answer span in the context text\n",
    "    start_idx, end_idx = get_correct_alignement(example[\"context\"], example[\"answers\"])\n",
    "    start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "    end_positions_context = context_encodings.char_to_token(end_idx - 1)\n",
    "    \n",
    "    # FIXME: UGLY HACK because of XLM-R tokenization, works fine with monolingual\n",
    "    # 2 training examples returns incorrect positions\n",
    "    sep_idx = encodings[\"input_ids\"].index(tokenizer.sep_token_id)\n",
    "    try:\n",
    "        # here we will compute the start and end position of the answer in the whole example\n",
    "        # as the example is encoded like this <s> question</s></s> context</s>\n",
    "        # and we know the postion of the answer in the context\n",
    "        # we can just find out the index of the sep token and then add that to position + 1 (+1 because there are two sep tokens)\n",
    "        # this will give us the position of the answer span in whole example\n",
    "        \n",
    "        start_positions = start_positions_context + sep_idx + 1\n",
    "        end_positions = end_positions_context + sep_idx + 1\n",
    "\n",
    "        if end_positions > 512:\n",
    "            start_positions, end_positions = 0, 0\n",
    "    \n",
    "    # Returned None for start or end position index\n",
    "    except:\n",
    "        #print(f\"{example}\")\n",
    "        #print(f\"Start_idx: {start_idx} \\t End_idx: {end_idx}\")\n",
    "        #print(f\"Sep_idx: {sep_idx}\")\n",
    "        #print(f\"with start: {start_positions_context} \\t end: {end_positions_context}\\n\")\n",
    "        start_positions = None\n",
    "        end_positions = None\n",
    "    \n",
    "    encodings.update(\n",
    "        {\n",
    "            \"start_positions\": start_positions,\n",
    "            \"end_positions\": end_positions,\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        }\n",
    "    )\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metallic-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/.cache/huggingface/datasets/xquad/xquad.en/1.0.0/9e12114a409c05777407a840606169d55d5ffb5ca8003000da5325a25fd55cd3)\n",
      "Reusing dataset xquad (/.cache/huggingface/datasets/xquad/xquad.ru/1.0.0/9e12114a409c05777407a840606169d55d5ffb5ca8003000da5325a25fd55cd3)\n",
      "Reusing dataset xquad (/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/9e12114a409c05777407a840606169d55d5ffb5ca8003000da5325a25fd55cd3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers'],\n",
       "    num_rows: 1190\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each of these are validation datasets\n",
    "xquad_en = nlp.load_dataset('xquad', 'xquad.en', split=\"validation\")\n",
    "xquad_ru = nlp.load_dataset('xquad', 'xquad.ru', split=\"validation\")\n",
    "xquad_ar = nlp.load_dataset('xquad', 'xquad.ar', split=\"validation\")\n",
    "xquad_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colonial-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad41fc550549cf89c9b37a0e627faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccf17e695eb45e595184195bcbf4795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a22f2c7ca24bed82f2e6303c18b2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaf5a4452df4fb0921513b32e8adaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions', 'title'],\n",
       "    num_rows: 10551\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train, squad_valid = nlp.load_dataset('squad', split=['train', 'validation'])\n",
    "train_dataset = squad_train.map(convert_to_features).filter(lambda example: (example['start_positions'] is not None) and (example['end_positions'] is not None))\n",
    "valid_dataset = squad_valid.map(convert_to_features).filter(lambda example: (example['start_positions'] is not None) and (example['end_positions'] is not None))\n",
    "\n",
    "\n",
    "# set the tensor type and the columns which the dataset should return\n",
    "columns = ['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "train_dataset.set_format(type='torch', columns=columns)\n",
    "valid_dataset.set_format(type='torch', columns=columns)\n",
    "\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appointed-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset_to_torch_format(data):\n",
    "    data = data.map(convert_to_features).filter(lambda example: (example['start_positions'] is not None) and (example['end_positions'] is not None))\n",
    "\n",
    "    # set the tensor type and the columns which the dataset should return\n",
    "    columns = ['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "    data.set_format(type='torch', columns=columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quarterly-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers'],\n",
       "    num_rows: 1190\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xquad_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nonprofit-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0031d130dbd247a0ade61ec7f3e82c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bebd0943ef4ba280c95095ed99d083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xquad_en = convert_dataset_to_torch_format(xquad_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporated-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions'],\n",
       "    num_rows: 1187\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xquad_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-arena",
   "metadata": {},
   "source": [
    "## MLQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "personal-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mlqa (/.cache/huggingface/datasets/mlqa/mlqa-translate-train.de/1.0.0/2b5eaa00f1bd38db2d350b549e6b98c12822a0a3f00ad9fff89743970d6b671a)\n",
      "Reusing dataset mlqa (/.cache/huggingface/datasets/mlqa/mlqa-translate-test.de/1.0.0/2b5eaa00f1bd38db2d350b549e6b98c12822a0a3f00ad9fff89743970d6b671a)\n",
      "Reusing dataset mlqa (/.cache/huggingface/datasets/mlqa/mlqa.de.de/1.0.0/2b5eaa00f1bd38db2d350b549e6b98c12822a0a3f00ad9fff89743970d6b671a)\n"
     ]
    }
   ],
   "source": [
    "mlqa_train_de = nlp.load_dataset('mlqa', 'mlqa-translate-train.de')\n",
    "mlqa_test_de = nlp.load_dataset('mlqa', 'mlqa-translate-test.de')\n",
    "mlqa_valid_de = nlp.load_dataset('mlqa', 'mlqa.de.de')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numeric-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'id'],\n",
      "        num_rows: 80069\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'id'],\n",
      "        num_rows: 9927\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'id'],\n",
      "        num_rows: 4517\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'id'],\n",
      "        num_rows: 4517\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'id'],\n",
      "        num_rows: 512\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(mlqa_train_de) # Yes for training and val\n",
    "print(mlqa_test_de)  # Dont use\n",
    "print(mlqa_valid_de) # Dont use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "micro-roman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'id'],\n",
       "        num_rows: 4517\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-treat",
   "metadata": {},
   "source": [
    "# TEST TO concat text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "basic-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = nlp.load_dataset('squad', split='train')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "\n",
    "# Combine the context form N samples\n",
    "text_lenght_above = len(''.join(train['context'][0:N-1]))\n",
    "prev_start = train['answers'][N]['answer_start'][0]\n",
    "start_pos = text_lenght_above + prev_start\n",
    "\n",
    "context = ''.join(train['context'][0:N])\n",
    "\n",
    "# Get the correct \n",
    "''.join(train['context'][0:N])[context_above+prev_start: context_above+prev_start+50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['answers'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "departmental-helena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_span(index, span=5):\n",
    "    \"\"\"\n",
    "    Returns the value in a range for whole numbers\n",
    "    \n",
    "    Ex: index=4, span=5\n",
    "        lower=0, upper=5\n",
    "        \n",
    "        index=8, span=5\n",
    "        lower=5, upper=10\n",
    "    \"\"\"\n",
    "    lower_bound = (index-1)//span\n",
    "    lower_bound = lower_bound*span\n",
    "    upper_bound = lower_bound+span\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "\n",
    "index=11\n",
    "get_span(index, span=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "disturbed-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span(index, span=5):\n",
    "    \"\"\"\n",
    "    Returns the value in a range for whole numbers\n",
    "    \n",
    "    Ex: index=4, span=5\n",
    "        lower=0, upper=5\n",
    "        \n",
    "        index=8, span=5\n",
    "        lower=5, upper=10\n",
    "    \"\"\"\n",
    "    lower_bound = (index)//span\n",
    "    lower_bound = lower_bound*span\n",
    "    upper_bound = lower_bound+span\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "#low, high = get_span(index, span=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eight-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cca9d14c36c46e992826a2ec49e1a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=88.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = train.filter(lambda example, indice: indice % 5 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spatial-pottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a86169fb0f747de9dfc799c120ce741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def a(index, example):\n",
    "    low, high = get_span(index, span=5)\n",
    "\n",
    "    # Get new starting position\n",
    "    if index != low:\n",
    "        prev_start = len(''.join(data['context'][low:index]))\n",
    "        start_pos = data['answers'][index]['answer_start'][0]\n",
    "        example['answers']['answer_start'] = [prev_start + start_pos]\n",
    "\n",
    "    # Get new context\n",
    "    example['context'] = ''.join(train['context'][low:high])\n",
    "    return example\n",
    "\n",
    "    \n",
    "    \n",
    "data = data.map(lambda example, indice: a(indice, example), with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "capital-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xquad (/.cache/huggingface/datasets/xquad/xquad.ar/1.0.0/9e12114a409c05777407a840606169d55d5ffb5ca8003000da5325a25fd55cd3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers'],\n",
       "    num_rows: 1190\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.load_dataset('xquad', 'xquad.ar', split=\"validation\")# Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "animal-discount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3475\n",
      "7025\n",
      "3520\n",
      "3620\n",
      "4179\n",
      "6323\n",
      "2979\n",
      "3038\n",
      "5098\n",
      "6033\n",
      "4648\n",
      "3326\n",
      "5632\n",
      "3634\n",
      "6075\n",
      "7260\n",
      "6155\n",
      "5881\n",
      "4676\n",
      "3992\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "for i in range(0, len(lst), N):\n",
    "    text_lenght_above = len(''.join(train['context'][i:i+N]))\n",
    "    print(text_lenght_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "nominated-draft",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
       " {'answer_start': [188], 'text': ['a copper statue of Christ']},\n",
       " {'answer_start': [279], 'text': ['the Main Building']},\n",
       " {'answer_start': [381], 'text': ['a Marian place of prayer and reflection']},\n",
       " {'answer_start': [92], 'text': ['a golden statue of the Virgin Mary']},\n",
       " {'answer_start': [248], 'text': ['September 1876']},\n",
       " {'answer_start': [441], 'text': ['twice']},\n",
       " {'answer_start': [598], 'text': ['The Observer']},\n",
       " {'answer_start': [126], 'text': ['three']},\n",
       " {'answer_start': [908], 'text': ['1987']},\n",
       " {'answer_start': [119], 'text': ['Rome']},\n",
       " {'answer_start': [145], 'text': ['Moreau Seminary']},\n",
       " {'answer_start': [234], 'text': ['Old College']},\n",
       " {'answer_start': [356], 'text': ['Retired priests and brothers']},\n",
       " {'answer_start': [675], 'text': ['Buechner Prize for Preaching']},\n",
       " {'answer_start': [487], 'text': ['eight']},\n",
       " {'answer_start': [46], 'text': ['1920']},\n",
       " {'answer_start': [126], 'text': ['the College of Science']},\n",
       " {'answer_start': [271], 'text': ['five']},\n",
       " {'answer_start': [155], 'text': ['the 1870s']},\n",
       " {'answer_start': [496], 'text': ['Learning Resource Center']},\n",
       " {'answer_start': [68], 'text': ['five']},\n",
       " {'answer_start': [155], 'text': ['The First Year of Studies program']},\n",
       " {'answer_start': [647], 'text': ['U.S. News & World Report']},\n",
       " {'answer_start': [358], 'text': ['1924']},\n",
       " {'answer_start': [624], 'text': ['Master of Divinity']},\n",
       " {'answer_start': [1163], 'text': ['Alliance for Catholic Education']},\n",
       " {'answer_start': [92], 'text': ['1854']},\n",
       " {'answer_start': [757], 'text': ['Department of Pre-Professional Studies']},\n",
       " {'answer_start': [4],\n",
       "  'text': ['Joan B. Kroc Institute for International Peace Studies']},\n",
       " {'answer_start': [466],\n",
       "  'text': ['President Emeritus of the University of Notre Dame']},\n",
       " {'answer_start': [303], 'text': ['1986']},\n",
       " {'answer_start': [377], 'text': ['Ray Kroc']},\n",
       " {'answer_start': [360], 'text': [\"McDonald's\"]},\n",
       " {'answer_start': [136], 'text': ['14']},\n",
       " {'answer_start': [145], 'text': ['Theodore M. Hesburgh Library']},\n",
       " {'answer_start': [188], 'text': ['1963']},\n",
       " {'answer_start': [344], 'text': ['Millard Sheets']},\n",
       " {'answer_start': [394], 'text': ['Touchdown Jesus']},\n",
       " {'answer_start': [109], 'text': ['3,577']},\n",
       " {'answer_start': [138], 'text': ['19.7%']},\n",
       " {'answer_start': [213], 'text': ['the top 10 to 15 in the nation']},\n",
       " {'answer_start': [488], 'text': ['39.1%']},\n",
       " {'answer_start': [618], 'text': ['more than 750 miles']},\n",
       " {'answer_start': [32], 'text': ['18th overall']},\n",
       " {'answer_start': [362], 'text': ['8th']},\n",
       " {'answer_start': [565], 'text': ['1st overall']},\n",
       " {'answer_start': [155], 'text': ['USA Today']},\n",
       " {'answer_start': [918], 'text': ['57.6%']},\n",
       " {'answer_start': [0], 'text': ['Father Joseph Carrier, C.S.C.']},\n",
       " {'answer_start': [353], 'text': ['1851–1921']},\n",
       " {'answer_start': [406], 'text': ['the Science Department']},\n",
       " {'answer_start': [638], 'text': ['Evolution and Dogma']},\n",
       " {'answer_start': [85], 'text': ['Professor of Chemistry and Physics']},\n",
       " {'answer_start': [3], 'text': ['1882']},\n",
       " {'answer_start': [136], 'text': ['Professor Jerome Green']},\n",
       " {'answer_start': [123], 'text': ['Around 1899']},\n",
       " {'answer_start': [222], 'text': ['Father Julius Nieuwland']},\n",
       " {'answer_start': [49], 'text': ['an early wind tunnel']},\n",
       " {'answer_start': [0], 'text': ['The Lobund Institute']},\n",
       " {'answer_start': [963], 'text': ['the 1940s']},\n",
       " {'answer_start': [1049], 'text': ['1950']},\n",
       " {'answer_start': [1099], 'text': ['1958']},\n",
       " {'answer_start': [86], 'text': ['1928']},\n",
       " {'answer_start': [0], 'text': ['The Review of Politics']},\n",
       " {'answer_start': [68], 'text': ['German Catholic journals']},\n",
       " {'answer_start': [233], 'text': ['44']},\n",
       " {'answer_start': [4], 'text': ['Review of Politics']},\n",
       " {'answer_start': [80], 'text': ['John Jenkins']},\n",
       " {'answer_start': [118], 'text': ['Notre Dame']},\n",
       " {'answer_start': [427], 'text': ['International Peace studies']},\n",
       " {'answer_start': [753], 'text': ['2013']},\n",
       " {'answer_start': [891], 'text': ['climate change']},\n",
       " {'answer_start': [71], 'text': ['8,448']},\n",
       " {'answer_start': [196], 'text': ['21–24%']},\n",
       " {'answer_start': [1446], 'text': ['over 700']},\n",
       " {'answer_start': [1588], 'text': ['the Holy Cross Missions in Bangladesh']},\n",
       " {'answer_start': [49], 'text': ['12,179']},\n",
       " {'answer_start': [6], 'text': ['80%']},\n",
       " {'answer_start': [136], 'text': ['four']},\n",
       " {'answer_start': [350], 'text': ['15']},\n",
       " {'answer_start': [32], 'text': ['20%']},\n",
       " {'answer_start': [368], 'text': ['14']},\n",
       " {'answer_start': [73], 'text': ['Congregatio a Sancta Cruce']},\n",
       " {'answer_start': [197], 'text': ['more than 93%']},\n",
       " {'answer_start': [331], 'text': ['over 100 times']},\n",
       " {'answer_start': [1237], 'text': ['Fifty-seven']},\n",
       " {'answer_start': [251], 'text': ['over 80%']},\n",
       " {'answer_start': [702], 'text': ['Washington Hall']},\n",
       " {'answer_start': [90], 'text': ['1879']},\n",
       " {'answer_start': [228], 'text': ['Rev. William Corby']},\n",
       " {'answer_start': [385], 'text': ['17th of May']},\n",
       " {'answer_start': [862], 'text': ['LaFortune Student Center']},\n",
       " {'answer_start': [244], 'text': ['scholastic and classical']},\n",
       " {'answer_start': [595], 'text': ['College of Commerce']},\n",
       " {'answer_start': [8], 'text': ['Father James Burns']},\n",
       " {'answer_start': [66], 'text': ['three years']},\n",
       " {'answer_start': [430], 'text': ['Harvard Law School']},\n",
       " {'answer_start': [117], 'text': ['Knute Rockne']},\n",
       " {'answer_start': [204], 'text': ['105']},\n",
       " {'answer_start': [354], 'text': ['1925']},\n",
       " {'answer_start': [251], 'text': ['13']},\n",
       " {'answer_start': [274], 'text': ['three']},\n",
       " {'answer_start': [297], 'text': ['the Protestant establishment']},\n",
       " {'answer_start': [571], 'text': ['the Ku Klux Klan']},\n",
       " {'answer_start': [1193], 'text': ['Fr. Matthew Walsh']},\n",
       " {'answer_start': [819], 'text': ['a week-long Klavern']},\n",
       " {'answer_start': [842], 'text': ['South Bend']},\n",
       " {'answer_start': [11], 'text': [\"Father John Francis O'Hara\"]},\n",
       " {'answer_start': [11], 'text': [\"Father John Francis O'Hara\"]},\n",
       " {'answer_start': [292], 'text': ['Laetare Medal']},\n",
       " {'answer_start': [321], 'text': ['1883']},\n",
       " {'answer_start': [587], 'text': ['God']},\n",
       " {'answer_start': [428], 'text': ['more than half']},\n",
       " {'answer_start': [522], 'text': ['Lobund Institute for Animal Studies']},\n",
       " {'answer_start': [720], 'text': ['Hall of Liberal Arts']},\n",
       " {'answer_start': [4], 'text': ['Rev. John J. Cavanaugh, C.S.C.']},\n",
       " {'answer_start': [575], 'text': ['Medieval Institute']},\n",
       " {'answer_start': [37], 'text': ['1917–2015']},\n",
       " {'answer_start': [181], 'text': ['18']},\n",
       " {'answer_start': [262], 'text': ['$9 million']},\n",
       " {'answer_start': [82], 'text': ['1952–87']},\n",
       " {'answer_start': [439], 'text': ['950']},\n",
       " {'answer_start': [82], 'text': ['coeducational']},\n",
       " {'answer_start': [625], 'text': ['Dean of Arts and Letters']},\n",
       " {'answer_start': [921], 'text': ['Vice President of Student Affairs']},\n",
       " {'answer_start': [1199], 'text': ['1971']},\n",
       " {'answer_start': [141], 'text': [\"Saint Mary's College\"]},\n",
       " {'answer_start': [64], 'text': ['1987–2005']},\n",
       " {'answer_start': [314], 'text': ['1240']},\n",
       " {'answer_start': [403], 'text': ['$350 million']},\n",
       " {'answer_start': [576], 'text': ['more than $70 million']},\n",
       " {'answer_start': [191], 'text': ['500']},\n",
       " {'answer_start': [6], 'text': ['2005']},\n",
       " {'answer_start': [68], 'text': ['17th']},\n",
       " {'answer_start': [138], 'text': ['Malloy']},\n",
       " {'answer_start': [488], 'text': ['Compton Family Ice Arena']},\n",
       " {'answer_start': [596], 'text': ['$400m']},\n",
       " {'answer_start': [162], 'text': ['Congregation of Holy Cross']},\n",
       " {'answer_start': [202], 'text': ['Basilica of the Sacred Heart']},\n",
       " {'answer_start': [349], 'text': ['French Revival']},\n",
       " {'answer_start': [474], 'text': ['Luigi Gregori']},\n",
       " {'answer_start': [730], 'text': ['1896']},\n",
       " {'answer_start': [56], 'text': ['Fr. Zahm']},\n",
       " {'answer_start': [73], 'text': ['1950']},\n",
       " {'answer_start': [157], 'text': ['Joseph LaFortune']},\n",
       " {'answer_start': [284], 'text': ['83,000 square feet']},\n",
       " {'answer_start': [535], 'text': ['$1.2 million']},\n",
       " {'answer_start': [120], 'text': ['29']},\n",
       " {'answer_start': [336], 'text': ['Theodore Hesburgh Library']},\n",
       " {'answer_start': [398], 'text': ['almost 4 million']},\n",
       " {'answer_start': [613], 'text': ['Duncan Hall']},\n",
       " {'answer_start': [1755], 'text': ['Frank Eck Stadium']},\n",
       " {'answer_start': [142], 'text': ['2008']},\n",
       " {'answer_start': [471], 'text': ['40%']},\n",
       " {'answer_start': [596], 'text': ['Sustainable Endowments Institute']},\n",
       " {'answer_start': [750],\n",
       "  'text': ['Kroc Institute for International Peace Studies']},\n",
       " {'answer_start': [198], 'text': ['1968']},\n",
       " {'answer_start': [289], 'text': ['1 Suffolk Street in Trafalgar Square']},\n",
       " {'answer_start': [535], 'text': ['Global Gateways']},\n",
       " {'answer_start': [210], 'text': ['1998']},\n",
       " {'answer_start': [0], 'text': ['The College of Arts and Letters']},\n",
       " {'answer_start': [85], 'text': ['1842']},\n",
       " {'answer_start': [122], 'text': ['1849']},\n",
       " {'answer_start': [221], 'text': ['Saint Louis University']},\n",
       " {'answer_start': [424], 'text': ['33']},\n",
       " {'answer_start': [78], 'text': ['Father Patrick Dillon']},\n",
       " {'answer_start': [60], 'text': ['1865']},\n",
       " {'answer_start': [134], 'text': ['six years']},\n",
       " {'answer_start': [242], 'text': ['Jordan Hall of Science']},\n",
       " {'answer_start': [275], 'text': ['over 1,200']},\n",
       " {'answer_start': [4], 'text': ['School of Architecture']},\n",
       " {'answer_start': [159], 'text': ['Bond Hall']},\n",
       " {'answer_start': [179], 'text': ['five-year']},\n",
       " {'answer_start': [325], 'text': ['Rome']},\n",
       " {'answer_start': [624], 'text': ['Driehaus Architecture Prize']},\n",
       " {'answer_start': [388], 'text': ['2015']},\n",
       " {'answer_start': [405], 'text': ['the first floor of Stanford Hall']},\n",
       " {'answer_start': [538], 'text': ['over three million volumes']},\n",
       " {'answer_start': [654], 'text': ['one of the 100 largest']},\n",
       " {'answer_start': [0], 'text': ['The rise of Hitler and other dictators']},\n",
       " {'answer_start': [162], 'text': ['Germany']},\n",
       " {'answer_start': [212], 'text': ['classics and law']},\n",
       " {'answer_start': [478], 'text': ['Max Scheler']},\n",
       " {'answer_start': [519], 'text': ['a renowned sculptor']},\n",
       " {'answer_start': [4], 'text': ['University of Notre Dame du']},\n",
       " {'answer_start': [92], 'text': ['Catholic research university']},\n",
       " {'answer_start': [220], 'text': ['Our Lady of the Lake']},\n",
       " {'answer_start': [287], 'text': ['the Virgin Mary']},\n",
       " {'answer_start': [327], 'text': ['1,250']},\n",
       " {'answer_start': [62], 'text': ['its Fighting Irish football team']},\n",
       " {'answer_start': [149], 'text': ['Knute Rockne']},\n",
       " {'answer_start': [214], 'text': ['NCAA Division I']},\n",
       " {'answer_start': [372], 'text': ['seven']},\n",
       " {'answer_start': [454], 'text': ['13']},\n",
       " {'answer_start': [140], 'text': ['among the top twenty']},\n",
       " {'answer_start': [294], 'text': ['four']},\n",
       " {'answer_start': [494], 'text': ['Driehaus Architecture Prize']},\n",
       " {'answer_start': [557], 'text': ['more than 50']},\n",
       " {'answer_start': [887], 'text': ['Snite Museum of Art']},\n",
       " {'answer_start': [3], 'text': ['1842']},\n",
       " {'answer_start': [34], 'text': ['Célestine Guynemer de la Hailandière']},\n",
       " {'answer_start': [111], 'text': ['the Congregation of the Holy Cross']},\n",
       " {'answer_start': [290], 'text': ['November 26, 1842']},\n",
       " {'answer_start': [336], 'text': [\"Father Stephen Badin's old log chapel\"]},\n",
       " {'answer_start': [51], 'text': ['1849']},\n",
       " {'answer_start': [359], 'text': ['1865']},\n",
       " {'answer_start': [495], 'text': ['Father Lemonnier']},\n",
       " {'answer_start': [516], 'text': ['1879']},\n",
       " {'answer_start': [453], 'text': ['1873']},\n",
       " {'answer_start': [24], 'text': ['NDtv']},\n",
       " {'answer_start': [40], 'text': ['one show']},\n",
       " {'answer_start': [128], 'text': ['WSND-FM']},\n",
       " {'answer_start': [440], 'text': ['WVFI']},\n",
       " {'answer_start': [42], 'text': ['$215 million']},\n",
       " {'answer_start': [169], 'text': ['June 3, 2008']},\n",
       " {'answer_start': [401], 'text': ['Kite Realty']},\n",
       " {'answer_start': [249], 'text': ['the City of South Bend']},\n",
       " {'answer_start': [367], 'text': ['non-union workers']},\n",
       " {'answer_start': [82], 'text': ['National Collegiate Athletic Association']},\n",
       " {'answer_start': [293], 'text': ['Horizon League']},\n",
       " {'answer_start': [889], 'text': ['Midwest Fencing Conference']},\n",
       " {'answer_start': [959], 'text': ['Hockey East']},\n",
       " {'answer_start': [384], 'text': ['Big East Conference']},\n",
       " {'answer_start': [239], 'text': ['the ACC']},\n",
       " {'answer_start': [382], 'text': ['five']},\n",
       " {'answer_start': [674], 'text': ['Central Collegiate Hockey Association']},\n",
       " {'answer_start': [1223], 'text': ['Navy Blue and Gold Rush']},\n",
       " {'answer_start': [1398], 'text': ['Leprechaun']},\n",
       " {'answer_start': [50], 'text': ['Under Armour']},\n",
       " {'answer_start': [223], 'text': ['almost $100 million']},\n",
       " {'answer_start': [392], 'text': ['1846']},\n",
       " {'answer_start': [420],\n",
       "  'text': ['oldest university band in continuous existence in the United States']},\n",
       " {'answer_start': [657], 'text': ['Notre Dame Victory March']},\n",
       " {'answer_start': [74], 'text': ['Michigan Wolverines football team']},\n",
       " {'answer_start': [142], 'text': ['1887']},\n",
       " {'answer_start': [509], 'text': ['Ohio State University']},\n",
       " {'answer_start': [715], 'text': ['USC']},\n",
       " {'answer_start': [441], 'text': ['the most']},\n",
       " {'answer_start': [0], 'text': ['George Gipp']},\n",
       " {'answer_start': [362], 'text': ['the Army team']},\n",
       " {'answer_start': [457], 'text': [\"Pat O'Brien\"]},\n",
       " {'answer_start': [506], 'text': ['Gipp']},\n",
       " {'answer_start': [562], 'text': ['80,795']},\n",
       " {'answer_start': [166], 'text': ['two-story banner']},\n",
       " {'answer_start': [245], 'text': [\"the Drummers' Circle\"]},\n",
       " {'answer_start': [594], 'text': ['the steps of Bond Hall']},\n",
       " {'answer_start': [480],\n",
       "  'text': ['the Notre Dame Victory March and the Notre Dame Alma Mater']},\n",
       " {'answer_start': [424], 'text': ['Saturday']},\n",
       " {'answer_start': [30], 'text': ['over 1,600']},\n",
       " {'answer_start': [59], 'text': ['12']},\n",
       " {'answer_start': [119], 'text': ['28']},\n",
       " {'answer_start': [154], 'text': ['Austin Carr']},\n",
       " {'answer_start': [850], 'text': ['Mike Brey']},\n",
       " {'answer_start': [222], 'text': ['John F. Shea']},\n",
       " {'answer_start': [173], 'text': ['1904']},\n",
       " {'answer_start': [149], 'text': ['Rev. Michael J. Shea']},\n",
       " {'answer_start': [411], 'text': ['1928']},\n",
       " {'answer_start': [677], 'text': ['onward to victory']},\n",
       " {'answer_start': [267], 'text': ['The Gipper']},\n",
       " {'answer_start': [344], 'text': ['Airplane!']},\n",
       " {'answer_start': [513], 'text': ['Sean Astin']},\n",
       " {'answer_start': [410], 'text': ['George Zipp']},\n",
       " {'answer_start': [40], 'text': ['Knute Rockne']},\n",
       " {'answer_start': [185], 'text': ['Condoleezza Rice']},\n",
       " {'answer_start': [278], 'text': ['Eric F. Wieschaus']},\n",
       " {'answer_start': [384], 'text': ['Rev. John Jenkins']},\n",
       " {'answer_start': [937], 'text': ['Olympic gold']},\n",
       " {'answer_start': [1232], 'text': ['Jim Wetherbee']},\n",
       " {'answer_start': [269], 'text': ['in the late 1990s']},\n",
       " {'answer_start': [207], 'text': ['singing and dancing']},\n",
       " {'answer_start': [526], 'text': ['2003']},\n",
       " {'answer_start': [166], 'text': ['Houston, Texas']},\n",
       " {'answer_start': [276], 'text': ['late 1990s']},\n",
       " {'answer_start': [320], 'text': [\"Destiny's Child\"]},\n",
       " {'answer_start': [505], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [360], 'text': ['Mathew Knowles']},\n",
       " {'answer_start': [166], 'text': ['Houston']},\n",
       " {'answer_start': [505], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [64], 'text': ['September 4, 1981']},\n",
       " {'answer_start': [0], 'text': ['Beyoncé Giselle Knowles-Carter']},\n",
       " {'answer_start': [276], 'text': ['late 1990s']},\n",
       " {'answer_start': [290], 'text': ['lead singer']},\n",
       " {'answer_start': [505], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [526], 'text': ['2003']},\n",
       " {'answer_start': [590], 'text': ['five']},\n",
       " {'answer_start': [290], 'text': ['lead singer']},\n",
       " {'answer_start': [505], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [526], 'text': ['2003']},\n",
       " {'answer_start': [207], 'text': ['acting']},\n",
       " {'answer_start': [369], 'text': ['Jay Z']},\n",
       " {'answer_start': [565], 'text': ['six']},\n",
       " {'answer_start': [260], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [586], 'text': ['2010']},\n",
       " {'answer_start': [180], 'text': ['Beyoncé']},\n",
       " {'answer_start': [406], 'text': ['Cadillac Records']},\n",
       " {'answer_start': [48], 'text': ['June 2005']},\n",
       " {'answer_start': [95], 'text': [\"B'Day\"]},\n",
       " {'answer_start': [260], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [369], 'text': ['Jay Z']},\n",
       " {'answer_start': [466], 'text': ['Sasha Fierce']},\n",
       " {'answer_start': [104], 'text': ['love, relationships, and monogamy']},\n",
       " {'answer_start': [935], 'text': ['influential']},\n",
       " {'answer_start': [985], 'text': ['Forbes']},\n",
       " {'answer_start': [736], 'text': ['2000s']},\n",
       " {'answer_start': [985], 'text': ['Forbes']},\n",
       " {'answer_start': [18], 'text': ['modern-day feminist']},\n",
       " {'answer_start': [970], 'text': ['2013 and 2014']},\n",
       " {'answer_start': [393], 'text': ['118 million']},\n",
       " {'answer_start': [445], 'text': ['60 million']},\n",
       " {'answer_start': [393], 'text': ['118 million']},\n",
       " {'answer_start': [552], 'text': ['20']},\n",
       " {'answer_start': [985], 'text': ['Forbes']},\n",
       " {'answer_start': [303], 'text': [\"Destiny's Child\"]},\n",
       " {'answer_start': [204], 'text': [\"her mother's maiden name\"]},\n",
       " {'answer_start': [330], 'text': ['African-American']},\n",
       " {'answer_start': [578], 'text': ['Methodist']},\n",
       " {'answer_start': [152], 'text': ['Xerox']},\n",
       " {'answer_start': [101], 'text': ['hairdresser and salon owner']},\n",
       " {'answer_start': [255], 'text': ['Solange']},\n",
       " {'answer_start': [540], 'text': ['Joseph Broussard']},\n",
       " {'answer_start': [152], 'text': ['Xerox']},\n",
       " {'answer_start': [117], 'text': ['salon']},\n",
       " {'answer_start': [255], 'text': ['Solange']},\n",
       " {'answer_start': [540], 'text': ['Joseph Broussard.']},\n",
       " {'answer_start': [578], 'text': ['Methodist']},\n",
       " {'answer_start': [49], 'text': ['Fredericksburg']},\n",
       " {'answer_start': [165], 'text': ['Darlette Johnson']},\n",
       " {'answer_start': [507], 'text': ['Houston']},\n",
       " {'answer_start': [148], 'text': ['dance instructor Darlette Johnson']},\n",
       " {'answer_start': [711], 'text': [\"St. John's United Methodist Church\"]},\n",
       " {'answer_start': [484], 'text': ['music magnet school']},\n",
       " {'answer_start': [385], 'text': ['Imagine']},\n",
       " {'answer_start': [49], 'text': ['Fredericksburg']},\n",
       " {'answer_start': [165], 'text': ['Darlette Johnson']},\n",
       " {'answer_start': [355], 'text': ['seven']},\n",
       " {'answer_start': [711], 'text': [\"St. John's United Methodist Church\"]},\n",
       " {'answer_start': [303], 'text': ['Arne Frager']},\n",
       " {'answer_start': [542], 'text': [\"Beyoncé's father\"]},\n",
       " {'answer_start': [918], 'text': ['Elektra Records']},\n",
       " {'answer_start': [303], 'text': ['Arne Frager']},\n",
       " {'answer_start': [537], 'text': ['1995']},\n",
       " {'answer_start': [1264], 'text': ['Sony Music']},\n",
       " {'answer_start': [918], 'text': ['Elektra Records']},\n",
       " {'answer_start': [3], 'text': ['age eight']},\n",
       " {'answer_start': [7], 'text': ['eight']},\n",
       " {'answer_start': [192], 'text': [\"Girl's Tyme\"]},\n",
       " {'answer_start': [303], 'text': ['Arne Frager']},\n",
       " {'answer_start': [537], 'text': ['1995']},\n",
       " {'answer_start': [1126],\n",
       "  'text': [\"Dwayne Wiggins's Grass Roots Entertainment\"]},\n",
       " {'answer_start': [215], 'text': ['Men in Black']},\n",
       " {'answer_start': [848], 'text': ['\"Say My Name\"']},\n",
       " {'answer_start': [1212], 'text': ['Marc Nelson']},\n",
       " {'answer_start': [51], 'text': ['1996']},\n",
       " {'answer_start': [85], 'text': ['Book of Isaiah']},\n",
       " {'answer_start': [215], 'text': ['Men in Black']},\n",
       " {'answer_start': [849], 'text': ['Say My Name']},\n",
       " {'answer_start': [1212], 'text': ['Marc Nelson']},\n",
       " {'answer_start': [85], 'text': ['Book of Isaiah.']},\n",
       " {'answer_start': [215], 'text': ['Men in Black.']},\n",
       " {'answer_start': [330], 'text': ['No, No, No']},\n",
       " {'answer_start': [688], 'text': ['1999']},\n",
       " {'answer_start': [1212], 'text': ['Marc Nelson']},\n",
       " {'answer_start': [169], 'text': ['depression']},\n",
       " {'answer_start': [320], 'text': ['boyfriend left her']},\n",
       " {'answer_start': [714], 'text': ['her mother']},\n",
       " {'answer_start': [194], 'text': ['split with Luckett and Rober']},\n",
       " {'answer_start': [396], 'text': ['a couple of years']},\n",
       " {'answer_start': [714], 'text': ['her mother']},\n",
       " {'answer_start': [110], 'text': ['Farrah Franklin and Michelle Williams.']},\n",
       " {'answer_start': [149], 'text': ['Beyoncé']},\n",
       " {'answer_start': [714], 'text': ['her mother']},\n",
       " {'answer_start': [110], 'text': ['Farrah Franklin']},\n",
       " {'answer_start': [37], 'text': ['Independent Women Part I']},\n",
       " {'answer_start': [216], 'text': ['eleven']},\n",
       " {'answer_start': [348], 'text': ['MTV']},\n",
       " {'answer_start': [793], 'text': ['663,000 copies']},\n",
       " {'answer_start': [557], 'text': ['Georges Bizet']},\n",
       " {'answer_start': [593], 'text': ['Survivor']},\n",
       " {'answer_start': [115], 'text': [\"Charlie's Angels.\"]},\n",
       " {'answer_start': [378], 'text': ['Carmen: A Hip Hopera']},\n",
       " {'answer_start': [593], 'text': ['Survivor']},\n",
       " {'answer_start': [628], 'text': ['Luckett and Roberson']},\n",
       " {'answer_start': [1070], 'text': ['October 2001']},\n",
       " {'answer_start': [84], 'text': ['Mike Myers']},\n",
       " {'answer_start': [331], 'text': ['UK, Norway, and Belgium']},\n",
       " {'answer_start': [431], 'text': ['The Fighting Temptations']},\n",
       " {'answer_start': [705], 'text': ['Missy Elliott']},\n",
       " {'answer_start': [834], 'text': ['Summertime']},\n",
       " {'answer_start': [115], 'text': ['Austin Powers in Goldmember']},\n",
       " {'answer_start': [210], 'text': ['73 million']},\n",
       " {'answer_start': [416], 'text': ['musical comedy']},\n",
       " {'answer_start': [435], 'text': ['Fighting Temptations']},\n",
       " {'answer_start': [545], 'text': ['mixed reviews']},\n",
       " {'answer_start': [115], 'text': ['Austin Powers in Goldmember']},\n",
       " {'answer_start': [58], 'text': ['Foxxy Cleopatra']},\n",
       " {'answer_start': [240], 'text': ['Work It Out']},\n",
       " {'answer_start': [431], 'text': ['The Fighting Temptations']},\n",
       " {'answer_start': [435], 'text': ['Fighting Temptations']},\n",
       " {'answer_start': [123], 'text': ['number four']},\n",
       " {'answer_start': [193], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [419], 'text': ['11 million']},\n",
       " {'answer_start': [474], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [130], 'text': ['four']},\n",
       " {'answer_start': [48], 'text': ['Jay Z']},\n",
       " {'answer_start': [193], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [123], 'text': ['number four']},\n",
       " {'answer_start': [1042], 'text': ['Luther Vandross']},\n",
       " {'answer_start': [48], 'text': ['Jay Z']},\n",
       " {'answer_start': [229], 'text': ['June 24, 2003']},\n",
       " {'answer_start': [474], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [1042], 'text': ['Luther Vandross.']},\n",
       " {'answer_start': [696], 'text': ['five.']},\n",
       " {'answer_start': [513], 'text': ['Destiny Fulfilled']},\n",
       " {'answer_start': [1212], 'text': ['2006']},\n",
       " {'answer_start': [3], 'text': ['November 2003']},\n",
       " {'answer_start': [664], 'text': ['Destiny Fulfilled']},\n",
       " {'answer_start': [935], 'text': ['Barcelona']},\n",
       " {'answer_start': [1206], 'text': ['March 2006']},\n",
       " {'answer_start': [38], 'text': ['Dangerously in Love Tour']},\n",
       " {'answer_start': [100], 'text': ['Missy Elliott and Alicia Keys']},\n",
       " {'answer_start': [253], 'text': ['Super Bowl XXXVIII']},\n",
       " {'answer_start': [848], 'text': ['Destiny Fulfilled.']},\n",
       " {'answer_start': [132], 'text': ['541,000']},\n",
       " {'answer_start': [303], 'text': ['Déjà Vu']},\n",
       " {'answer_start': [346], 'text': ['five']},\n",
       " {'answer_start': [346], 'text': ['five']},\n",
       " {'answer_start': [101], 'text': ['twenty-fifth birthday']},\n",
       " {'answer_start': [323], 'text': ['Jay Z']},\n",
       " {'answer_start': [342], 'text': ['top five']},\n",
       " {'answer_start': [28], 'text': [\"B'Day\"]},\n",
       " {'answer_start': [132], 'text': ['541,000']},\n",
       " {'answer_start': [323], 'text': ['Jay Z']},\n",
       " {'answer_start': [635], 'text': ['Green Light']},\n",
       " {'answer_start': [53], 'text': ['The Pink Panther']},\n",
       " {'answer_start': [171], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [171], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [550], 'text': ['2007']},\n",
       " {'answer_start': [671], 'text': ['24 million']},\n",
       " {'answer_start': [112], 'text': ['158.8 million']},\n",
       " {'answer_start': [576], 'text': ['The Beyoncé Experience']},\n",
       " {'answer_start': [932], 'text': ['Shakira']},\n",
       " {'answer_start': [53], 'text': ['The Pink Panther']},\n",
       " {'answer_start': [436], 'text': ['Diana Ross.']},\n",
       " {'answer_start': [487], 'text': ['Listen']},\n",
       " {'answer_start': [576], 'text': ['The Beyoncé Experience']},\n",
       " {'answer_start': [932], 'text': ['Shakira']},\n",
       " {'answer_start': [34], 'text': ['Jay Z']},\n",
       " {'answer_start': [253], 'text': ['November 18, 2008']},\n",
       " {'answer_start': [897], 'text': ['2000s']},\n",
       " {'answer_start': [1567], 'text': ['Taylor Swift']},\n",
       " {'answer_start': [1881], 'text': ['119.5 million']},\n",
       " {'answer_start': [78], 'text': ['in a video montage']},\n",
       " {'answer_start': [1744], 'text': ['March 2009']},\n",
       " {'answer_start': [1567], 'text': ['Taylor Swift']},\n",
       " {'answer_start': [1881], 'text': ['119.5 million']},\n",
       " {'answer_start': [3], 'text': ['April 4, 2008']},\n",
       " {'answer_start': [34], 'text': ['Jay Z.']},\n",
       " {'answer_start': [156], 'text': ['Sasha Fierce']},\n",
       " {'answer_start': [605], 'text': ['Single Ladies']},\n",
       " {'answer_start': [1611], 'text': ['Kanye West']},\n",
       " {'answer_start': [69], 'text': ['Etta James']},\n",
       " {'answer_start': [439], 'text': ['Phoenix House']},\n",
       " {'answer_start': [582], 'text': ['At Last']},\n",
       " {'answer_start': [693], 'text': ['thriller']},\n",
       " {'answer_start': [1101], 'text': ['MTV Movie Award for Best Fight']},\n",
       " {'answer_start': [439], 'text': ['Phoenix House']},\n",
       " {'answer_start': [703], 'text': ['Obsessed']},\n",
       " {'answer_start': [724], 'text': ['Sharon Charles']},\n",
       " {'answer_start': [940], 'text': ['60 million']},\n",
       " {'answer_start': [69], 'text': ['Etta James']},\n",
       " {'answer_start': [439], 'text': ['Phoenix House']},\n",
       " {'answer_start': [594], 'text': [\"the First Couple's first inaugural ball.\"]},\n",
       " {'answer_start': [703], 'text': ['Obsessed.']},\n",
       " {'answer_start': [51], 'text': ['ten']},\n",
       " {'answer_start': [242], 'text': ['Lauryn Hill']},\n",
       " {'answer_start': [352], 'text': ['Lady Gaga']},\n",
       " {'answer_start': [457], 'text': ['six']},\n",
       " {'answer_start': [517], 'text': ['Mariah Carey']},\n",
       " {'answer_start': [51], 'text': ['ten nominations']},\n",
       " {'answer_start': [372], 'text': ['Telephone']},\n",
       " {'answer_start': [352], 'text': ['Lady Gaga']},\n",
       " {'answer_start': [517], 'text': ['Mariah Carey']},\n",
       " {'answer_start': [242], 'text': ['Lauryn Hill']},\n",
       " {'answer_start': [51], 'text': ['ten']},\n",
       " {'answer_start': [242], 'text': ['Lauryn Hill']},\n",
       " {'answer_start': [352], 'text': ['Lady Gaga']},\n",
       " {'answer_start': [517], 'text': ['Mariah Carey']},\n",
       " {'answer_start': [60], 'text': ['2010']},\n",
       " {'answer_start': [60], 'text': ['2010']},\n",
       " {'answer_start': [300], 'text': ['the Great Wall of China']},\n",
       " {'answer_start': [60], 'text': ['2010']},\n",
       " {'answer_start': [74], 'text': ['her mother']},\n",
       " {'answer_start': [143], 'text': ['During the break']},\n",
       " {'answer_start': [244], 'text': ['nine months']},\n",
       " {'answer_start': [18], 'text': ['a hiatus']},\n",
       " {'answer_start': [74], 'text': ['her mother']},\n",
       " {'answer_start': [168], 'text': ['her father']},\n",
       " {'answer_start': [244], 'text': ['nine months']},\n",
       " {'answer_start': [3], 'text': ['2011']},\n",
       " {'answer_start': [367], 'text': ['Clinton Bush Haiti Fund']},\n",
       " {'answer_start': [486], 'text': ['the 2011 Glastonbury Festival']},\n",
       " {'answer_start': [313], 'text': ['The Huffington Post']},\n",
       " {'answer_start': [596], 'text': ['minute']},\n",
       " {'answer_start': [9], 'text': ['documents obtained by WikiLeaks']},\n",
       " {'answer_start': [3], 'text': ['2011']},\n",
       " {'answer_start': [313], 'text': ['The Huffington Post']},\n",
       " {'answer_start': [495], 'text': ['Glastonbury Festival']},\n",
       " {'answer_start': [137], 'text': ['Muammar Gaddafi.']},\n",
       " {'answer_start': [31], 'text': ['WikiLeaks']},\n",
       " {'answer_start': [367], 'text': ['Clinton Bush Haiti Fund.']},\n",
       " {'answer_start': [469], 'text': ['Pyramid stage']},\n",
       " {'answer_start': [51], 'text': ['2011']},\n",
       " {'answer_start': [371], 'text': ['Love on Top']},\n",
       " {'answer_start': [617], 'text': ['writing']},\n",
       " {'answer_start': [719], 'text': [\"New York's Roseland Ballroom\"]},\n",
       " {'answer_start': [42], 'text': ['June 28, 2011']},\n",
       " {'answer_start': [74], 'text': ['310,000 copies']},\n",
       " {'answer_start': [640],\n",
       "  'text': ['New York Association of Black Journalists']},\n",
       " {'answer_start': [51], 'text': ['2011']},\n",
       " {'answer_start': [24], 'text': ['4']},\n",
       " {'answer_start': [42], 'text': ['June 28, 2011']},\n",
       " {'answer_start': [74], 'text': ['310,000']},\n",
       " {'answer_start': [562], 'text': ['Essence']},\n",
       " {'answer_start': [719], 'text': [\"New York's Roseland Ballroom\"]},\n",
       " {'answer_start': [3], 'text': ['January 7, 2012']},\n",
       " {'answer_start': [91], 'text': ['Lenox Hill Hospital']},\n",
       " {'answer_start': [71], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [176], 'text': [\"Revel Atlantic City's Ovation Hall\"]},\n",
       " {'answer_start': [3], 'text': ['January 7, 2012']},\n",
       " {'answer_start': [71], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [124], 'text': ['Five months']},\n",
       " {'answer_start': [161], 'text': ['four nights']},\n",
       " {'answer_start': [3], 'text': ['January 7, 2012']},\n",
       " {'answer_start': [71], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [91], 'text': ['Lenox Hill Hospital in New York.']},\n",
       " {'answer_start': [176], 'text': [\"Revel Atlantic City's Ovation Hall\"]},\n",
       " {'answer_start': [161], 'text': ['four']},\n",
       " {'answer_start': [81], 'text': ['romance']},\n",
       " {'answer_start': [689], 'text': ['Life Is But a Dream']},\n",
       " {'answer_start': [1163], 'text': ['global publishing agreement']},\n",
       " {'answer_start': [3], 'text': ['January 2013']},\n",
       " {'answer_start': [158], 'text': ['Nuclear']},\n",
       " {'answer_start': [258], 'text': ['President Obama']},\n",
       " {'answer_start': [523], 'text': ['268,000 tweets per minute']},\n",
       " {'answer_start': [3], 'text': ['January 2013']},\n",
       " {'answer_start': [158], 'text': ['Nuclear']},\n",
       " {'answer_start': [186], 'text': ['the American national anthem']},\n",
       " {'answer_start': [362], 'text': ['Super Bowl XLVII halftime show']},\n",
       " {'answer_start': [689], 'text': ['Life Is But a Dream']},\n",
       " {'answer_start': [103], 'text': ['132']},\n",
       " {'answer_start': [20], 'text': ['The Mrs. Carter Show']},\n",
       " {'answer_start': [560], 'text': ['Rise Up']},\n",
       " {'answer_start': [469], 'text': ['Epic']},\n",
       " {'answer_start': [55], 'text': ['April 15']},\n",
       " {'answer_start': [399], 'text': ['2013 Met Gala']},\n",
       " {'answer_start': [429], 'text': ['Queen Tara']},\n",
       " {'answer_start': [560], 'text': ['Rise Up']},\n",
       " {'answer_start': [20], 'text': ['The Mrs. Carter Show World Tour']},\n",
       " {'answer_start': [103], 'text': ['132']},\n",
       " {'answer_start': [288], 'text': ['Back to Black']},\n",
       " {'answer_start': [404], 'text': ['Met Gala.']},\n",
       " {'answer_start': [429], 'text': ['Queen Tara']},\n",
       " {'answer_start': [88], 'text': ['the iTunes Store']},\n",
       " {'answer_start': [3], 'text': ['December 13, 2013']},\n",
       " {'answer_start': [88], 'text': ['the iTunes Store']},\n",
       " {'answer_start': [810], 'text': ['Jay Z']},\n",
       " {'answer_start': [1344], 'text': ['Forbes']},\n",
       " {'answer_start': [1471], 'text': ['more than double her earnings']},\n",
       " {'answer_start': [3], 'text': ['December 13, 2013']},\n",
       " {'answer_start': [440], 'text': ['one million']},\n",
       " {'answer_start': [784], 'text': ['Drunk in Love']},\n",
       " {'answer_start': [974], 'text': ['On the Run Tour.']},\n",
       " {'answer_start': [108], 'text': ['three']},\n",
       " {'answer_start': [283], 'text': ['Beck']},\n",
       " {'answer_start': [364], 'text': ['Vogue']},\n",
       " {'answer_start': [770], 'text': ['Coldplay']},\n",
       " {'answer_start': [108], 'text': ['three']},\n",
       " {'answer_start': [283], 'text': ['Beck']},\n",
       " {'answer_start': [770], 'text': ['Coldplay']},\n",
       " {'answer_start': [77], 'text': ['six awards']},\n",
       " {'answer_start': [364], 'text': ['Vogue']},\n",
       " {'answer_start': [770], 'text': ['Coldplay']},\n",
       " {'answer_start': [770], 'text': ['Coldplay']},\n",
       " {'answer_start': [77], 'text': ['six']},\n",
       " {'answer_start': [108], 'text': ['three']},\n",
       " {'answer_start': [283], 'text': ['Beck']},\n",
       " {'answer_start': [364], 'text': ['Vogue']},\n",
       " {'answer_start': [770], 'text': ['Coldplay']},\n",
       " {'answer_start': [140], 'text': ['Tidal']},\n",
       " {'answer_start': [154], 'text': ['Formation']},\n",
       " {'answer_start': [3], 'text': ['February 6, 2016']},\n",
       " {'answer_start': [101], 'text': ['exclusively']},\n",
       " {'answer_start': [140], 'text': ['Tidal']},\n",
       " {'answer_start': [116], 'text': ['music streaming']},\n",
       " {'answer_start': [3], 'text': ['February 6, 2016']},\n",
       " {'answer_start': [140], 'text': ['Tidal']},\n",
       " {'answer_start': [447], 'text': ['300 million']},\n",
       " {'answer_start': [825], 'text': ['Paris']},\n",
       " {'answer_start': [617], 'text': ['miscarriage']},\n",
       " {'answer_start': [62], 'text': ['Jay Z']},\n",
       " {'answer_start': [332], 'text': ['April 4, 2008']},\n",
       " {'answer_start': [447], 'text': ['300 million']},\n",
       " {'answer_start': [736], 'text': ['wrote music']},\n",
       " {'answer_start': [825], 'text': ['Paris']},\n",
       " {'answer_start': [94], 'text': [\"'03 Bonnie & Clyde\"]},\n",
       " {'answer_start': [332], 'text': ['April 4, 2008']},\n",
       " {'answer_start': [447], 'text': ['300 million']},\n",
       " {'answer_start': [617], 'text': ['miscarriage']},\n",
       " {'answer_start': [912], 'text': ['Paris.']},\n",
       " {'answer_start': [40], 'text': ['MTV Video Music Awards']},\n",
       " {'answer_start': [360], 'text': ['her pregnancy']},\n",
       " {'answer_start': [535], 'text': ['12.4 million']},\n",
       " {'answer_start': [35], 'text': ['2011 MTV Video Music Awards']},\n",
       " {'answer_start': [417], 'text': ['Her appearance']},\n",
       " {'answer_start': [616], 'text': ['most tweets per second']},\n",
       " {'answer_start': [719], 'text': ['Beyonce pregnant']},\n",
       " {'answer_start': [92], 'text': ['Love on Top']},\n",
       " {'answer_start': [35], 'text': ['2011 MTV Video Music Awards']},\n",
       " {'answer_start': [92], 'text': ['Love on Top']},\n",
       " {'answer_start': [535], 'text': ['12.4 million']},\n",
       " {'answer_start': [719], 'text': ['Beyonce pregnant']},\n",
       " {'answer_start': [216], 'text': ['Lifeandtimes.com']},\n",
       " {'answer_start': [160], 'text': ['Glory']},\n",
       " {'answer_start': [54], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [74], 'text': ['Lenox Hill Hospital']},\n",
       " {'answer_start': [160], 'text': ['Glory']},\n",
       " {'answer_start': [54], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [457], 'text': ['B.I.C.']},\n",
       " {'answer_start': [3], 'text': ['January 7, 2012']},\n",
       " {'answer_start': [54], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [160], 'text': ['Glory']},\n",
       " {'answer_start': [367], 'text': [\"Blue Ivy's cries\"]},\n",
       " {'answer_start': [457], 'text': ['B.I.C.']},\n",
       " {'answer_start': [880], 'text': ['George Zimmerman']},\n",
       " {'answer_start': [112], 'text': ['America the Beautiful']},\n",
       " {'answer_start': [398], 'text': ['4 million']},\n",
       " {'answer_start': [700], 'text': ['same sex marriage']},\n",
       " {'answer_start': [840], 'text': ['a rally']},\n",
       " {'answer_start': [112], 'text': ['America the Beautiful']},\n",
       " {'answer_start': [112], 'text': ['America the Beautiful']},\n",
       " {'answer_start': [186], 'text': ['At Last']},\n",
       " {'answer_start': [458], 'text': ['Tumblr']},\n",
       " {'answer_start': [700], 'text': ['same sex marriage']},\n",
       " {'answer_start': [29], 'text': ['Vogue']},\n",
       " {'answer_start': [514], 'text': ['Ban Bossy campaign']},\n",
       " {'answer_start': [29], 'text': ['Vogue']},\n",
       " {'answer_start': [38], 'text': ['April 2013']},\n",
       " {'answer_start': [514], 'text': ['Ban Bossy']},\n",
       " {'answer_start': [445], 'text': ['Flawless']},\n",
       " {'answer_start': [586], 'text': ['leadership in girls']},\n",
       " {'answer_start': [365], 'text': ['Chimamanda Ngozi Adichie']},\n",
       " {'answer_start': [514], 'text': ['Ban Bossy']},\n",
       " {'answer_start': [44], 'text': ['the ONE Campaign']},\n",
       " {'answer_start': [374], 'text': ['September 2015']},\n",
       " {'answer_start': [191], 'text': ['women']},\n",
       " {'answer_start': [313], 'text': ['priorities']},\n",
       " {'answer_start': [3], 'text': ['2015']},\n",
       " {'answer_start': [125], 'text': ['Angela Merkel and Nkosazana Dlamini-Zuma']},\n",
       " {'answer_start': [218], 'text': ['head of the G7 in Germany']},\n",
       " {'answer_start': [374], 'text': ['September 2015']},\n",
       " {'answer_start': [44], 'text': ['the ONE Campaign']},\n",
       " {'answer_start': [125], 'text': ['Angela Merkel and Nkosazana Dlamini-Zuma']},\n",
       " {'answer_start': [214], 'text': ['the head of the G7 in Germany']},\n",
       " {'answer_start': [191], 'text': ['women']},\n",
       " {'answer_start': [23], 'text': ['Freddie Gray']},\n",
       " {'answer_start': [132], 'text': ['protesters']},\n",
       " {'answer_start': [23], 'text': ['Freddie Gray']},\n",
       " {'answer_start': [186], 'text': ['thousands of dollars']},\n",
       " {'answer_start': [248], 'text': ['Madonna and Celine Dion']},\n",
       " {'answer_start': [1013], 'text': ['highest-earning power couple']},\n",
       " {'answer_start': [1460], 'text': ['2014']},\n",
       " {'answer_start': [1880], 'text': ['250 million']},\n",
       " {'answer_start': [248], 'text': ['Madonna and Celine Dion']},\n",
       " {'answer_start': [0], 'text': ['Forbes']},\n",
       " {'answer_start': [1112], 'text': ['2011']},\n",
       " {'answer_start': [1660], 'text': ['115 million']},\n",
       " {'answer_start': [1880], 'text': ['250 million']},\n",
       " {'answer_start': [0], 'text': ['Forbes']},\n",
       " {'answer_start': [1557], 'text': ['April 2014.']},\n",
       " {'answer_start': [1427], 'text': ['MTV']},\n",
       " {'answer_start': [1204], 'text': ['2013']},\n",
       " {'answer_start': [28], 'text': ['four']},\n",
       " {'answer_start': [42], 'text': ['Jody Rosen']},\n",
       " {'answer_start': [415], 'text': ['The Daily Mail']},\n",
       " {'answer_start': [546], 'text': ['hip hop']},\n",
       " {'answer_start': [28], 'text': ['four octaves']},\n",
       " {'answer_start': [453], 'text': ['versatile']},\n",
       " {'answer_start': [714], 'text': ['hip hop']},\n",
       " {'answer_start': [883], 'text': ['praise her range and power']},\n",
       " {'answer_start': [28], 'text': ['four']},\n",
       " {'answer_start': [333], 'text': ['Her vocal abilities']},\n",
       " {'answer_start': [630], 'text': ['tart']},\n",
       " {'answer_start': [710], 'text': ['the hip hop era']},\n",
       " {'answer_start': [29], 'text': ['R&B']},\n",
       " {'answer_start': [60], 'text': ['pop, soul and funk']},\n",
       " {'answer_start': [307], 'text': ['Spanish']},\n",
       " {'answer_start': [417], 'text': [\"re-release of B'Day\"]},\n",
       " {'answer_start': [516], 'text': ['Rudy Perez']},\n",
       " {'answer_start': [29], 'text': ['R&B']},\n",
       " {'answer_start': [267], 'text': ['English']},\n",
       " {'answer_start': [307], 'text': ['Spanish']},\n",
       " {'answer_start': [369], 'text': [\"B'Day\"]},\n",
       " {'answer_start': [29], 'text': ['R&B']},\n",
       " {'answer_start': [307], 'text': ['Spanish']},\n",
       " {'answer_start': [516], 'text': ['Rudy Perez.']},\n",
       " {'answer_start': [431], 'text': [\"B'Day.\"]},\n",
       " {'answer_start': [521], 'text': ['beats']},\n",
       " {'answer_start': [338], 'text': ['Cater 2 U']},\n",
       " {'answer_start': [153], 'text': ['female-empowerment']},\n",
       " {'answer_start': [309], 'text': ['man-tending anthems']},\n",
       " {'answer_start': [376], 'text': ['co-producing credits']},\n",
       " {'answer_start': [564], 'text': ['melodies']},\n",
       " {'answer_start': [210], 'text': ['Women']},\n",
       " {'answer_start': [376], 'text': ['co-producing']},\n",
       " {'answer_start': [564], 'text': ['melodies and ideas']},\n",
       " {'answer_start': [205], 'text': ['Beyoncé']},\n",
       " {'answer_start': [132],\n",
       "  'text': ['American Society of Composers, Authors, and Publishers Pop Music Awards']},\n",
       " {'answer_start': [436], 'text': ['Diane Warren']},\n",
       " {'answer_start': [656], 'text': ['Top 20 Hot 100 Songwriters']},\n",
       " {'answer_start': [3], 'text': ['2001']},\n",
       " {'answer_start': [221], 'text': ['third']},\n",
       " {'answer_start': [587], 'text': ['Billboard magazine']},\n",
       " {'answer_start': [221], 'text': ['third woman']},\n",
       " {'answer_start': [92], 'text': ['Pop Songwriter of the Year award']},\n",
       " {'answer_start': [128],\n",
       "  'text': ['the American Society of Composers, Authors, and Publishers Pop Music Awards.']},\n",
       " {'answer_start': [260], 'text': ['three']},\n",
       " {'answer_start': [631], 'text': ['17']},\n",
       " {'answer_start': [14], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [67], 'text': ['five']},\n",
       " {'answer_start': [14], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [589], 'text': ['vocal runs']},\n",
       " {'answer_start': [14], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [534], 'text': ['Vision of Love']},\n",
       " {'answer_start': [14], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [14], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [358], 'text': ['Diana Ross']},\n",
       " {'answer_start': [404], 'text': ['Whitney Houston']},\n",
       " {'answer_start': [534], 'text': ['Vision of Love']},\n",
       " {'answer_start': [4], 'text': ['feminism and female empowerment']},\n",
       " {'answer_start': [134], 'text': ['Josephine Baker']},\n",
       " {'answer_start': [399], 'text': ['Etta James']},\n",
       " {'answer_start': [109], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [418], 'text': ['boldness']},\n",
       " {'answer_start': [211], 'text': ['2006 Fashion Rocks concert']},\n",
       " {'answer_start': [134], 'text': ['Josephine Baker.']},\n",
       " {'answer_start': [195], 'text': ['Déjà Vu']},\n",
       " {'answer_start': [68], 'text': ['Michelle Obama']},\n",
       " {'answer_start': [588], 'text': ['February 2013']},\n",
       " {'answer_start': [144], 'text': ['Oprah Winfrey']},\n",
       " {'answer_start': [68], 'text': ['Michelle Obama']},\n",
       " {'answer_start': [196], 'text': ['a strong woman']},\n",
       " {'answer_start': [567], 'text': ['lyrical and raw']},\n",
       " {'answer_start': [642], 'text': ['to take control of her own career']},\n",
       " {'answer_start': [251], 'text': ['continuing inspiration']},\n",
       " {'answer_start': [57], 'text': ['First Lady Michelle Obama']},\n",
       " {'answer_start': [144], 'text': ['Oprah Winfrey']},\n",
       " {'answer_start': [431], 'text': ['Jean-Michel Basquiat']},\n",
       " {'answer_start': [621], 'text': ['Madonna']},\n",
       " {'answer_start': [53], 'text': ['Suga Mama']},\n",
       " {'answer_start': [216], 'text': ['The Mamas']},\n",
       " {'answer_start': [238],\n",
       "  'text': ['Montina Cooper-Donnell, Crystal Collins and Tiffany Moniqué Riddick']},\n",
       " {'answer_start': [3], 'text': ['2006']},\n",
       " {'answer_start': [53], 'text': ['Suga Mama']},\n",
       " {'answer_start': [53], 'text': ['Suga Mama']},\n",
       " {'answer_start': [347], 'text': ['2006 BET Awards']},\n",
       " {'answer_start': [53], 'text': ['Suga Mama']},\n",
       " {'answer_start': [53], 'text': ['Suga Mama']},\n",
       " {'answer_start': [91], 'text': [\"B'Day\"]},\n",
       " {'answer_start': [216], 'text': ['The Mamas']},\n",
       " {'answer_start': [343], 'text': ['the 2006 BET Awards']},\n",
       " {'answer_start': [36], 'text': ['stage presence and voice']},\n",
       " {'answer_start': [445], 'text': ['L.A. Reid']},\n",
       " {'answer_start': [36], 'text': ['stage presence']},\n",
       " {'answer_start': [87], 'text': ['Jarett Wieselman']},\n",
       " {'answer_start': [484], 'text': ['greatest entertainer alive']},\n",
       " {'answer_start': [393], 'text': [\"she's almost too good\"]},\n",
       " {'answer_start': [87], 'text': ['Jarett Wieselman']},\n",
       " {'answer_start': [445], 'text': ['L.A. Reid']},\n",
       " {'answer_start': [139], 'text': ['Sasha Fierce']},\n",
       " {'answer_start': [378], 'text': ['making of \"Crazy in Love\"']},\n",
       " {'answer_start': [501], 'text': ['2010']},\n",
       " {'answer_start': [712], 'text': ['Revel Presents: Beyoncé Live']},\n",
       " {'answer_start': [243], 'text': ['too aggressive, too strong']},\n",
       " {'answer_start': [679], 'text': ['she would bring her back']},\n",
       " {'answer_start': [475], 'text': ['Sasha Fierce.']},\n",
       " {'answer_start': [456], 'text': ['2008']},\n",
       " {'answer_start': [389], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [542], 'text': ['Allure magazine']},\n",
       " {'answer_start': [41], 'text': ['wide-ranging']},\n",
       " {'answer_start': [88], 'text': ['Touré']},\n",
       " {'answer_start': [389], 'text': ['Bootylicious']},\n",
       " {'answer_start': [497], 'text': [\"Destiny's Child\"]},\n",
       " {'answer_start': [389], 'text': ['Bootylicious']},\n",
       " {'answer_start': [389], 'text': ['Bootylicious']},\n",
       " {'answer_start': [543], 'text': ['2006']},\n",
       " {'answer_start': [88], 'text': ['Touré']},\n",
       " {'answer_start': [389], 'text': ['Bootylicious']},\n",
       " {'answer_start': [543], 'text': ['2006']},\n",
       " {'answer_start': [242], 'text': ['sexily']},\n",
       " {'answer_start': [43], 'text': ['modelling']},\n",
       " {'answer_start': [62],\n",
       "  'text': [\"Tom Ford's Spring/Summer 2011 fashion show\"]},\n",
       " {'answer_start': [154], 'text': ['People']},\n",
       " {'answer_start': [228], 'text': ['January 2013']},\n",
       " {'answer_start': [339], 'text': ['VH1']},\n",
       " {'answer_start': [154], 'text': ['People']},\n",
       " {'answer_start': [208], 'text': ['Complex']},\n",
       " {'answer_start': [236], 'text': ['2013']},\n",
       " {'answer_start': [357], 'text': ['number 1']},\n",
       " {'answer_start': [13], 'text': ['2010']},\n",
       " {'answer_start': [154], 'text': ['People']},\n",
       " {'answer_start': [170], 'text': ['Hottest Female Singer of All Time']},\n",
       " {'answer_start': [443], 'text': ['Madame Tussauds Wax Museums']},\n",
       " {'answer_start': [134], 'text': ['Her mother']},\n",
       " {'answer_start': [535], 'text': ['Tyra Banks']},\n",
       " {'answer_start': [188], 'text': [\"Destiny's Style\"]},\n",
       " {'answer_start': [404], 'text': ['2007']},\n",
       " {'answer_start': [535], 'text': ['Tyra Banks']},\n",
       " {'answer_start': [535], 'text': ['Tyra Banks']},\n",
       " {'answer_start': [551], 'text': ['People']},\n",
       " {'answer_start': [0], 'text': ['The Bey Hive']},\n",
       " {'answer_start': [83], 'text': ['The Beyontourage']},\n",
       " {'answer_start': [321], 'text': ['Twitter']},\n",
       " {'answer_start': [4], 'text': ['Bey Hive']},\n",
       " {'answer_start': [87], 'text': ['Beyontourage']},\n",
       " {'answer_start': [4], 'text': ['Bey Hive']},\n",
       " {'answer_start': [87], 'text': ['Beyontourage']},\n",
       " {'answer_start': [184], 'text': ['beehive']},\n",
       " {'answer_start': [158], 'text': ['House of Deréon']},\n",
       " {'answer_start': [237], 'text': [\"L'Officiel\"]},\n",
       " {'answer_start': [252], 'text': ['blackface and tribal makeup']},\n",
       " {'answer_start': [3], 'text': ['2006']},\n",
       " {'answer_start': [111], 'text': ['for wearing and using fur']},\n",
       " {'answer_start': [237], 'text': [\"L'Officiel\"]},\n",
       " {'answer_start': [249], 'text': ['in blackface and tribal makeup']},\n",
       " {'answer_start': [237], 'text': [\"L'Officiel\"]},\n",
       " {'answer_start': [158], 'text': ['House of Deréon.']},\n",
       " {'answer_start': [213], 'text': ['French fashion magazine']},\n",
       " {'answer_start': [80], 'text': ['African-American']},\n",
       " {'answer_start': [108], 'text': ['Emmett Price']},\n",
       " {'answer_start': [335], 'text': [\"L'Oréal\"]},\n",
       " {'answer_start': [615], 'text': ['natural pictures be used']},\n",
       " {'answer_start': [436], 'text': ['it is categorically untrue']},\n",
       " {'answer_start': [33], 'text': ['costuming']},\n",
       " {'answer_start': [108], 'text': ['Emmett Price']},\n",
       " {'answer_start': [335], 'text': [\"L'Oréal\"]},\n",
       " {'answer_start': [386], 'text': ['Feria hair color advertisements']},\n",
       " {'answer_start': [505], 'text': ['H&M']},\n",
       " {'answer_start': [215], 'text': ['The Guardian']},\n",
       " {'answer_start': [700], 'text': ['2013']},\n",
       " {'answer_start': [1078], 'text': ['2014']},\n",
       " {'answer_start': [238], 'text': ['Artist of the Decade']},\n",
       " {'answer_start': [700], 'text': ['2013']},\n",
       " {'answer_start': [1078], 'text': ['2014']},\n",
       " {'answer_start': [738], 'text': ['Baz Luhrmann']},\n",
       " {'answer_start': [31], 'text': ['Jody Rosen']},\n",
       " {'answer_start': [215], 'text': ['The Guardian']},\n",
       " {'answer_start': [723], 'text': ['Time 100 list']},\n",
       " {'answer_start': [738], 'text': ['Baz Luhrmann']},\n",
       " {'answer_start': [1078], 'text': ['2014']},\n",
       " {'answer_start': [292], 'text': ['White Rabbits']},\n",
       " {'answer_start': [385], 'text': ['Gwyneth Paltrow']},\n",
       " {'answer_start': [562], 'text': ['Pepsi']},\n",
       " {'answer_start': [552], 'text': [\"Beyoncé's Pepsi commercial\"]},\n",
       " {'answer_start': [292], 'text': ['White Rabbits']},\n",
       " {'answer_start': [10], 'text': ['work']},\n",
       " {'answer_start': [501], 'text': ['Country Strong']},\n",
       " {'answer_start': [292], 'text': ['White Rabbits']},\n",
       " {'answer_start': [358], 'text': ['Milk Famous']},\n",
       " {'answer_start': [385], 'text': ['Gwyneth Paltrow']},\n",
       " {'answer_start': [501], 'text': ['Country Strong.']},\n",
       " {'answer_start': [517], 'text': ['Nicki Minaj']},\n",
       " {'answer_start': [19], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [225], 'text': ['two']},\n",
       " {'answer_start': [304], 'text': ['8 million']},\n",
       " {'answer_start': [959], 'text': ['fly']},\n",
       " {'answer_start': [1073], 'text': ['July 2014']},\n",
       " {'answer_start': [19], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [218], 'text': ['earned two Grammy Awards']},\n",
       " {'answer_start': [297], 'text': ['around 8 million copies']},\n",
       " {'answer_start': [702], 'text': ['Drake']},\n",
       " {'answer_start': [155], 'text': ['Rolling Stone']},\n",
       " {'answer_start': [702], 'text': ['Drake']},\n",
       " {'answer_start': [940], 'text': ['a species of horse fly']},\n",
       " {'answer_start': [73], 'text': ['15 million']},\n",
       " {'answer_start': [111], 'text': ['118 million']},\n",
       " {'answer_start': [387], 'text': ['64']},\n",
       " {'answer_start': [152], 'text': ['60 million']},\n",
       " {'answer_start': [0], 'text': ['Beyoncé']},\n",
       " {'answer_start': [73], 'text': ['15 million']},\n",
       " {'answer_start': [111], 'text': ['118 million']},\n",
       " {'answer_start': [152], 'text': ['60 million']},\n",
       " {'answer_start': [1052], 'text': ['2008 World Music Awards']},\n",
       " {'answer_start': [387], 'text': ['64 certifications']},\n",
       " {'answer_start': [68], 'text': ['over 15 million']},\n",
       " {'answer_start': [106], 'text': ['over 118 million']},\n",
       " {'answer_start': [261],\n",
       "  'text': ['The Recording Industry Association of America']},\n",
       " {'answer_start': [387], 'text': ['64']},\n",
       " {'answer_start': [1048], 'text': ['the 2008 World Music Awards']},\n",
       " {'answer_start': [16], 'text': ['20']},\n",
       " {'answer_start': [159], 'text': ['Alison Krauss']},\n",
       " {'answer_start': [231], 'text': ['52']},\n",
       " {'answer_start': [586], 'text': ['six']},\n",
       " {'answer_start': [949], 'text': ['two']},\n",
       " {'answer_start': [16], 'text': ['20 Grammy Awards']},\n",
       " {'answer_start': [231], 'text': ['52 nominations']},\n",
       " {'answer_start': [306], 'text': ['2010']},\n",
       " {'answer_start': [705], 'text': ['Adele']},\n",
       " {'answer_start': [16], 'text': ['20']},\n",
       " {'answer_start': [231], 'text': ['52']},\n",
       " {'answer_start': [247], 'text': ['\"Single Ladies (Put a Ring on It)\"']},\n",
       " {'answer_start': [756], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [24], 'text': ['Pepsi']},\n",
       " {'answer_start': [172], 'text': ['50 million']},\n",
       " {'answer_start': [206],\n",
       "  'text': ['The Center for Science in the Public Interest (CSPINET)']},\n",
       " {'answer_start': [535], 'text': ['70']},\n",
       " {'answer_start': [36], 'text': ['2002']},\n",
       " {'answer_start': [101],\n",
       "  'text': ['Britney Spears, Pink, and Enrique Iglesias']},\n",
       " {'answer_start': [191], 'text': ['endorse Pepsi']},\n",
       " {'answer_start': [210],\n",
       "  'text': ['Center for Science in the Public Interest']},\n",
       " {'answer_start': [24], 'text': ['Pepsi']},\n",
       " {'answer_start': [171], 'text': ['$50 million']},\n",
       " {'answer_start': [206],\n",
       "  'text': ['The Center for Science in the Public Interest (CSPINET)']},\n",
       " {'answer_start': [437], 'text': ['NetBase']},\n",
       " {'answer_start': [24], 'text': ['Tommy Hilfiger']},\n",
       " {'answer_start': [0], 'text': ['Beyoncé']},\n",
       " {'answer_start': [247], 'text': ['Heat']},\n",
       " {'answer_start': [577], 'text': ['2013']},\n",
       " {'answer_start': [750], 'text': ['400 million']},\n",
       " {'answer_start': [247], 'text': ['Heat']},\n",
       " {'answer_start': [452], 'text': ['2011']},\n",
       " {'answer_start': [535], 'text': ['Pulse']},\n",
       " {'answer_start': [654], 'text': ['six editions']},\n",
       " {'answer_start': [172], 'text': ['Diamonds']},\n",
       " {'answer_start': [255], 'text': ['2010.']},\n",
       " {'answer_start': [247], 'text': ['Heat']},\n",
       " {'answer_start': [654], 'text': ['six']},\n",
       " {'answer_start': [450], 'text': ['18']},\n",
       " {'answer_start': [28], 'text': ['Starpower: Beyoncé']},\n",
       " {'answer_start': [433], 'text': ['since the age of 18']},\n",
       " {'answer_start': [168], 'text': ['70 staff']},\n",
       " {'answer_start': [236], 'text': ['out of court']},\n",
       " {'answer_start': [28], 'text': ['Starpower: Beyoncé']},\n",
       " {'answer_start': [28], 'text': ['Starpower: Beyoncé']},\n",
       " {'answer_start': [109], 'text': ['GateFive']},\n",
       " {'answer_start': [168], 'text': ['70']},\n",
       " {'answer_start': [267], 'text': ['June 2013']},\n",
       " {'answer_start': [136], 'text': ['fashion retailer Topshop']},\n",
       " {'answer_start': [209], 'text': ['Parkwood Topshop Athletic Ltd']},\n",
       " {'answer_start': [299], 'text': ['activewear']},\n",
       " {'answer_start': [698], 'text': ['fall of 2015']},\n",
       " {'answer_start': [153], 'text': ['Topshop']},\n",
       " {'answer_start': [706], 'text': ['2015']},\n",
       " {'answer_start': [75], 'text': ['Parkwood Entertainment']},\n",
       " {'answer_start': [153], 'text': ['Topshop']},\n",
       " {'answer_start': [123], 'text': ['London']},\n",
       " {'answer_start': [299], 'text': ['activewear']},\n",
       " {'answer_start': [3], 'text': ['March 30, 2015']},\n",
       " {'answer_start': [230], 'text': ['Jay Z']},\n",
       " {'answer_start': [3], 'text': ['March 30, 2015']},\n",
       " {'answer_start': [105], 'text': ['music streaming service']},\n",
       " {'answer_start': [763], 'text': ['low payout of royalties']},\n",
       " {'answer_start': [129], 'text': ['Tidal.']},\n",
       " {'answer_start': [274], 'text': ['Aspiro']},\n",
       " {'answer_start': [230], 'text': ['Jay Z']},\n",
       " {'answer_start': [717], 'text': ['Spotify']},\n",
       " {'answer_start': [12], 'text': ['her mother']},\n",
       " {'answer_start': [218], 'text': ['Agnèz Deréon']},\n",
       " {'answer_start': [408], 'text': ['Beyond Productions']},\n",
       " {'answer_start': [670],\n",
       "  'text': ['sportswear, denim offerings with fur, outerwear and accessories that include handbags and footwear']},\n",
       " {'answer_start': [834], 'text': ['US and Canada']},\n",
       " {'answer_start': [12], 'text': ['her mother']},\n",
       " {'answer_start': [91], 'text': ['2005']},\n",
       " {'answer_start': [205], 'text': ['grandmother, Agnèz Deréon']},\n",
       " {'answer_start': [572], 'text': [\"in Destiny's Child's shows and tours\"]},\n",
       " {'answer_start': [12], 'text': ['her mother']},\n",
       " {'answer_start': [526], 'text': ['Deréon.']},\n",
       " {'answer_start': [51], 'text': ['shoe']},\n",
       " {'answer_start': [741], 'text': ['Brazil']},\n",
       " {'answer_start': [294], 'text': ['2009']},\n",
       " {'answer_start': [258], 'text': ['House of Deréon collection']},\n",
       " {'answer_start': [360], 'text': ['Sasha Fierce for Deréon']},\n",
       " {'answer_start': [638], 'text': ['May 27, 2010']},\n",
       " {'answer_start': [32], 'text': ['House of Brands']},\n",
       " {'answer_start': [159], 'text': ['Beyoncé Fashion Diva']},\n",
       " {'answer_start': [360], 'text': ['Sasha Fierce for Deréon']},\n",
       " {'answer_start': [690], 'text': ['C&A']},\n",
       " {'answer_start': [570], 'text': [\"Dillard's\"]},\n",
       " {'answer_start': [110], 'text': ['Topshop']},\n",
       " {'answer_start': [250], 'text': ['autumn 2015']},\n",
       " {'answer_start': [147], 'text': ['Parkwood Topshop Athletic Ltd']},\n",
       " {'answer_start': [126], 'text': ['50']},\n",
       " {'answer_start': [287], 'text': ['April 2016']},\n",
       " {'answer_start': [110], 'text': ['Topshop']},\n",
       " {'answer_start': [147], 'text': ['Parkwood Topshop Athletic Ltd']},\n",
       " {'answer_start': [52], 'text': ['activewear']},\n",
       " {'answer_start': [6], 'text': ['Hurricane Katrina']},\n",
       " {'answer_start': [191], 'text': ['250,000']},\n",
       " {'answer_start': [321], 'text': ['Ike']},\n",
       " {'answer_start': [61], 'text': ['the Survivor Foundation']},\n",
       " ...]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "acute-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 1, 2, 3, 4]\n",
      "1 [0]\n",
      "1 [0, 1, 2, 3, 4]\n",
      "2 [0, 1]\n",
      "2 [0, 1, 2, 3, 4]\n",
      "3 [0, 1, 2]\n",
      "3 [0, 1, 2, 3, 4]\n",
      "4 [0, 1, 2, 3]\n",
      "4 [0, 1, 2, 3, 4]\n",
      "5 [5, 6, 7, 8, 9]\n",
      "6 [5]\n",
      "6 [5, 6, 7, 8, 9]\n",
      "7 [5, 6]\n",
      "7 [5, 6, 7, 8, 9]\n",
      "8 [5, 6, 7]\n",
      "8 [5, 6, 7, 8, 9]\n",
      "9 [5, 6, 7, 8]\n",
      "9 [5, 6, 7, 8, 9]\n",
      "10 [10, 11, 12, 13, 14]\n",
      "11 [10]\n",
      "11 [10, 11, 12, 13, 14]\n",
      "12 [10, 11]\n",
      "12 [10, 11, 12, 13, 14]\n",
      "13 [10, 11, 12]\n",
      "13 [10, 11, 12, 13, 14]\n",
      "14 [10, 11, 12, 13]\n",
      "14 [10, 11, 12, 13, 14]\n",
      "15 [15, 16, 17, 18, 19]\n",
      "16 [15]\n",
      "16 [15, 16, 17, 18, 19]\n",
      "17 [15, 16]\n",
      "17 [15, 16, 17, 18, 19]\n",
      "18 [15, 16, 17]\n",
      "18 [15, 16, 17, 18, 19]\n",
      "19 [15, 16, 17, 18]\n",
      "19 [15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "def get_span(index, span=5):\n",
    "    \"\"\"\n",
    "    Returns the value in a range for whole numbers\n",
    "    \n",
    "    Ex: index=4, span=5\n",
    "        lower=0, upper=5\n",
    "        \n",
    "        index=8, span=5\n",
    "        lower=5, upper=10\n",
    "    \"\"\"\n",
    "    lower_bound = (index)//span\n",
    "    lower_bound = lower_bound*span\n",
    "    upper_bound = lower_bound+span\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "lst = list(range(20))\n",
    "\n",
    "for index in range(20):\n",
    "    low, high = get_span(index, span=5)\n",
    "    if index != low:\n",
    "        start = lst[low:index] # + example['start'][index]\n",
    "        print(index, start)\n",
    "        # example['start'][index] = sum(lst[low:index])  + example['start'][index]\n",
    "    print(index, lst[low:high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "checked-entry",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-76c72db8cca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-herald",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "destroyed-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nlp.load_from_disk(\"squad_concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "previous-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "    num_rows: 17520\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "passing-analyst",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
       " {'answer_start': [943], 'text': ['September 1876']},\n",
       " {'answer_start': [2219], 'text': ['Rome']},\n",
       " {'answer_start': [3291], 'text': ['eight']},\n",
       " {'answer_start': [4024], 'text': ['Learning Resource Center']},\n",
       " {'answer_start': [624], 'text': ['Master of Divinity']},\n",
       " {'answer_start': [1893],\n",
       "  'text': ['President Emeritus of the University of Notre Dame']},\n",
       " {'answer_start': [2187], 'text': ['Theodore M. Hesburgh Library']},\n",
       " {'answer_start': [2699], 'text': ['19.7%']},\n",
       " {'answer_start': [3885], 'text': ['8th']},\n",
       " {'answer_start': [353], 'text': ['1851–1921']},\n",
       " {'answer_start': [1169], 'text': ['Professor Jerome Green']},\n",
       " {'answer_start': [2512], 'text': ['the 1940s']},\n",
       " {'answer_start': [2879], 'text': ['German Catholic journals']},\n",
       " {'answer_start': [3822], 'text': ['International Peace studies']},\n",
       " {'answer_start': [1446], 'text': ['over 700']},\n",
       " {'answer_start': [1976], 'text': ['15']},\n",
       " {'answer_start': [3148], 'text': ['over 100 times']},\n",
       " {'answer_start': [4336], 'text': ['Rev. William Corby']},\n",
       " {'answer_start': [5120], 'text': ['Father James Burns']},\n",
       " {'answer_start': [354], 'text': ['1925']},\n",
       " {'answer_start': [1941], 'text': ['Fr. Matthew Walsh']},\n",
       " {'answer_start': [2587], 'text': ['Laetare Medal']},\n",
       " {'answer_start': [3759], 'text': ['Hall of Liberal Arts']},\n",
       " {'answer_start': [4348], 'text': ['$9 million']},\n",
       " {'answer_start': [921], 'text': ['Vice President of Student Affairs']},\n",
       " {'answer_start': [1803], 'text': ['$350 million']},\n",
       " {'answer_start': [2310], 'text': ['Malloy']},\n",
       " {'answer_start': [3171], 'text': ['French Revival']},\n",
       " {'answer_start': [3907], 'text': ['Joseph LaFortune']},\n",
       " {'answer_start': [398], 'text': ['almost 4 million']},\n",
       " {'answer_start': [2382], 'text': ['Sustainable Endowments Institute']},\n",
       " {'answer_start': [2883], 'text': ['1998']},\n",
       " {'answer_start': [3708], 'text': ['33']},\n",
       " {'answer_start': [4126], 'text': ['over 1,200']},\n",
       " {'answer_start': [624], 'text': ['Driehaus Architecture Prize']},\n",
       " {'answer_start': [652], 'text': ['The rise of Hitler and other dictators']},\n",
       " {'answer_start': [1452], 'text': ['University of Notre Dame du']},\n",
       " {'answer_start': [2027], 'text': ['its Fighting Irish football team']},\n",
       " {'answer_start': [2900], 'text': ['among the top twenty']},\n",
       " {'answer_start': [3], 'text': ['1842']},\n",
       " {'answer_start': [620], 'text': ['1849']},\n",
       " {'answer_start': [1189], 'text': ['NDtv']},\n",
       " {'answer_start': [1841], 'text': ['June 3, 2008']},\n",
       " {'answer_start': [2534], 'text': ['Horizon League']},\n",
       " {'answer_start': [382], 'text': ['five']},\n",
       " {'answer_start': [1906], 'text': ['almost $100 million']},\n",
       " {'answer_start': [2771], 'text': ['1887']},\n",
       " {'answer_start': [3900], 'text': ['the Army team']},\n",
       " {'answer_start': [5172], 'text': [\"the Drummers' Circle\"]},\n",
       " {'answer_start': [59], 'text': ['12']},\n",
       " {'answer_start': [1893], 'text': ['1904']},\n",
       " {'answer_start': [2760], 'text': ['Airplane!']},\n",
       " {'answer_start': [3348], 'text': ['Eric F. Wieschaus']},\n",
       " {'answer_start': [4523], 'text': ['singing and dancing']},\n",
       " {'answer_start': [505], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [694], 'text': ['Beyoncé Giselle Knowles-Carter']},\n",
       " {'answer_start': [1978], 'text': ['five']},\n",
       " {'answer_start': [2451], 'text': ['Jay Z']},\n",
       " {'answer_start': [3504], 'text': ['Cadillac Records']},\n",
       " {'answer_start': [466], 'text': ['Sasha Fierce']},\n",
       " {'answer_start': [2001], 'text': ['Forbes']},\n",
       " {'answer_start': [2471], 'text': ['118 million']},\n",
       " {'answer_start': [3470], 'text': ['African-American']},\n",
       " {'answer_start': [4278], 'text': ['Joseph Broussard']},\n",
       " {'answer_start': [578], 'text': ['Methodist']},\n",
       " {'answer_start': [1309], 'text': [\"St. John's United Methodist Church\"]},\n",
       " {'answer_start': [1726], 'text': ['seven']},\n",
       " {'answer_start': [2447], 'text': ['Arne Frager']},\n",
       " {'answer_start': [3522], 'text': ['eight']},\n",
       " {'answer_start': [215], 'text': ['Men in Black']},\n",
       " {'answer_start': [1566], 'text': ['Men in Black']},\n",
       " {'answer_start': [3032], 'text': ['No, No, No']},\n",
       " {'answer_start': [4767], 'text': ['her mother']},\n",
       " {'answer_start': [5034], 'text': ['Beyoncé']},\n",
       " {'answer_start': [348], 'text': ['MTV']},\n",
       " {'answer_start': [1522], 'text': ['Carmen: A Hip Hopera']},\n",
       " {'answer_start': [2619], 'text': ['UK, Norway, and Belgium']},\n",
       " {'answer_start': [3375], 'text': ['73 million']},\n",
       " {'answer_start': [4100], 'text': ['Foxxy Cleopatra']},\n",
       " {'answer_start': [193], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [1251], 'text': ['Dangerously in Love']},\n",
       " {'answer_start': [2590], 'text': ['Crazy in Love']},\n",
       " {'answer_start': [3177], 'text': ['November 2003']},\n",
       " {'answer_start': [4491], 'text': ['Missy Elliott and Alicia Keys']},\n",
       " {'answer_start': [346], 'text': ['five']},\n",
       " {'answer_start': [714], 'text': [\"B'Day\"]},\n",
       " {'answer_start': [1543], 'text': ['Dreamgirls']},\n",
       " {'answer_start': [2905], 'text': ['The Beyoncé Experience']},\n",
       " {'answer_start': [3862], 'text': ['The Beyoncé Experience']},\n",
       " {'answer_start': [1567], 'text': ['Taylor Swift']},\n",
       " {'answer_start': [3776], 'text': ['119.5 million']},\n",
       " {'answer_start': [5401], 'text': ['Kanye West']},\n",
       " {'answer_start': [6786], 'text': ['MTV Movie Award for Best Fight']},\n",
       " {'answer_start': [6886], 'text': ['Etta James']},\n",
       " {'answer_start': [242], 'text': ['Lauryn Hill']},\n",
       " {'answer_start': [1066], 'text': ['Telephone']},\n",
       " {'answer_start': [1630], 'text': ['Lauryn Hill']},\n",
       " {'answer_start': [2382], 'text': ['the Great Wall of China']},\n",
       " {'answer_start': [2527], 'text': ['a hiatus']},\n",
       " {'answer_start': [367], 'text': ['Clinton Bush Haiti Fund']},\n",
       " {'answer_start': [606], 'text': ['2011']},\n",
       " {'answer_start': [1573], 'text': ['Clinton Bush Haiti Fund.']},\n",
       " {'answer_start': [2528], 'text': [\"New York's Roseland Ballroom\"]},\n",
       " {'answer_start': [2725], 'text': ['4']},\n",
       " {'answer_start': [3], 'text': ['January 7, 2012']},\n",
       " {'answer_start': [371], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [691], 'text': ['Lenox Hill Hospital in New York.']},\n",
       " {'answer_start': [2063], 'text': ['global publishing agreement']},\n",
       " {'answer_start': [2194], 'text': ['January 2013']},\n",
       " {'answer_start': [103], 'text': ['132']},\n",
       " {'answer_start': [989], 'text': ['2013 Met Gala']},\n",
       " {'answer_start': [1468], 'text': ['Back to Black']},\n",
       " {'answer_start': [1858], 'text': ['the iTunes Store']},\n",
       " {'answer_start': [3842], 'text': ['one million']},\n",
       " {'answer_start': [364], 'text': ['Vogue']},\n",
       " {'answer_start': [1211], 'text': ['six awards']},\n",
       " {'answer_start': [2376], 'text': ['three']},\n",
       " {'answer_start': [3556], 'text': ['Formation']},\n",
       " {'answer_start': [3570], 'text': ['February 6, 2016']},\n",
       " {'answer_start': [62], 'text': ['Jay Z']},\n",
       " {'answer_start': [1012], 'text': [\"'03 Bonnie & Clyde\"]},\n",
       " {'answer_start': [1876], 'text': ['MTV Video Music Awards']},\n",
       " {'answer_start': [3243], 'text': ['most tweets per second']},\n",
       " {'answer_start': [3953], 'text': ['12.4 million']},\n",
       " {'answer_start': [74], 'text': ['Lenox Hill Hospital']},\n",
       " {'answer_start': [666], 'text': ['Blue Ivy Carter']},\n",
       " {'answer_start': [1336], 'text': ['America the Beautiful']},\n",
       " {'answer_start': [2268], 'text': ['America the Beautiful']},\n",
       " {'answer_start': [3602], 'text': ['Ban Bossy campaign']},\n",
       " {'answer_start': [586], 'text': ['leadership in girls']},\n",
       " {'answer_start': [797], 'text': ['women']},\n",
       " {'answer_start': [1430], 'text': ['September 2015']},\n",
       " {'answer_start': [1529], 'text': ['Freddie Gray']},\n",
       " {'answer_start': [2743], 'text': ['highest-earning power couple']},\n",
       " {'answer_start': [1112], 'text': ['2011']},\n",
       " {'answer_start': [3319], 'text': ['MTV']},\n",
       " {'answer_start': [4330], 'text': ['hip hop']},\n",
       " {'answer_start': [4873], 'text': ['four']},\n",
       " {'answer_start': [5966], 'text': ['pop, soul and funk']},\n",
       " {'answer_start': [267], 'text': ['English']},\n",
       " {'answer_start': [1043], 'text': ['Rudy Perez.']},\n",
       " {'answer_start': [1363], 'text': ['man-tending anthems']},\n",
       " {'answer_start': [2248], 'text': ['melodies and ideas']},\n",
       " {'answer_start': [2317], 'text': ['2001']},\n",
       " {'answer_start': [128],\n",
       "  'text': ['the American Society of Composers, Authors, and Publishers Pop Music Awards.']},\n",
       " {'answer_start': [832], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [1598], 'text': ['Michael Jackson']},\n",
       " {'answer_start': [2484], 'text': ['Josephine Baker']},\n",
       " {'answer_start': [3195], 'text': ['Josephine Baker.']},\n",
       " {'answer_start': [68], 'text': ['Michelle Obama']},\n",
       " {'answer_start': [919], 'text': ['First Lady Michelle Obama']},\n",
       " {'answer_start': [1940], 'text': ['The Mamas']},\n",
       " {'answer_start': [2710], 'text': ['2006 BET Awards']},\n",
       " {'answer_start': [3345], 'text': ['the 2006 BET Awards']},\n",
       " {'answer_start': [484], 'text': ['greatest entertainer alive']},\n",
       " {'answer_start': [1010], 'text': ['making of \"Crazy in Love\"']},\n",
       " {'answer_start': [1871], 'text': ['Sasha Fierce.']},\n",
       " {'answer_start': [2248], 'text': ['Touré']},\n",
       " {'answer_start': [3298], 'text': ['2006']},\n",
       " {'answer_start': [43], 'text': ['modelling']},\n",
       " {'answer_start': [738], 'text': ['People']},\n",
       " {'answer_start': [1322], 'text': ['People']},\n",
       " {'answer_start': [1940], 'text': [\"Destiny's Style\"]},\n",
       " {'answer_start': [2368], 'text': ['The Bey Hive']},\n",
       " {'answer_start': [4], 'text': ['Bey Hive']},\n",
       " {'answer_start': [625], 'text': ['blackface and tribal makeup']},\n",
       " {'answer_start': [1099], 'text': [\"L'Officiel\"]},\n",
       " {'answer_start': [1686], 'text': [\"L'Oréal\"]},\n",
       " {'answer_start': [2327], 'text': [\"L'Oréal\"]},\n",
       " {'answer_start': [1078], 'text': ['2014']},\n",
       " {'answer_start': [1200], 'text': ['Jody Rosen']},\n",
       " {'answer_start': [2630], 'text': ['White Rabbits']},\n",
       " {'answer_start': [2999], 'text': ['work']},\n",
       " {'answer_start': [4141], 'text': ['Country Strong.']},\n",
       " {'answer_start': [959], 'text': ['fly']},\n",
       " {'answer_start': [2041], 'text': ['Drake']},\n",
       " {'answer_start': [2789], 'text': ['118 million']},\n",
       " {'answer_start': [3935], 'text': ['118 million']},\n",
       " {'answer_start': [5076], 'text': ['over 118 million']},\n",
       " {'answer_start': [159], 'text': ['Alison Krauss']},\n",
       " {'answer_start': [1344], 'text': ['52 nominations']},\n",
       " {'answer_start': [2473], 'text': ['\"Single Ladies (Put a Ring on It)\"']},\n",
       " {'answer_start': [3874], 'text': ['70']},\n",
       " {'answer_start': [3969], 'text': ['Pepsi']},\n",
       " {'answer_start': [0], 'text': ['Beyoncé']},\n",
       " {'answer_start': [1214], 'text': ['2011']},\n",
       " {'answer_start': [1771], 'text': ['Heat']},\n",
       " {'answer_start': [2454], 'text': ['70 staff']},\n",
       " {'answer_start': [2907], 'text': ['70']},\n",
       " {'answer_start': [698], 'text': ['fall of 2015']},\n",
       " {'answer_start': [834], 'text': ['London']},\n",
       " {'answer_start': [1527], 'text': ['music streaming service']},\n",
       " {'answer_start': [3047], 'text': ['Spotify']},\n",
       " {'answer_start': [4072], 'text': ['US and Canada']},\n",
       " {'answer_start': [12], 'text': ['her mother']},\n",
       " {'answer_start': [1106], 'text': ['House of Deréon collection']},\n",
       " {'answer_start': [2091], 'text': ['Sasha Fierce for Deréon']},\n",
       " {'answer_start': [2761], 'text': ['Parkwood Topshop Athletic Ltd']},\n",
       " {'answer_start': [2964], 'text': ['activewear']},\n",
       " {'answer_start': [190], 'text': ['$250,000']},\n",
       " {'answer_start': [367], 'text': ['George Clooney and Wyclef Jean']},\n",
       " {'answer_start': [2102],\n",
       "  'text': [\"New York Police and Fire Widows' and Children's Benefit Fund\"]},\n",
       " {'answer_start': [2443], 'text': ['Sandy Hook Elementary School shooting']},\n",
       " {'answer_start': [4171], 'text': ['Sandy Hook Elementary School shooting.']},\n",
       " {'answer_start': [412], 'text': ['I Was Here']},\n",
       " {'answer_start': [2318], 'text': ['77']},\n",
       " {'answer_start': [3078], 'text': ['grizzly bear']},\n",
       " {'answer_start': [3422], 'text': ['1865']},\n",
       " {'answer_start': [4577], 'text': ['Billings']},\n",
       " {'answer_start': [502], 'text': ['Wyoming']},\n",
       " {'answer_start': [1142], 'text': ['Hudson Bay.']},\n",
       " {'answer_start': [1502], 'text': ['1996']},\n",
       " {'answer_start': [2236], 'text': ['60 percent']},\n",
       " {'answer_start': [2609], 'text': ['1880s']},\n",
       " {'answer_start': [259], 'text': ['Federation of Fly Fishers']},\n",
       " {'answer_start': [1474], 'text': ['$1.75']},\n",
       " {'answer_start': [3204], 'text': ['Pacific Ocean']},\n",
       " {'answer_start': [3435], 'text': ['north']},\n",
       " {'answer_start': [4232], 'text': ['Missouri river']},\n",
       " {'answer_start': [609], 'text': ['at least 17']},\n",
       " {'answer_start': [968], 'text': ['6.9 percent']},\n",
       " {'answer_start': [1960], 'text': ['Great Falls']},\n",
       " {'answer_start': [3369], 'text': ['Big Horn, Glacier, and Roosevelt']},\n",
       " {'answer_start': [4422], 'text': ['1855']},\n",
       " {'answer_start': [63], 'text': ['on the Missouri River']},\n",
       " {'answer_start': [1150], 'text': ['Spanish']},\n",
       " {'answer_start': [2615], 'text': ['2.9']},\n",
       " {'answer_start': [3150], 'text': ['1917']},\n",
       " {'answer_start': [3861], 'text': ['General Philip Sheridan']},\n",
       " {'answer_start': [572], 'text': ['1876']},\n",
       " {'answer_start': [1046], 'text': ['1889']},\n",
       " {'answer_start': [1673], 'text': ['1877']},\n",
       " {'answer_start': [2627], 'text': ['1909']},\n",
       " {'answer_start': [4052], 'text': ['200']},\n",
       " {'answer_start': [695],\n",
       "  'text': ['First Special Service Force or \"Devil\\'s Brigade,\"']},\n",
       " {'answer_start': [1426], 'text': ['Prosecutor v. Radislav Krstic']},\n",
       " {'answer_start': [2670], 'text': ['Convention States municipal laws']},\n",
       " {'answer_start': [3164], 'text': ['United Nations General Assembly']},\n",
       " {'answer_start': [4082], 'text': ['William Schabas']},\n",
       " {'answer_start': [404], 'text': ['biological-physical']},\n",
       " {'answer_start': [1244], 'text': ['\"ritualcide\"']},\n",
       " {'answer_start': [1490], 'text': ['a crime']},\n",
       " {'answer_start': [2995],\n",
       "  'text': ['ethnic, national, racial and in some instances religious groups']},\n",
       " {'answer_start': [3512], 'text': ['Raphael Lemkin']},\n",
       " {'answer_start': [435],\n",
       "  'text': ['Greek prefix geno- (meaning tribe or race) and caedere (the Latin word for to kill)']},\n",
       " {'answer_start': [1227], 'text': ['prominence within the group']},\n",
       " {'answer_start': [2025], 'text': ['inform the analysis']},\n",
       " {'answer_start': [2647], 'text': ['four']},\n",
       " {'answer_start': [2751], 'text': ['Jonassohn and Björnson']},\n",
       " {'answer_start': [17], 'text': ['social and political groups']},\n",
       " {'answer_start': [983], 'text': ['policies']},\n",
       " {'answer_start': [2117], 'text': ['murder by government']},\n",
       " {'answer_start': [2993], 'text': ['Adrian Gallagher']},\n",
       " {'answer_start': [3664], 'text': ['acts of genocide']},\n",
       " {'answer_start': [127],\n",
       "  'text': ['Convention on the Prevention and Punishment of the Crime of Genocide']},\n",
       " {'answer_start': [772], 'text': ['European Court of Human Rights']},\n",
       " {'answer_start': [1740], 'text': ['About 30']},\n",
       " {'answer_start': [2787], 'text': ['He died']},\n",
       " {'answer_start': [3450],\n",
       "  'text': ['International Criminal Tribunal for Rwanda (ICTR)']},\n",
       " {'answer_start': [49], 'text': ['situation in Darfur']},\n",
       " {'answer_start': [1210],\n",
       "  'text': ['Prosecutor of the International Criminal Court']},\n",
       " {'answer_start': [1860], 'text': ['psychological and social']},\n",
       " {'answer_start': [3115], 'text': ['evolution']},\n",
       " {'answer_start': [4470], 'text': ['1943']},\n",
       " {'answer_start': [385], 'text': ['division of bacterial cells']},\n",
       " {'answer_start': [1241], 'text': ['penicillins and cephalosporins']},\n",
       " {'answer_start': [2495], 'text': ['polymyxins']},\n",
       " {'answer_start': [3779], 'text': ['aminoglycosides']},\n",
       " {'answer_start': [4302], 'text': ['fungi']},\n",
       " {'answer_start': [631], 'text': ['anyone, of any age, in any country']},\n",
       " {'answer_start': [747], 'text': ['vaccination']},\n",
       " {'answer_start': [1377], 'text': ['20th century']},\n",
       " {'answer_start': [2524], 'text': ['laboratory']},\n",
       " {'answer_start': [2557],\n",
       "  'text': ['a patient has proven or suspected infection, but the responsible microorganism is not yet unidentified']},\n",
       " {'answer_start': [1258],\n",
       "  'text': ['a quinolone antibiotic with a systemic corticosteroid']},\n",
       " {'answer_start': [2125], 'text': ['Adverse effects']},\n",
       " {'answer_start': [3982], 'text': ['overgrowth of yeast']},\n",
       " {'answer_start': [5256], 'text': ['unclear']},\n",
       " {'answer_start': [6040],\n",
       "  'text': ['The majority of studies indicate antibiotics do interfere with contraceptive pills']},\n",
       " {'answer_start': [63], 'text': ['contraceptive pills']},\n",
       " {'answer_start': [1596], 'text': ['extra contraceptive measures']},\n",
       " {'answer_start': [2290], 'text': ['widespread']},\n",
       " {'answer_start': [2542],\n",
       "  'text': ['specific types of antibiotics with which alcohol consumption may cause serious side-effects']},\n",
       " {'answer_start': [3453], 'text': ['vertical transmission']},\n",
       " {'answer_start': [214], 'text': ['tuberculosis']},\n",
       " {'answer_start': [1209], 'text': ['overuse of antibiotics']},\n",
       " {'answer_start': [2148], 'text': ['prescribe antibiotics']},\n",
       " {'answer_start': [2429], 'text': ['Swann report 1969']},\n",
       " {'answer_start': [3753], 'text': ['1977']},\n",
       " {'answer_start': [727], 'text': ['against life']},\n",
       " {'answer_start': [2192], 'text': ['chemotherapy']},\n",
       " {'answer_start': [2552], 'text': ['tyrothricin']},\n",
       " {'answer_start': [3098], 'text': ['1942']},\n",
       " {'answer_start': [4282], 'text': ['immune modulation or augmentation']},\n",
       " {'answer_start': [801], 'text': ['phages will infect \"good\" bacteria']},\n",
       " {'answer_start': [1233], 'text': ['economic incentives']},\n",
       " {'answer_start': [2527], 'text': ['solo piano']},\n",
       " {'answer_start': [3626], 'text': ['Warsaw']},\n",
       " {'answer_start': [4225], 'text': ['solo piano']},\n",
       " {'answer_start': [276], 'text': ['Romantic']},\n",
       " {'answer_start': [1475], 'text': ['Majorca']},\n",
       " {'answer_start': [2216], 'text': ['1835']},\n",
       " {'answer_start': [3526], 'text': ['Jane Stirling']},\n",
       " {'answer_start': [4045], 'text': ['instrumental ballade']},\n",
       " {'answer_start': [340], 'text': ['instrumental ballade']},\n",
       " {'answer_start': [1067], 'text': ['Polish']},\n",
       " {'answer_start': [2529], 'text': ['Paris salons']},\n",
       " {'answer_start': [2761], 'text': ['France']},\n",
       " {'answer_start': [3382], 'text': ['political insurrection']},\n",
       " {'answer_start': [274], 'text': ['Fridericus Franciscus']},\n",
       " {'answer_start': [852], 'text': ['1 March']},\n",
       " {'answer_start': [1192], 'text': ['Fridericus Franciscus']},\n",
       " {'answer_start': [1533], 'text': ['Polish']},\n",
       " {'answer_start': [2750], 'text': ['Ludwika']},\n",
       " {'answer_start': [122], 'text': ['French']},\n",
       " {'answer_start': [591], 'text': ['Warsaw Lyceum']},\n",
       " {'answer_start': [1170], 'text': ['flute and violin']},\n",
       " {'answer_start': [1756], 'text': ['7']},\n",
       " {'answer_start': [2323], 'text': ['7']},\n",
       " {'answer_start': [391], 'text': ['7']},\n",
       " {'answer_start': [924], 'text': ['Belweder Palace']},\n",
       " {'answer_start': [1715], 'text': ['a march']},\n",
       " {'answer_start': [2382], 'text': ['Julian Ursyn Niemcewicz']},\n",
       " {'answer_start': [3365], 'text': ['10 June 1825']},\n",
       " {'answer_start': [883], 'text': ['Rondo Op. 1']},\n",
       " {'answer_start': [1982], 'text': ['Rondo Op. 1.']},\n",
       " {'answer_start': [2337], 'text': ['Dominik Dziewanowski']},\n",
       " {'answer_start': [2694], 'text': ['1827']},\n",
       " {'answer_start': [3341], 'text': ['1827']},\n",
       " {'answer_start': [329], 'text': ['1830']},\n",
       " {'answer_start': [1039], 'text': ['Konstancja Gładkowska']},\n",
       " {'answer_start': [1647], 'text': ['Jan Matuszyński and Julian Fontana']},\n",
       " {'answer_start': [2511], 'text': ['Feliks Jarocki']},\n",
       " {'answer_start': [3065], 'text': ['Feliks Jarocki']},\n",
       " {'answer_start': [96], 'text': ['Feliks Jarocki']},\n",
       " {'answer_start': [840], 'text': ['August']},\n",
       " {'answer_start': [2267], 'text': ['Piano Concerto No. 2 in F minor, Op. 21']},\n",
       " {'answer_start': [2724], 'text': ['two']},\n",
       " {'answer_start': [3351], 'text': ['Zdzisław Jachimecki']},\n",
       " {'answer_start': [66], 'text': ['western Europe']},\n",
       " {'answer_start': [1052], 'text': ['the Polish Great Emigration']},\n",
       " {'answer_start': [1551], 'text': ['September 1831']},\n",
       " {'answer_start': [2262], 'text': ['France']},\n",
       " {'answer_start': [3065], 'text': ['Adam Mickiewicz']},\n",
       " {'answer_start': [385], 'text': ['principal of the Polish Literary Society']},\n",
       " {'answer_start': [468], 'text': ['Polish']},\n",
       " {'answer_start': [1098], 'text': ['Julian Fontana']},\n",
       " {'answer_start': [2632], 'text': ['his father']},\n",
       " {'answer_start': [3561], 'text': ['keyboard technique']},\n",
       " {'answer_start': [1080], 'text': ['Hexameron']},\n",
       " {'answer_start': [2609], 'text': ['Maurice Schlesinger']},\n",
       " {'answer_start': [2789], 'text': ['the Lower Rhenish Music Festival']},\n",
       " {'answer_start': [4669], 'text': ['Felix Mendelssohn']},\n",
       " {'answer_start': [6588], 'text': ['Herz, Liszt, Hiller']},\n",
       " {'answer_start': [88], 'text': [\"38 Rue de la Chaussée-d'Antin\"]},\n",
       " {'answer_start': [1044], 'text': ['2 April 1833']},\n",
       " {'answer_start': [1928], 'text': ['Harriet Smithson']},\n",
       " {'answer_start': [2741], 'text': ['Op. 10 Études']},\n",
       " {'answer_start': [4132], 'text': ['Hiller']},\n",
       " {'answer_start': [75], 'text': ['George Sand']},\n",
       " {'answer_start': [1764], 'text': ['My tragedy']},\n",
       " {'answer_start': [2762], 'text': ['miserable']},\n",
       " {'answer_start': [4296], 'text': ['Félicien Mallefille']},\n",
       " {'answer_start': [5558], 'text': ['Félicien Mallefille.']},\n",
       " {'answer_start': [3], 'text': ['3']},\n",
       " {'answer_start': [948], 'text': ['Pleyel']},\n",
       " {'answer_start': [2092], 'text': [\"Square d'Orléans\"]},\n",
       " {'answer_start': [2865], 'text': [\"Square d'Orléans\"]},\n",
       " {'answer_start': [3336], 'text': ['Nohant']},\n",
       " {'answer_start': [133], 'text': [\"Franz Schubert's lied Die Gestirne\"]},\n",
       " {'answer_start': [567], 'text': ['Polonaise in A-flat major, Op. 53']},\n",
       " {'answer_start': [1117], 'text': ['piano technique and composition.']},\n",
       " {'answer_start': [1816], 'text': ['piano']},\n",
       " {'answer_start': [2034], 'text': ['From 1842 onwards']},\n",
       " {'answer_start': [149], 'text': ['Auguste Clésinger']},\n",
       " {'answer_start': [1268], 'text': ['1846']},\n",
       " {'answer_start': [3179], 'text': ['Lucrezia Floriani']},\n",
       " {'answer_start': [3811], 'text': ['six']},\n",
       " {'answer_start': [4379], 'text': ['February 1848']},\n",
       " {'answer_start': [234], 'text': ['Auguste Franchomme']},\n",
       " {'answer_start': [375], 'text': ['BBC']},\n",
       " {'answer_start': [682], 'text': ['Cornel Wilde']},\n",
       " {'answer_start': [1145], 'text': ['Cornel Wilde']},\n",
       " {'answer_start': [1610], 'text': ['Giacomo Orefice']},\n",
       " {'answer_start': [179], 'text': ['Milan']},\n",
       " {'answer_start': [419], 'text': ['1830']},\n",
       " {'answer_start': [1045], 'text': ['The Warsaw Chopin Society']},\n",
       " {'answer_start': [1337], 'text': ['Paul Pabst']},\n",
       " {'answer_start': [2044], 'text': ['1927']},\n",
       " {'answer_start': [203], 'text': ['1927']},\n",
       " {'answer_start': [777], 'text': ['Les Sylphides']},\n",
       " {'answer_start': [897], 'text': ['Alexander Glazunov.']},\n",
       " {'answer_start': [1308], 'text': ['Jane Stirling and her elder sister']},\n",
       " {'answer_start': [1504], 'text': ['Broadwood']},\n",
       " {'answer_start': [94], 'text': ['a grand piano.']},\n",
       " {'answer_start': [1531], 'text': ['Adam Łyszczyński']},\n",
       " {'answer_start': [1779], 'text': ['Guildhall']},\n",
       " {'answer_start': [2390], 'text': ['Chaillot']},\n",
       " {'answer_start': [2995], 'text': ['Princess Obreskoff.']},\n",
       " {'answer_start': [139], 'text': ['her husband and daughter']},\n",
       " {'answer_start': [1296], 'text': ['Clésinger']},\n",
       " {'answer_start': [1809], 'text': ['DNA testing']},\n",
       " {'answer_start': [1924], 'text': ['Church of the Madeleine']},\n",
       " {'answer_start': [2384], 'text': ['Over 3,000']},\n",
       " {'answer_start': [0], 'text': [\"Mozart's Requiem\"]},\n",
       " {'answer_start': [738], 'text': ['Clésinger']},\n",
       " {'answer_start': [1271], 'text': ['Clésinger.']},\n",
       " {'answer_start': [1689], 'text': ['Over 230']},\n",
       " {'answer_start': [1982], 'text': ['Clementi']},\n",
       " {'answer_start': [39], 'text': ['nocturne']},\n",
       " {'answer_start': [951], 'text': ['nine']},\n",
       " {'answer_start': [1552], 'text': ['the mazurka']},\n",
       " {'answer_start': [2577], 'text': ['Sonata No. 2']},\n",
       " {'answer_start': [3002], 'text': ['Julian Fontana']},\n",
       " {'answer_start': [396], 'text': ['1857']},\n",
       " {'answer_start': [813], 'text': ['KK']},\n",
       " {'answer_start': [999], 'text': ['popular 19th-century piano anthologies.']},\n",
       " {'answer_start': [1391], 'text': ['Improvisation']},\n",
       " {'answer_start': [2737], 'text': ['departure and return']},\n",
       " {'answer_start': [344], 'text': [\"a canon at one beat's distance\"]},\n",
       " {'answer_start': [404], 'text': ['21']},\n",
       " {'answer_start': [706], 'text': ['études']},\n",
       " {'answer_start': [948], 'text': ['The preludes']},\n",
       " {'answer_start': [2382], 'text': ['Kornel Michałowski and Jim Samson']},\n",
       " {'answer_start': [9], 'text': ['harmonic innovations']},\n",
       " {'answer_start': [749], 'text': ['Karol Szymanowski']},\n",
       " {'answer_start': [2015], 'text': ['Nikolai Zverev']},\n",
       " {'answer_start': [2995], 'text': ['Berlioz']},\n",
       " {'answer_start': [3731], 'text': ['mazurkas']},\n",
       " {'answer_start': [130], 'text': ['1836']},\n",
       " {'answer_start': [1013], 'text': ['Schumann']},\n",
       " {'answer_start': [2343], 'text': ['Richard Taruskin']},\n",
       " {'answer_start': [3429], 'text': ['Liszt and Henri Herz']},\n",
       " {'answer_start': [3774], 'text': ['six']},\n",
       " {'answer_start': [269], 'text': ['Liszt']},\n",
       " {'answer_start': [763], 'text': ['Mainland Chinese scholars']},\n",
       " {'answer_start': [1781], 'text': ['Nepal']},\n",
       " {'answer_start': [2675], 'text': ['the 9th century']},\n",
       " {'answer_start': [2964], 'text': ['907–960']},\n",
       " {'answer_start': [26], 'text': ['Genghis Khan']},\n",
       " {'answer_start': [592], 'text': ['Sakya Pandita']},\n",
       " {'answer_start': [1337], 'text': ['Ögedei Khan']},\n",
       " {'answer_start': [2264], 'text': ['the Yuan dynasty']},\n",
       " {'answer_start': [3212],\n",
       "  'text': ['the Phagmodru myriarch Tai Situ Changchub Gyaltsen']},\n",
       " {'answer_start': [188], 'text': ['1368–1398']},\n",
       " {'answer_start': [930], 'text': ['disciples']},\n",
       " {'answer_start': [1231], 'text': ['1739']},\n",
       " {'answer_start': [2387], 'text': ['Tai Situ Changchub Gyaltsen']},\n",
       " {'answer_start': [2789], 'text': ['historian Tsepon W. D. Shakabpa']},\n",
       " {'answer_start': [805], 'text': ['imperial edicts']},\n",
       " {'answer_start': [1640], 'text': ['the line of Mongol rulers in China']},\n",
       " {'answer_start': [4059], 'text': ['a licensed border market']},\n",
       " {'answer_start': [4265], 'text': ['Beijing']},\n",
       " {'answer_start': [5545], 'text': ['ruling lamas']},\n",
       " {'answer_start': [242], 'text': ['Degsi']},\n",
       " {'answer_start': [1618], 'text': ['Van Praag']},\n",
       " {'answer_start': [2115], 'text': ['Jamyang Shakya Gyaltsen']},\n",
       " {'answer_start': [2687], 'text': ['1642']},\n",
       " {'answer_start': [2910], 'text': ['the Ming Yongle Emperor']},\n",
       " {'answer_start': [574], 'text': ['1414']},\n",
       " {'answer_start': [1238], 'text': ['Yang Sanbao']},\n",
       " {'answer_start': [1724], 'text': ['the Ming court']},\n",
       " {'answer_start': [2182], 'text': ['Melvyn C. Goldstein']},\n",
       " {'answer_start': [2809], 'text': ['the Buddhist monk Yao Guangxiao']},\n",
       " {'answer_start': [265], 'text': ['1407']},\n",
       " {'answer_start': [913], 'text': ['Kublai']},\n",
       " {'answer_start': [2018],\n",
       "  'text': ['religious leaders of other Tibetan Buddhist sects']},\n",
       " {'answer_start': [2088], 'text': ['Deshin Shekpa']},\n",
       " {'answer_start': [3149], 'text': ['Buddhist artifacts']},\n",
       " {'answer_start': [277], 'text': ['Great Treasure Prince of Dharma']},\n",
       " {'answer_start': [448], 'text': ['the Karmapa']},\n",
       " {'answer_start': [2659], 'text': ['Silk workshops']},\n",
       " {'answer_start': [3053], 'text': ['Altan Khan']},\n",
       " {'answer_start': [4598], 'text': ['November 1378']},\n",
       " {'answer_start': [105], 'text': ['the Mongols']},\n",
       " {'answer_start': [1968], 'text': ['fifth Karmapa']},\n",
       " {'answer_start': [3082], 'text': ['1518']},\n",
       " {'answer_start': [4102], 'text': [\"China's intervening Ming dynasty\"]},\n",
       " {'answer_start': [4925], 'text': ['the Tibetan lamas and Mongol khans']},\n",
       " {'answer_start': [202], 'text': ['the 13th century']},\n",
       " {'answer_start': [991], 'text': ['1521–1567']},\n",
       " {'answer_start': [1767], 'text': ['Jiajing']},\n",
       " {'answer_start': [2316], 'text': ['the Kokonor region']},\n",
       " {'answer_start': [3445],\n",
       "  'text': ['the native Mongol practices of shamanism and blood sacrifice']},\n",
       " {'answer_start': [157], 'text': ['Tümen Khan']},\n",
       " {'answer_start': [475], 'text': ['Altan Khan']},\n",
       " {'answer_start': [1652], 'text': ['pay tribute']},\n",
       " {'answer_start': [2312], 'text': ['Yonten Gyatso']},\n",
       " {'answer_start': [3044], 'text': ['their old vassal of Tibet']},\n",
       " {'answer_start': [339], 'text': ['1611–1621']},\n",
       " {'answer_start': [2159], 'text': ['the Gelugpas']},\n",
       " {'answer_start': [3079], 'text': ['the Dalai Lama']},\n",
       " {'answer_start': [5041], 'text': ['Shunzhi']},\n",
       " {'answer_start': [6067], 'text': ['1735–1796']},\n",
       " {'answer_start': [400], 'text': ['touchscreen']},\n",
       " {'answer_start': [709], 'text': ['2015']},\n",
       " {'answer_start': [1021], 'text': ['iPod Touch']},\n",
       " {'answer_start': [1108], 'text': ['iTunes']},\n",
       " {'answer_start': [1624], 'text': ['\"Music\" and \"Videos\"']},\n",
       " {'answer_start': [230], 'text': ['A8']},\n",
       " {'answer_start': [1510], 'text': ['Braun T3 transistor radio']},\n",
       " {'answer_start': [2489], 'text': ['Jon Rubinstein']},\n",
       " {'answer_start': [4329], 'text': ['Helvetica']},\n",
       " {'answer_start': [4597], 'text': ['U2']},\n",
       " {'answer_start': [3], 'text': ['2006']},\n",
       " {'answer_start': [754], 'text': ['IXI']},\n",
       " {'answer_start': [933], 'text': ['freelance copywriter']},\n",
       " {'answer_start': [1956], 'text': ['Vinnie Chieco']},\n",
       " {'answer_start': [3086], 'text': ['12.2']},\n",
       " {'answer_start': [37], 'text': ['bass']},\n",
       " {'answer_start': [700], 'text': ['2006']},\n",
       " {'answer_start': [1336], 'text': ['France']},\n",
       " {'answer_start': [1718], 'text': ['FireWire']},\n",
       " {'answer_start': [2685], 'text': ['3.5 mm minijack']},\n",
       " {'answer_start': [196], 'text': ['iPod Hi-Fi']},\n",
       " {'answer_start': [683], 'text': ['iPod Hi-Fi']},\n",
       " {'answer_start': [1328], 'text': ['both sides']},\n",
       " {'answer_start': [2014],\n",
       "  'text': ['Griffin Technology, Belkin, JBL, Bose, Monster Cable, and SendStation']},\n",
       " {'answer_start': [2293], 'text': ['2005']},\n",
       " {'answer_start': [278], 'text': ['FM']},\n",
       " {'answer_start': [686], 'text': ['individual seat-back displays']},\n",
       " {'answer_start': [1065], 'text': ['iPod photo']},\n",
       " {'answer_start': [2131], 'text': ['iPod photo']},\n",
       " {'answer_start': [3325], 'text': ['click wheel']},\n",
       " {'answer_start': [129], 'text': ['Shuffle']},\n",
       " {'answer_start': [1450], 'text': ['September 12, 2006']},\n",
       " {'answer_start': [1612], 'text': ['five']},\n",
       " {'answer_start': [2583], 'text': ['FairPlay']},\n",
       " {'answer_start': [3538], 'text': ['DRM']},\n",
       " {'answer_start': [46], 'text': ['September 5, 2007']},\n",
       " {'answer_start': [508], 'text': ['Steve Wozniak']},\n",
       " {'answer_start': [718], 'text': ['2006']},\n",
       " {'answer_start': [1294], 'text': ['fifth']},\n",
       " {'answer_start': [1683], 'text': ['.zip']},\n",
       " {'answer_start': [248], 'text': ['not']},\n",
       " {'answer_start': [471], 'text': ['iTunes 7']},\n",
       " {'answer_start': [693], 'text': ['patent infringement']},\n",
       " {'answer_start': [1220], 'text': ['rotational user inputs']},\n",
       " {'answer_start': [2000], 'text': ['rotational user inputs']},\n",
       " {'answer_start': [123], 'text': ['$100 million']},\n",
       " {'answer_start': [894], 'text': ['Bloomberg Online']},\n",
       " {'answer_start': [931], 'text': ['Hewlett-Packard']},\n",
       " {'answer_start': [1311], 'text': ['hundred million']},\n",
       " {'answer_start': [1868], 'text': ['32%']},\n",
       " {'answer_start': [236], 'text': ['$3.5 billion']},\n",
       " {'answer_start': [719], 'text': ['Peter Oppenheimer']},\n",
       " {'answer_start': [1160], 'text': ['fourth']},\n",
       " {'answer_start': [2165], 'text': ['Sony Ericsson and Nokia']},\n",
       " {'answer_start': [2561], 'text': ['Glasgow, Scotland']},\n",
       " {'answer_start': [259], 'text': ['the Album Era']},\n",
       " {'answer_start': [489], 'text': ['MP3.com']},\n",
       " {'answer_start': [1304], 'text': ['refurbished replacement iPod']},\n",
       " {'answer_start': [1758], 'text': ['$99']},\n",
       " {'answer_start': [2335], 'text': ['Nano']},\n",
       " {'answer_start': [186], 'text': ['13.7%']},\n",
       " {'answer_start': [876], 'text': ['The Mail on Sunday']},\n",
       " {'answer_start': [1602], 'text': ['Verité']},\n",
       " {'answer_start': [2224], 'text': ['Verité']},\n",
       " {'answer_start': [2876], 'text': ['innovation']},\n",
       " {'answer_start': [569], 'text': ['November 2006']},\n",
       " {'answer_start': [745], 'text': ['Link']},\n",
       " {'answer_start': [1476], 'text': ['The Wind Waker']},\n",
       " {'answer_start': [1761], 'text': ['several']},\n",
       " {'answer_start': [2263], 'text': ['L-targeting']},\n",
       " {'answer_start': [509], 'text': ['sword and shield']},\n",
       " {'answer_start': [843], 'text': ['context-sensitive button mechanic']},\n",
       " {'answer_start': [1798], 'text': ['Nunchuk']},\n",
       " {'answer_start': [2177], 'text': ['enemies']},\n",
       " {'answer_start': [2739], 'text': ['overworld']},\n",
       " {'answer_start': [435], 'text': ['human']},\n",
       " {'answer_start': [1128], 'text': ['The Wind Waker']},\n",
       " {'answer_start': [1744], 'text': ['Midna']},\n",
       " {'answer_start': [2416], 'text': ['Midna']},\n",
       " {'answer_start': [3594], 'text': ['Tears of Light']},\n",
       " {'answer_start': [355], 'text': ['Zant']},\n",
       " {'answer_start': [1271], 'text': ['Zant']},\n",
       " {'answer_start': [2452], 'text': ['Ganondorf']},\n",
       " {'answer_start': [3671], 'text': ['Midna']},\n",
       " {'answer_start': [5179], 'text': ['Zelda']},\n",
       " {'answer_start': [661], 'text': ['Mirror of Twilight']},\n",
       " {'answer_start': [858], 'text': ['2003']},\n",
       " {'answer_start': [2255], 'text': ['Nintendo DS']},\n",
       " {'answer_start': [3733], 'text': ['Revolution']},\n",
       " {'answer_start': [4479], 'text': ['2005']},\n",
       " {'answer_start': [41], 'text': ['Wii']},\n",
       " {'answer_start': [1393], 'text': ['2006']},\n",
       " {'answer_start': [2168], 'text': ['sword']},\n",
       " {'answer_start': [2941], 'text': ['Koji Kondo']},\n",
       " {'answer_start': [3679], 'text': ['live']},\n",
       " {'answer_start': [561], 'text': ['November 19, 2006']},\n",
       " {'answer_start': [811], 'text': ['Twilight Hack']},\n",
       " {'answer_start': [1491], 'text': ['November 12, 2015']},\n",
       " {'answer_start': [2029], 'text': ['March 4, 2016']},\n",
       " {'answer_start': [2223], 'text': ['Cave of Shadows']},\n",
       " {'answer_start': [71], 'text': ['GameStop']},\n",
       " {'answer_start': [468], 'text': ['GameRankings and Metacritic']},\n",
       " {'answer_start': [1120], 'text': ['GameTrailers']},\n",
       " {'answer_start': [2722], 'text': ['Hyper']},\n",
       " {'answer_start': [3605], 'text': ['16th']},\n",
       " {'answer_start': [660], 'text': ['16th']},\n",
       " {'answer_start': [913], 'text': ['PAL region']},\n",
       " {'answer_start': [1454], 'text': ['Shogakukan']},\n",
       " {'answer_start': [2013], 'text': ['Skyfall']},\n",
       " {'answer_start': [2719],\n",
       "  'text': ['Metro-Goldwyn-Mayer and Columbia Pictures']},\n",
       " {'answer_start': [400], 'text': ['Dave Bautista']},\n",
       " {'answer_start': [639], 'text': ['1971']},\n",
       " {'answer_start': [1694], 'text': ['Best Original Song']},\n",
       " {'answer_start': [1922], 'text': ['C']},\n",
       " {'answer_start': [3118], 'text': ['his ring']},\n",
       " {'answer_start': [388], 'text': ['Moneypenny']},\n",
       " {'answer_start': [649], 'text': ['thallium poisoning']},\n",
       " {'answer_start': [1256], 'text': ['thallium poisoning.']},\n",
       " {'answer_start': [2586], 'text': ['Hannes']},\n",
       " {'answer_start': [3853], 'text': ['Westminster Bridge']},\n",
       " {'answer_start': [262], 'text': ['Ian Fleming and Kevin McClory']},\n",
       " {'answer_start': [2112], 'text': ['Never Say Never Again']},\n",
       " {'answer_start': [2488], 'text': ['2013']},\n",
       " {'answer_start': [2967], 'text': ['hackers']},\n",
       " {'answer_start': [3857], 'text': ['Eon Productions']},\n",
       " {'answer_start': [253], 'text': ['Octopussy']},\n",
       " {'answer_start': [955], 'text': ['Spectre']},\n",
       " {'answer_start': [2124], 'text': ['Blofeld']},\n",
       " {'answer_start': [2425], 'text': ['Ben Whishaw']},\n",
       " {'answer_start': [2664], 'text': ['Franz Oberhauser']},\n",
       " {'answer_start': [311], 'text': ['Bérénice Lim Marlohe']},\n",
       " {'answer_start': [1197], 'text': ['February 2015']},\n",
       " {'answer_start': [1744], 'text': ['John Glen']},\n",
       " {'answer_start': [2626], 'text': ['Spectre']},\n",
       " {'answer_start': [3383], 'text': ['Pinewood Studios']},\n",
       " {'answer_start': [256], 'text': ['February 2015']},\n",
       " {'answer_start': [886], 'text': ['Rettenbach glacier']},\n",
       " {'answer_start': [1573], 'text': ['Blenheim Palace in Oxfordshire']},\n",
       " {'answer_start': [2739], 'text': ['Mexico City']},\n",
       " {'answer_start': [3618], 'text': ['the Day of the Dead festival']},\n",
       " {'answer_start': [78], 'text': ['New York']},\n",
       " {'answer_start': [583], 'text': ['Westminster and Lambeth Bridges']},\n",
       " {'answer_start': [1529], 'text': ['Largest film stunt explosion']},\n",
       " {'answer_start': [2333], 'text': ['128 days.']},\n",
       " {'answer_start': [3142], 'text': ['Istanbul']},\n",
       " {'answer_start': [464], 'text': ['Decca Records']},\n",
       " {'answer_start': [792], 'text': ['demo']},\n",
       " {'answer_start': [1224], 'text': ['Radiohead']},\n",
       " {'answer_start': [1402], 'text': ['10']},\n",
       " {'answer_start': [2103], 'text': ['clapperboards']},\n",
       " {'answer_start': [262], 'text': ['BBC One']},\n",
       " {'answer_start': [574], 'text': ['Royal Albert Hall']},\n",
       " {'answer_start': [1196], 'text': ['$879.3 million']},\n",
       " {'answer_start': [2124], 'text': ['Avatar']},\n",
       " {'answer_start': [2478], 'text': ['Paris']},\n",
       " {'answer_start': [1046], 'text': ['Minions']},\n",
       " {'answer_start': [1947], 'text': ['374']},\n",
       " {'answer_start': [3013], 'text': ['$84.7 million']},\n",
       " {'answer_start': [3522], 'text': ['64%']},\n",
       " {'answer_start': [4648], 'text': ['IGN']},\n",
       " {'answer_start': [2118], 'text': ['75']},\n",
       " {'answer_start': [3277], 'text': ['Bored, James Bored']},\n",
       " {'answer_start': [3471], 'text': ['spring 2016.']},\n",
       " {'answer_start': [3762], 'text': ['8.0 Ms and 7.9 Mw']},\n",
       " {'answer_start': [4252], 'text': ['19 km']},\n",
       " {'answer_start': [319], 'text': ['19 km']},\n",
       " {'answer_start': [1372], 'text': ['1 trillion RMB']},\n",
       " {'answer_start': [1804], 'text': ['11 million']},\n",
       " {'answer_start': [2717], 'text': ['2 minutes']},\n",
       " {'answer_start': [3393], 'text': ['10 km']},\n",
       " {'answer_start': [233], 'text': ['April 30, 2008']},\n",
       " {'answer_start': [2008], 'text': ['droughts']},\n",
       " {'answer_start': [2813], 'text': ['240 km long']},\n",
       " {'answer_start': [3270], 'text': ['in two stages']},\n",
       " {'answer_start': [4084], 'text': ['Between 64 and 104']},\n",
       " {'answer_start': [326], 'text': ['6.4 MS']},\n",
       " {'answer_start': [529],\n",
       "  'text': ['because it was caused by a different fault.']},\n",
       " {'answer_start': [661], 'text': ['CEA']},\n",
       " {'answer_start': [1827],\n",
       "  'text': ['the eastern border of the Tibetan Plateau']},\n",
       " {'answer_start': [2624], 'text': ['Tibetan Plateau']},\n",
       " {'answer_start': [20], 'text': [\"Shanghai's financial district\"]},\n",
       " {'answer_start': [1011], 'text': ['evacuated']},\n",
       " {'answer_start': [1729], 'text': ['Beijing']},\n",
       " {'answer_start': [2326], 'text': ['venues']},\n",
       " {'answer_start': [2855], 'text': ['Dujiangyan']},\n",
       " {'answer_start': [253], 'text': ['two chemical plants']},\n",
       " {'answer_start': [891], 'text': ['suspended trading']},\n",
       " {'answer_start': [1249], 'text': ['internet']},\n",
       " {'answer_start': [2003], 'text': ['news and media websites']},\n",
       " {'answer_start': [2224], 'text': ['traffic congestion']},\n",
       " {'answer_start': [88], 'text': ['around 280']},\n",
       " {'answer_start': [1886], 'text': ['five']},\n",
       " {'answer_start': [2536], 'text': ['391']},\n",
       " {'answer_start': [3033], 'text': ['391']},\n",
       " {'answer_start': [3368], 'text': ['158']},\n",
       " {'answer_start': [338], 'text': ['tried to repair roads']},\n",
       " {'answer_start': [584], 'text': ['10,000']},\n",
       " {'answer_start': [1587], 'text': ['Eight schools']},\n",
       " {'answer_start': [2169], 'text': ['inland areas']},\n",
       " {'answer_start': [2816], 'text': ['1,700']},\n",
       " {'answer_start': [153], 'text': ['1,700']},\n",
       " {'answer_start': [840], 'text': ['5,335']},\n",
       " {'answer_start': [1591], 'text': ['546']},\n",
       " {'answer_start': [1964], 'text': ['1 million']},\n",
       " {'answer_start': [2498], 'text': ['Reginald DesRoches']},\n",
       " {'answer_start': [118],\n",
       "  'text': ['make a detailed preliminary survey of damaged buildings']},\n",
       " {'answer_start': [301], 'text': ['the poorer, rural villages']},\n",
       " {'answer_start': [1461], 'text': ['regulations']},\n",
       " {'answer_start': [1504], 'text': ['five largest cities']},\n",
       " {'answer_start': [2183], 'text': ['63']},\n",
       " {'answer_start': [294], 'text': ['1,300']},\n",
       " {'answer_start': [743], 'text': ['1.94 million']},\n",
       " {'answer_start': [1122], 'text': ['90 minutes after']},\n",
       " {'answer_start': [1807],\n",
       "  'text': ['the most serious class of natural disasters']},\n",
       " {'answer_start': [1902], 'text': ['National Disaster Relief Commission']},\n",
       " {'answer_start': [3], 'text': ['earthquake emergency relief']},\n",
       " {'answer_start': [357],\n",
       "  'text': ['a close analysis by an alleged Chinese construction engineer']},\n",
       " {'answer_start': [610], 'text': ['living in relief centres']},\n",
       " {'answer_start': [780], 'text': ['more than $48.6 million']},\n",
       " {'answer_start': [1035], 'text': ['19 countries']},\n",
       " {'answer_start': [189], 'text': ['Saudi Arabia']},\n",
       " {'answer_start': [531], 'text': ['one province to one affected county']},\n",
       " {'answer_start': [1120], 'text': ['25 times more']},\n",
       " {'answer_start': [1951], 'text': ['the time of the 2008 Sichuan earthquake']},\n",
       " {'answer_start': [2410], 'text': ['a global issue']},\n",
       " {'answer_start': [27], 'text': ['Chen Xuezhong']},\n",
       " {'answer_start': [856], 'text': ['no consensus']},\n",
       " {'answer_start': [1199], 'text': ['the traffic problem']},\n",
       " {'answer_start': [2333], 'text': ['20']},\n",
       " {'answer_start': [3356], 'text': ['20']},\n",
       " {'answer_start': [95], 'text': ['60']},\n",
       " {'answer_start': [577], 'text': ['civil aviation industry']},\n",
       " {'answer_start': [854], 'text': ['Tzu Chi Foundation']},\n",
       " {'answer_start': [1667], 'text': ['May 16']},\n",
       " {'answer_start': [1778], 'text': ['Chengdu']},\n",
       " {'answer_start': [151], 'text': ['satellite images']},\n",
       " {'answer_start': [649],\n",
       "  'text': ['to find the blind spots of disaster recovery']},\n",
       " {'answer_start': [1680], 'text': ['contact information']},\n",
       " {'answer_start': [1940], 'text': ['a moment of silence']},\n",
       " {'answer_start': [2653], 'text': ['China Unicom and China Mobile']},\n",
       " {'answer_start': [420], 'text': ['$772 million']},\n",
       " {'answer_start': [801], 'text': ['30,000']},\n",
       " {'answer_start': [957], 'text': ['The Amity Foundation']},\n",
       " {'answer_start': [1340], 'text': ['tofu-dregs schoolhouses']},\n",
       " {'answer_start': [2774], 'text': ['$1.57 million']},\n",
       " {'answer_start': [721], 'text': ['1.57 million']},\n",
       " {'answer_start': [1572], 'text': ['Los Angeles Times']},\n",
       " {'answer_start': [1685], 'text': ['7.9']},\n",
       " {'answer_start': [2494],\n",
       "  'text': ['Mount Tangjia in Beichuan County, Sichuan']},\n",
       " {'answer_start': [3303], 'text': ['Mount Tangjia']},\n",
       " {'answer_start': [435], 'text': ['Mao Zedong']},\n",
       " {'answer_start': [879], 'text': ['Ningbo']},\n",
       " {'answer_start': [1310], 'text': ['black and white']},\n",
       " {'answer_start': [2056], 'text': ['Ye Zhiping']},\n",
       " {'answer_start': [2648], 'text': ['Sangzao']},\n",
       " {'answer_start': [49], 'text': ['Chinese prosecutors']},\n",
       " {'answer_start': [1314], 'text': ['riot police']},\n",
       " {'answer_start': [2525], 'text': ['on school collapses']},\n",
       " {'answer_start': [2913], 'text': ['put them online']},\n",
       " {'answer_start': [3385], 'text': ['massive casualties']},\n",
       " {'answer_start': [15], 'text': ['magnitude of the quake']},\n",
       " {'answer_start': [495], 'text': ['Yao Ming']},\n",
       " {'answer_start': [1278], 'text': ['10 days']},\n",
       " {'answer_start': [1421], 'text': ['Myanmar']},\n",
       " {'answer_start': [2306], 'text': ['poorly built schools']},\n",
       " {'answer_start': [198], 'text': ['thin iron wires']},\n",
       " {'answer_start': [705], 'text': ['the Times']},\n",
       " {'answer_start': [809], 'text': ['New York']},\n",
       " {'answer_start': [1867], 'text': ['8,491,079']},\n",
       " {'answer_start': [2939], 'text': ['1898']},\n",
       " {'answer_start': [276], 'text': ['1790']},\n",
       " {'answer_start': [742], 'text': ['1664']},\n",
       " {'answer_start': [2466], 'text': ['120']},\n",
       " {'answer_start': [2812], 'text': ['Lenapehoking']},\n",
       " {'answer_start': [3231], 'text': ['Nouvelle Angoulême']},\n",
       " {'answer_start': [36], 'text': ['Estêvão Gomes']},\n",
       " {'answer_start': [1022], 'text': ['Padrón Real']},\n",
       " {'answer_start': [1429], 'text': ['North River']},\n",
       " {'answer_start': [2118], 'text': ['Jan Rodrigues']},\n",
       " {'answer_start': [2795],\n",
       "  'text': ['Broadway, from 159th Street to 218th Street']},\n",
       " {'answer_start': [627], 'text': ['1626']},\n",
       " {'answer_start': [999], 'text': ['James II']},\n",
       " {'answer_start': [1173], 'text': ['William III']},\n",
       " {'answer_start': [1425], 'text': ['England']},\n",
       " {'answer_start': [2072], 'text': ['200']},\n",
       " {'answer_start': [578], 'text': ['courthouse']},\n",
       " {'answer_start': [820], 'text': ['1754']},\n",
       " {'answer_start': [1357], 'text': ['New York']},\n",
       " {'answer_start': [2175], 'text': ['1783']},\n",
       " {'answer_start': [2485], 'text': ['Lord Howe']},\n",
       " {'answer_start': [257], 'text': ['the Great Fire of New York']},\n",
       " {'answer_start': [1018], 'text': ['Philadelphia']},\n",
       " {'answer_start': [1120], 'text': ['1799']},\n",
       " {'answer_start': [1981], 'text': ['1799']},\n",
       " {'answer_start': [3342], 'text': ['Irish']},\n",
       " {'answer_start': [4], 'text': ['Great Irish Famine']},\n",
       " {'answer_start': [338], 'text': ['Great Irish Famine']},\n",
       " {'answer_start': [1741], 'text': ['120']},\n",
       " {'answer_start': [2391], 'text': ['the Bronx']},\n",
       " {'answer_start': [2910], 'text': ['146']},\n",
       " {'answer_start': [36], 'text': ['36,620']},\n",
       " {'answer_start': [694], 'text': ['megacity']},\n",
       " {'answer_start': [1085], 'text': ['the Stonewall Inn']},\n",
       " {'answer_start': [1526],\n",
       "  'text': ['Stonewall Inn in the Greenwich Village neighborhood of Lower Manhattan']},\n",
       " {'answer_start': [1775], 'text': ['1970s']},\n",
       " {'answer_start': [727], 'text': ['July 19, 1909']},\n",
       " {'answer_start': [1316], 'text': ['September 17, 2011']},\n",
       " {'answer_start': [1728], 'text': ['William F. Buckley, Jr.']},\n",
       " {'answer_start': [2013], 'text': ['southeastern']},\n",
       " {'answer_start': [2648], 'text': ['Atlantic Ocean']},\n",
       " {'answer_start': [54], 'text': ['New York Bay']},\n",
       " {'answer_start': [793], 'text': ['Battery Park City']},\n",
       " {'answer_start': [1098], 'text': ['Staten Island']},\n",
       " {'answer_start': [1518], 'text': ['409.8']},\n",
       " {'answer_start': [1921], 'text': ['1656']},\n",
       " {'answer_start': [425], 'text': ['1913']},\n",
       " {'answer_start': [680], 'text': ['Art Deco']},\n",
       " {'answer_start': [1687], 'text': ['1931']},\n",
       " {'answer_start': [2587], 'text': ['1930']},\n",
       " {'answer_start': [3465], 'text': ['Jackson Heights']},\n",
       " {'answer_start': [60], 'text': ['five']},\n",
       " {'answer_start': [702], 'text': ['humid continental']},\n",
       " {'answer_start': [1142], 'text': ['Appalachians']},\n",
       " {'answer_start': [3535], 'text': ['106']},\n",
       " {'answer_start': [4022], 'text': ['October 29, 2012']},\n",
       " {'answer_start': [110],\n",
       "  'text': ['New York State Office of Parks, Recreation and Historic Preservation']},\n",
       " {'answer_start': [298], 'text': ['10,521.83']},\n",
       " {'answer_start': [872], 'text': ['over 26,000']},\n",
       " {'answer_start': [1518], 'text': ['National Park Service']},\n",
       " {'answer_start': [2237], 'text': ['seven']},\n",
       " {'answer_start': [23], 'text': ['28,000']},\n",
       " {'answer_start': [397], 'text': ['14']},\n",
       " {'answer_start': [780], 'text': ['Brooklyn']},\n",
       " {'answer_start': [1558], 'text': ['Brooklyn']},\n",
       " {'answer_start': [2718], 'text': ['40%']},\n",
       " {'answer_start': [57], 'text': ['27,858']},\n",
       " {'answer_start': [828], 'text': ['Asians']},\n",
       " {'answer_start': [1321], 'text': ['Asians']},\n",
       " {'answer_start': [2044], 'text': ['92%']},\n",
       " {'answer_start': [2279], 'text': ['Dominican Republic']},\n",
       " {'answer_start': [624], 'text': ['Manhattan']},\n",
       " {'answer_start': [2345], 'text': ['550,000']},\n",
       " {'answer_start': [3573], 'text': ['20 million']},\n",
       " {'answer_start': [5337], 'text': ['1.3 million']},\n",
       " {'answer_start': [5486], 'text': ['568,903']},\n",
       " {'answer_start': [294], 'text': ['30']},\n",
       " {'answer_start': [538], 'text': ['Islam']},\n",
       " {'answer_start': [1081], 'text': ['Islam']},\n",
       " {'answer_start': [1757], 'text': ['$2,749']},\n",
       " {'answer_start': [3173], 'text': ['2014']},\n",
       " {'answer_start': [252], 'text': ['US$1.1 billion']},\n",
       " {'answer_start': [1358], 'text': ['660 Madison Avenue']},\n",
       " {'answer_start': [1867], 'text': ['180,000']},\n",
       " {'answer_start': [1989], 'text': ['US$234 million']},\n",
       " {'answer_start': [2398], 'text': ['Godiva']},\n",
       " {'answer_start': [448], 'text': ['22']},\n",
       " {'answer_start': [1343], 'text': ['19%']},\n",
       " {'answer_start': [2340], 'text': ['400']},\n",
       " {'answer_start': [3729], 'text': ['300,000']},\n",
       " {'answer_start': [4337], 'text': ['US$30 million']},\n",
       " {'answer_start': [220], 'text': ['56.4 million']},\n",
       " {'answer_start': [477], 'text': ['1977']},\n",
       " {'answer_start': [1193], 'text': ['Greenwich Village']},\n",
       " {'answer_start': [1938], 'text': ['90,000']},\n",
       " {'answer_start': [2221], 'text': ['90,000']},\n",
       " {'answer_start': [372], 'text': ['$7.1 billion']},\n",
       " {'answer_start': [1032], 'text': ['25,000']},\n",
       " {'answer_start': [1783], 'text': ['More than 200']},\n",
       " {'answer_start': [2839], 'text': ['CBS']},\n",
       " {'answer_start': [3369], 'text': ['1971']},\n",
       " {'answer_start': [185], 'text': ['1971']},\n",
       " {'answer_start': [739], 'text': ['nine']},\n",
       " {'answer_start': [986], 'text': ['half million']},\n",
       " {'answer_start': [2153], 'text': ['The New York Public Library']},\n",
       " {'answer_start': [2474],\n",
       "  'text': ['New York City Health and Hospitals Corporation']},\n",
       " {'answer_start': [355], 'text': ['1969']},\n",
       " {'answer_start': [949], 'text': ['Bellevue Hospital']},\n",
       " {'answer_start': [1572], 'text': [\"New York's Finest\"]},\n",
       " {'answer_start': [1848], 'text': ['75%']},\n",
       " {'answer_start': [2790], 'text': ['Forty Thieves and the Roach Guards']},\n",
       " {'answer_start': [0], 'text': ['The New York City Fire Department']},\n",
       " {'answer_start': [994], 'text': ['3,300']},\n",
       " {'answer_start': [1187], 'text': ['Randalls Island']},\n",
       " {'answer_start': [1764], 'text': ['11 Metrotech Center']},\n",
       " {'answer_start': [2142], 'text': ['abstract expressionism']},\n",
       " {'answer_start': [494], 'text': ['New York Fashion Week']},\n",
       " {'answer_start': [1472], 'text': ['Harrigan']},\n",
       " {'answer_start': [1882], 'text': ['US$1.27 billion']},\n",
       " {'answer_start': [2490], 'text': ['4,000']},\n",
       " {'answer_start': [3646],\n",
       "  'text': ['MetLife Stadium, the new Yankee Stadium, Madison Square Garden, and Citi Field']},\n",
       " {'answer_start': [512], 'text': ['forty']},\n",
       " {'answer_start': [1110], 'text': ['35']},\n",
       " {'answer_start': [2534], 'text': ['MetLife Stadium']},\n",
       " {'answer_start': [2843], 'text': ['Super Bowl XLVIII']},\n",
       " {'answer_start': [2952], 'text': ['Hockey']},\n",
       " {'answer_start': [106], 'text': ['New York Liberty']},\n",
       " {'answer_start': [909], 'text': ['Millrose Games']},\n",
       " {'answer_start': [1584], 'text': ['United States Open Tennis Championships']},\n",
       " {'answer_start': [2812], 'text': ['Stickball Boulevard']},\n",
       " {'answer_start': [3358], 'text': ['1.75 billion']},\n",
       " {'answer_start': [48], 'text': ['54.6%']},\n",
       " {'answer_start': [823], 'text': ['Port Authority Bus Terminal']},\n",
       " {'answer_start': [1217], 'text': ['Newark Liberty International Airport']},\n",
       " {'answer_start': [2106], 'text': ['24']},\n",
       " {'answer_start': [2363], 'text': ['The Verrazano-Narrows Bridge']},\n",
       " {'answer_start': [129], 'text': ['Verrazano-Narrows Bridge']},\n",
       " {'answer_start': [1452], 'text': ['1940']},\n",
       " {'answer_start': [2187], 'text': ['Jersey City']},\n",
       " {'answer_start': [3151], 'text': ['Citibank']},\n",
       " {'answer_start': [3910], 'text': ['US$3.2 billion']},\n",
       " {'answer_start': [269], 'text': ['three']},\n",
       " {'answer_start': [559], 'text': ['four']},\n",
       " {'answer_start': [1267], 'text': ['Calvin Coolidge']},\n",
       " {'answer_start': [1793], 'text': ['Republican']},\n",
       " {'answer_start': [2275], 'text': ['one million']},\n",
       " {'answer_start': [281], 'text': ['crack']},\n",
       " {'answer_start': [1059], 'text': ['Manhattan']},\n",
       " {'answer_start': [1715], 'text': ['Fifth Avenue']},\n",
       " {'answer_start': [2613], 'text': ['Brooklynese']},\n",
       " {'answer_start': [3181], 'text': ['Yankee Stadium']},\n",
       " {'answer_start': [335], 'text': ['20']},\n",
       " {'answer_start': [1293], 'text': ['three']},\n",
       " {'answer_start': [1606], 'text': ['12,000']},\n",
       " {'answer_start': [2069], 'text': ['Seventh Avenue']},\n",
       " {'answer_start': [2437], 'text': ['the west end']},\n",
       " {'answer_start': [256], 'text': ['28%']},\n",
       " {'answer_start': [854], 'text': ['110,000']},\n",
       " {'answer_start': [1213], 'text': ['Manhattan']},\n",
       " {'answer_start': [1797],\n",
       "  'text': ['the District Court for the Eastern District of New York']},\n",
       " {'answer_start': [2698], 'text': ['$11 billion']},\n",
       " {'answer_start': [109], 'text': ['Pulitzer Prize']},\n",
       " {'answer_start': [693], 'text': ['United States']},\n",
       " {'answer_start': [1093], 'text': ['Mary McDonough Murphy']},\n",
       " {'answer_start': [2001], 'text': ['Bible']},\n",
       " {'answer_start': [2344], 'text': ['Go Set a Watchman']},\n",
       " {'answer_start': [569], 'text': ['1950']},\n",
       " {'answer_start': [1237], 'text': ['Huntingdon College']},\n",
       " {'answer_start': [2283], 'text': ['Therese von Hohoff Torrey']},\n",
       " {'answer_start': [2879], 'text': ['over two and a half years']},\n",
       " {'answer_start': [4302], 'text': ['Dill']},\n",
       " {'answer_start': [40], 'text': ['Tom Robinson']},\n",
       " {'answer_start': [1220], 'text': ['shot and killed']},\n",
       " {'answer_start': [1861], 'text': ['Boo Radley']},\n",
       " {'answer_start': [2605], 'text': ['25']},\n",
       " {'answer_start': [2994], 'text': ['Truman Capote']},\n",
       " {'answer_start': [870], 'text': ['Emmett Till']},\n",
       " {'answer_start': [1588], 'text': ['parody, satire, and irony']},\n",
       " {'answer_start': [2537],\n",
       "  'text': ['Southern Gothic and coming-of-age or Bildungsroman novel']},\n",
       " {'answer_start': [4299], 'text': ['1955']},\n",
       " {'answer_start': [5460], 'text': ['poor white farmers']},\n",
       " {'answer_start': [474], 'text': ['Aunt Alexandra']},\n",
       " {'answer_start': [1009], 'text': ['gender and class']},\n",
       " {'answer_start': [1907], 'text': ['Charles Shields']},\n",
       " {'answer_start': [4042], 'text': ['Calpurnia and Miss Maudie']},\n",
       " {'answer_start': [5088], 'text': ['Dolphus Raymond']},\n",
       " {'answer_start': [154], 'text': ['mockingbird']},\n",
       " {'answer_start': [1299], 'text': ['Book of the Month Club']},\n",
       " {'answer_start': [1557], 'text': ['more than 40']},\n",
       " {'answer_start': [2229], 'text': ['integrity']},\n",
       " {'answer_start': [3409], 'text': ['21']},\n",
       " {'answer_start': [322],\n",
       "  'text': [\"Mayella Ewell's attraction to Tom Robinson\"]},\n",
       " {'answer_start': [1288], 'text': ['Archulus Persons']},\n",
       " {'answer_start': [1979], 'text': ['1961']},\n",
       " {'answer_start': [3420], 'text': ['1964']},\n",
       " {'answer_start': [4415], 'text': ['25']},\n",
       " {'answer_start': [335], 'text': ['George W. Bush']},\n",
       " {'answer_start': [1566], 'text': ['grandson']},\n",
       " {'answer_start': [1651], 'text': ['Christopher Sergel']},\n",
       " {'answer_start': [2400], 'text': ['the UK']},\n",
       " {'answer_start': [2975], 'text': ['20']},\n",
       " {'answer_start': [91], 'text': ['rape and racial inequality']},\n",
       " {'answer_start': [762], 'text': ['the neighborhood']},\n",
       " {'answer_start': [1977], 'text': ['Boo Radley']},\n",
       " {'answer_start': [2866], 'text': [\"Flannery O'Connor\"]},\n",
       " {'answer_start': [3445], 'text': ['Calpurnia']},\n",
       " {'answer_start': [115], 'text': ['like Scripture']},\n",
       " {'answer_start': [919], 'text': ['radiant light and heat from the Sun']},\n",
       " {'answer_start': [1226], 'text': ['Approximately 30%']},\n",
       " {'answer_start': [2253], 'text': ['photosynthesis']},\n",
       " {'answer_start': [3044], 'text': ['photosynthesis']},\n",
       " {'answer_start': [81],\n",
       "  'text': ['approximately 3,850,000 exajoules (EJ) per year']},\n",
       " {'answer_start': [589],\n",
       "  'text': ['depending on the way they capture, convert and distribute sunlight']},\n",
       " {'answer_start': [1057], 'text': ['solar thermal collectors']},\n",
       " {'answer_start': [1878], 'text': ['1908']},\n",
       " {'answer_start': [2716], 'text': ['1908']},\n",
       " {'answer_start': [62], 'text': ['Maadi, Egypt']},\n",
       " {'answer_start': [754], 'text': ['70']},\n",
       " {'answer_start': [1177], 'text': ['154']},\n",
       " {'answer_start': [1969], 'text': ['United States, Canada and Australia']},\n",
       " {'answer_start': [2124], 'text': ['Thermal']},\n",
       " {'answer_start': [685], 'text': ['auxiliary heating and cooling equipment']},\n",
       " {'answer_start': [1046], 'text': ['winter']},\n",
       " {'answer_start': [1801], 'text': ['1767']},\n",
       " {'answer_start': [2846], 'text': ['90–150 °C (194–302 °F)']},\n",
       " {'answer_start': [3474],\n",
       "  'text': ['Solar Total Energy Project (STEP) in Shenandoah, Georgia, USA']},\n",
       " {'answer_start': [0], 'text': ['Solar distillation']},\n",
       " {'answer_start': [1094], 'text': ['the World Health Organization']},\n",
       " {'answer_start': [1341],\n",
       "  'text': ['to treat waste water without chemicals or electricity']},\n",
       " {'answer_start': [2267], 'text': ['2013']},\n",
       " {'answer_start': [3157], 'text': ['1954']},\n",
       " {'answer_start': [726],\n",
       "  'text': ['Gerald Pearson, Calvin Fuller and Daryl Chapin']},\n",
       " {'answer_start': [1501],\n",
       "  'text': ['a working fluid is heated by the concentrated sunlight']},\n",
       " {'answer_start': [2222], 'text': ['pumps, fans and switchable windows']},\n",
       " {'answer_start': [2716],\n",
       "  'text': ['paint buildings and roads white and plant trees']},\n",
       " {'answer_start': [3571], 'text': ['employed fruit walls']},\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "matched-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer-4094-squad_seed_42\n",
      "RoBERTa_Long_seed_1337\n",
      "longformer-base-seed-42-squad-finetuned\n",
      "roberta-base-4096-seed-42-fastest-lm-complete\n",
      "roberta-long-seed-1337-squad-finetuned\n",
      "roberta-long-seed-42-fine-tuned-squad\n",
      "roberta-long-seed-42-squad\n",
      "xlm-roberta-base-4096-seed-42-fast-lm\n",
      "xlm-roberta-base-4096-seed-42-fastest-lm-complete\n",
      "xlm-roberta-base-seed-1337-xquad-long-finetuned\n",
      "xlm-roberta-base-seed-165-xquad-finetuned\n",
      "xlm-roberta-base-seed-165-xquad-long-finetuned\n",
      "xlm-roberta-base-seed-1729-xquad-long-finetuned\n",
      "xlm-roberta-base-seed-42-xquad-long-finetuned\n",
      "xlm-roberta-base-seed-758241-xquad-long-finetuned\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ethical-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:393] 2021-01-22 20:36:01,372 >> loading configuration file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/config.json\n",
      "[INFO|configuration_utils.py:431] 2021-01-22 20:36:01,375 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete\",\n",
      "  \"architectures\": [\n",
      "    \"LongModelForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1512] 2021-01-22 20:36:01,377 >> Model name '/workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete' not found in model shortcut name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). Assuming '/workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[INFO|tokenization_utils_base.py:1542] 2021-01-22 20:36:01,400 >> Didn't find file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/tokenizer.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1542] 2021-01-22 20:36:01,401 >> Didn't find file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1597] 2021-01-22 20:36:01,404 >> loading file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/sentencepiece.bpe.model\n",
      "[INFO|tokenization_utils_base.py:1597] 2021-01-22 20:36:01,405 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1597] 2021-01-22 20:36:01,406 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1597] 2021-01-22 20:36:01,407 >> loading file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1597] 2021-01-22 20:36:01,408 >> loading file /workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/workspace/models/xlm-roberta-base-4096-seed-42-fastest-lm-complete', use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-integral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
