{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤© Currently 179 datasets are available on the hub:\n",
      "['Fraser/news-category-dataset', 'aeslc', 'ag_news', 'ai2_arc', 'allocine',\n",
      " 'amazon_us_reviews', 'anli', 'arcd', 'art', 'aslg_pc12', 'asnq', 'billsum',\n",
      " 'biomrc', 'blended_skill_talk', 'blimp', 'blog_authorship_corpus',\n",
      " 'bookcorpus', 'bookcorpusopen', 'boolq', 'break_data', 'c4', 'cdminix/mgb1',\n",
      " 'cfq', 'civil_comments', 'clue', 'cmrc2018', 'cnn_dailymail',\n",
      " 'coarse_discourse', 'com_qa', 'common_gen', 'commonsense_qa', 'compguesswhat',\n",
      " 'conll2000', 'conll2003', 'coqa', 'cornell_movie_dialog', 'cos_e', 'cosmos_qa',\n",
      " 'crd3', 'crime_and_punish', 'csv', 'daily_dialog',\n",
      " 'definite_pronoun_resolution', 'discofuse', 'docred', 'doqa', 'drop', 'eli5',\n",
      " 'emo', 'emotion', 'empathetic_dialogues', 'eraser_multi_rc', 'esnli',\n",
      " 'event2Mind', 'fever', 'flores', 'fquad', 'gap', 'germeval_14', 'gigaword',\n",
      " 'glue', 'guardian_authorship', 'hans', 'hansards', 'hellaswag', 'hotpot_qa',\n",
      " 'hyperpartisan_news_detection', 'imdb', 'iwslt2017', 'jeopardy',\n",
      " 'joelito/sem_eval_2010_task_8', 'json', 'kilt_tasks', 'kilt_wikipedia',\n",
      " 'kor_nli', 'lc_quad', 'lhoestq/squad', 'librispeech_lm', 'lince', 'lm1b',\n",
      " 'math_dataset', 'math_qa', 'matinf', 'mlqa', 'mlsum', 'movie_rationales',\n",
      " 'ms_marco', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'mwsc',\n",
      " 'natural_questions', 'newsgroup', 'newsroom', 'nli_tr', 'openbookqa',\n",
      " 'openwebtext', 'opinosis', 'pandas', 'para_crawl', 'pg19',\n",
      " 'piEsposito/br-quad-2.0', 'piEsposito/br_quad_20', 'piEsposito/squad_20_ptbr',\n",
      " 'piaf', 'polyglot_ner', 'qa4mre', 'qa_zre', 'qangaroo', 'qanta', 'qasc',\n",
      " 'quail', 'quarel', 'quartz', 'quora', 'quoref', 'race', 'reclor', 'reddit',\n",
      " 'reddit_tifu', 'reuters21578', 'rotten_tomatoes', 'scan', 'scicite',\n",
      " 'scientific_papers', 'scifact', 'sciq', 'scitail', 'search_qa', 'sentiment140',\n",
      " 'snli', 'social_bias_frames', 'social_i_qa', 'sogou_news', 'squad', 'squad_es',\n",
      " 'squad_it', 'squad_v1_pt', 'squad_v2', 'squadshifts',\n",
      " 'sshleifer/pseudo_bart_xsum', 'style_change_detection', 'super_glue',\n",
      " 'ted_hrlr', 'ted_multi', 'text', 'tiny_shakespeare', 'trec', 'trivia_qa',\n",
      " 'tydiqa', 'ubuntu_dialogs_corpus', 'web_of_science', 'web_questions',\n",
      " 'wiki40b', 'wiki_dpr', 'wiki_qa', 'wiki_snippets', 'wiki_split', 'wikihow',\n",
      " 'wikipedia', 'wikisql', 'wikitext', 'winogrande', 'wiqa', 'wmt14', 'wmt15',\n",
      " 'wmt16', 'wmt17', 'wmt18', 'wmt19', 'wmt_t2t', 'wnut_17', 'x_stance', 'xcopa',\n",
      " 'xnli', 'xquad', 'xsum', 'xtreme', 'yelp_polarity']\n",
      "ðŸ¤© Currently 17 metrics are available on the hub:\n",
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'coval', 'f1', 'gleu', 'glue',\n",
      " 'meteor', 'precision', 'recall', 'rouge', 'sacrebleu', 'seqeval', 'squad',\n",
      " 'squad_v2', 'xnli']\n"
     ]
    }
   ],
   "source": [
    "# Let's import the library. We typically only need at most four methods:\n",
    "from datasets import list_datasets, list_metrics, load_dataset, load_metric\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Currently available datasets and metrics\n",
    "datasets = list_datasets()\n",
    "metrics = list_metrics()\n",
    "\n",
    "print(f\"ðŸ¤© Currently {len(datasets)} datasets are available on the hub:\")\n",
    "pprint(datasets, compact=True)\n",
    "print(f\"ðŸ¤© Currently {len(metrics)} metrics are available on the hub:\")\n",
    "pprint(metrics, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': None,\n",
      " 'citation': '@article{2016arXiv160605250R,\\n'\n",
      "             '       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and '\n",
      "             '{Lopyrev},\\n'\n",
      "             '                 Konstantin and {Liang}, Percy},\\n'\n",
      "             '        title = \"{SQuAD: 100,000+ Questions for Machine '\n",
      "             'Comprehension of Text}\",\\n'\n",
      "             '      journal = {arXiv e-prints},\\n'\n",
      "             '         year = 2016,\\n'\n",
      "             '          eid = {arXiv:1606.05250},\\n'\n",
      "             '        pages = {arXiv:1606.05250},\\n'\n",
      "             'archivePrefix = {arXiv},\\n'\n",
      "             '       eprint = {1606.05250},\\n'\n",
      "             '}',\n",
      " 'description': 'Stanford Question Answering Dataset (SQuAD) is a reading '\n",
      "                'comprehension dataset, consisting of questions posed by '\n",
      "                'crowdworkers on a set of Wikipedia articles, where the answer '\n",
      "                'to every question is a segment of text, or span, from the '\n",
      "                'corresponding reading passage, or the question might be '\n",
      "                'unanswerable.',\n",
      " 'etag': '\"76740beadcb478d2255f2f2ef0141e24\"',\n",
      " 'id': 'squad',\n",
      " 'key': 'datasets/datasets/squad/squad.py',\n",
      " 'lastModified': '2020-09-15T08:26:32.000Z',\n",
      " 'numModels': 23,\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/plain_text/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/plain_text/1.0.0/dummy_data/dev'),\n",
      "              datasets.S3Object('dummy/plain_text/1.0.0/dummy_data/train'),\n",
      "              datasets.S3Object('squad.py')],\n",
      " 'size': 5239}\n"
     ]
    }
   ],
   "source": [
    "# You can access various attributes of the datasets before downloading them\n",
    "squad_dataset = list_datasets(with_details=True)[datasets.index('squad')]\n",
    "\n",
    "pprint(squad_dataset.__dict__)  # It's a simple python dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰Dataset len(dataset): 1057\n",
      "\n",
      "ðŸ‘‰First item 'dataset[0]':\n",
      "{'answers': {'answer_start': [177, 177, 177],\n",
      "             'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']},\n",
      " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
      "            'champion of the National Football League (NFL) for the 2015 '\n",
      "            'season. The American Football Conference (AFC) champion Denver '\n",
      "            'Broncos defeated the National Football Conference (NFC) champion '\n",
      "            'Carolina Panthers 24â€“10 to earn their third Super Bowl title. The '\n",
      "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
      "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
      "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
      "            'with various gold-themed initiatives, as well as temporarily '\n",
      "            'suspending the tradition of naming each Super Bowl game with '\n",
      "            'Roman numerals (under which the game would have been known as '\n",
      "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
      "            'Arabic numerals 50.',\n",
      " 'id': '56be4db0acb8001400a502ec',\n",
      " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
      " 'title': 'Super_Bowl_50'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('squad', split=\"validation[:10%]\")\n",
    "print(f\"ðŸ‘‰Dataset len(dataset): {len(dataset)}\")\n",
    "print(\"\\nðŸ‘‰First item 'dataset[0]':\")\n",
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the dataset with `dataset.map`\n",
    "\n",
    "Now that we know how to inspect our dataset we also want to update it. For that there is a powerful method `.map()` which is inspired by `tf.data` map method and that you can use to apply a function to each examples, independently or in batch.\n",
    "\n",
    "`.map()` takes a callable accepting a dict as argument (same dict as the one returned by `dataset[i]`) and iterate over the dataset by calling the function on each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775,"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4dd98aa1594bf988ce907bf20904dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1057.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,775,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,637,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,347,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,394,179,179,179,179,179,179,179,179,179,179,179,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,168,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,638,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,704,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,917,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1271,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,2060,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,929,704,704,704,704,704,704,704,704,704,704,704,704,704,704,353,353,353,353,353,353,353,353,353,353,353,353,353,353,353,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,306,306,306,306,306,306,306,306,306,306,306,306,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,372,496,496,496,496,496,496,496,496,496,496,496,496,496,496,496,260,260,260,260,260,260,260,260,260,874,874,874,874,874,874,874,874,874,874,874,874,874,874,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,1025,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,176,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,782,536,536,536,536,536,536,536,536,536,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,666,495,495,495,495,495,495,495,495,495,495,495,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,385,441,441,441,441,441,441,441,441,441,441,441,357,357,357,357,357,357,357,357,357,296,296,296,296,296,296,296,296,296,296,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,644,804,804,804,804,804,804,804,804,804,804,804,397,397,397,397,397,397,397,397,397,397,397,397,397,397,360,360,360,360,360,360,360,973,973,973,973,973,973,973,973,973,973,973,973,973,973,263,263,263,263,263,263,263,263,263,263,263,568,568,568,568,568,568,568,568,568,568,568,264,264,264,264,264,264,264,264,264,264,264,264,264,264,264,892,892,892,892,892,892,892,892,892,892,892,206,206,206,206,206,489,489,489,489,489,489,489,489,489,489,489,489,489,181,181,181,181,181,181,181,181,181,181,181,181,531,531,531,531,531,531,531,531,531,531,531,531,664,664,664,664,664,664,664,664,664,664,664,664,664,664,672,672,672,672,672,672,672,672,672,672,672,672,672,672,858,858,858,858,858,858,858,858,858,858,858,858,634,634,634,634,634,634,634,634,634,634,634,634,634,634,891,891,891,891,891,891,891,891,891,891,891,891,891,488,488,488,488,488,488,488,488,488,488,488,488,942,942,942,942,942,942,942,942,942,942,942,942,942,942,942,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1162,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,1353,522,522,522,522,522,1643,1643,1643,1643,1643,628,628,628,628,628,758,758,758,758,758,883,883,883,883,883,559,559,559,559,559,603,603,603,603,631,631,631,631,631,626,626,626,626,626,541,541,541,541,541,795,795,795,795,795,591,591,591,591,591,568,568,568,568,568,536,536,536,536,536,575,575,575,575,575,571,571,571,571,571,641,641,641,641,641,665,665,665,665,665,1088,1088,1088,1088,1088,1619,1619,1619,1619,1619,939,939,939,939,939,865,865,865,865,865,711,711,711,711,711,831,831,831,831,831,501,501,501,501,501,676,676,676,676,676,854,854,854,854,854,784,784,784,784,784,641,641,641,641,641,544,544,544,544,544,918,918,918,918,918,763,763,763,763,763,906,906,906,906,906,632,632,632,632,632,869,869,869,869,869,1044,1044,1044,1044,1044,760,760,760,760,760,715,715,715,715,715,838,838,838,838,838,881,881,881,881,881,940,940,940,940,940,618,618,618,618,618,1205,1205,1205,534,534,534,534,534,757,757,757,757,757,1239,1239,1239,1239,1239,609,609,609,609,609,798,798,798,798,798,613,613,613,613,613,613,613,613,613,613,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 1057\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(lambda example: print(len(example['context']), end=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-b77390bfc6185d83.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My cutest title: Super_Bowl_50', 'My cutest title: Warsaw']\n"
     ]
    }
   ],
   "source": [
    "# Since the input example dict is updated with our function output dict,\n",
    "# we can actually just return the updated 'title' field\n",
    "titled_dataset = dataset.map(lambda example: {'title': 'My cutest title: ' + example['title']})\n",
    "\n",
    "print(titled_dataset.unique('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-6bd4c36d58a9620a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answers', 'context', 'id', 'new_title', 'question']\n",
      "['Wouhahh: Super_Bowl_50', 'Wouhahh: Warsaw']\n"
     ]
    }
   ],
   "source": [
    "# This will remove the 'title' column while doing the update (after having send it the the mapped function so you can use it in your function!)\n",
    "less_columns_dataset = dataset.map(lambda example: {'new_title': 'Wouhahh: ' + example['title']}, remove_columns=['title'])\n",
    "\n",
    "print(less_columns_dataset.column_names)\n",
    "print(less_columns_dataset.unique('new_title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using examples indices\n",
    "With `with_indices=True`, dataset indices (from `0` to `len(dataset)`) will be supplied to the function which must thus have the following signature: `function(example: dict, indice: int) -> dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-5ec89c9f36e5b090.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0: Which NFL team represented the AFC at Super Bowl 50?',\n",
      " '1: Which NFL team represented the NFC at Super Bowl 50?',\n",
      " '2: Where did Super Bowl 50 take place?',\n",
      " '3: Which NFL team won Super Bowl 50?',\n",
      " '4: What color was used to emphasize the 50th anniversary of the Super Bowl?']\n"
     ]
    }
   ],
   "source": [
    "# This will add the index in the dataset to the 'question' field\n",
    "with_indices_dataset = dataset.map(lambda example, idx: {'question': f'{idx}: ' + example['question']},\n",
    "                                   with_indices=True)\n",
    "\n",
    "pprint(with_indices_dataset['question'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets as nlp\n",
    "from transformers import LongformerTokenizerFast\n",
    "import transformers\n",
    "\n",
    "\n",
    "def get_correct_alignement(context, answer):\n",
    "    \"\"\" Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here. \"\"\"\n",
    "    gold_text = answer['text'][0]\n",
    "    start_idx = answer['answer_start'][0]\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "        return start_idx, end_idx       # When the gold label position is good\n",
    "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "        return start_idx-1, end_idx-1   # When the gold label is off by one character\n",
    "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "        return start_idx-2, end_idx-2   # When the gold label is off by two character\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    input_pairs = [example['question'], example['context']]\n",
    "    encodings = tokenizer.encode_plus(input_pairs, pad_to_max_length=True, max_length=512)\n",
    "    context_encodings = tokenizer.encode_plus(example['context'])\n",
    "    \n",
    "\n",
    "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methodes.\n",
    "    # this will give us the position of answer span in the context text\n",
    "    start_idx, end_idx = get_correct_alignement(example['context'], example['answers'])\n",
    "    start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "    end_positions_context = context_encodings.char_to_token(end_idx-1)\n",
    "\n",
    "    # here we will compute the start and end position of the answer in the whole example\n",
    "    # as the example is encoded like this <s> question</s></s> context</s>\n",
    "    # and we know the postion of the answer in the context\n",
    "    # we can just find out the index of the sep token and then add that to position + 1 (+1 because there are two sep tokens)\n",
    "    # this will give us the position of the answer span in whole example \n",
    "    sep_idx = encodings['input_ids'].index(tokenizer.sep_token_id)\n",
    "    start_positions = start_positions_context + sep_idx + 1\n",
    "    end_positions = end_positions_context + sep_idx + 1\n",
    "\n",
    "    if end_positions > 512:\n",
    "        start_positions, end_positions = 0, 0\n",
    "\n",
    "    encodings.update({'start_positions': start_positions,\n",
    "                      'end_positions': end_positions,\n",
    "                      'attention_mask': encodings['attention_mask']})\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Modifying the dataset with batched updates\n",
    "\n",
    "`.map()` can also work with batch of examples (slices of the dataset).\n",
    "\n",
    "This is particularly interesting if you have a function that can handle batch of inputs like the tokenizers of HuggingFace `tokenizers`.\n",
    "\n",
    "To work on batched inputs set `batched=True` when calling `.map()` and supply a function with the following signature: `function(examples: Dict[List]) -> Dict[List]` or, if you use indices, `function(examples: Dict[List], indices: List[int]) -> Dict[List]`).\n",
    "\n",
    "Bascially, your function should accept an input with the format of a slice of the dataset: `function(dataset[:10])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import a fast tokenizer that can work on batched inputs\n",
    "# (the 'Fast' tokenizers in HuggingFace)\n",
    "from transformers import BertTokenizerFast, logging as transformers_logging\n",
    "\n",
    "#transformers_logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-fe1d89e061918ba8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_dataset[0]\n",
      "{'answers': {'answer_start': [177, 177, 177],\n",
      "             'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']},\n",
      " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1],\n",
      " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
      "            'champion of the National Football League (NFL) for the 2015 '\n",
      "            'season. The American Football Conference (AFC) champion Denver '\n",
      "            'Broncos defeated the National Football Conference (NFC) champion '\n",
      "            'Carolina Panthers 24â€“10 to earn their third Super Bowl title. The '\n",
      "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
      "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
      "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
      "            'with various gold-themed initiatives, as well as temporarily '\n",
      "            'suspending the tradition of naming each Super Bowl game with '\n",
      "            'Roman numerals (under which the game would have been known as '\n",
      "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
      "            'Arabic numerals 50.',\n",
      " 'id': '56be4db0acb8001400a502ec',\n",
      " 'input_ids': [101, 3198, 5308, 1851, 1108, 1126, 1237, 1709, 1342, 1106, 4959,\n",
      "               1103, 3628, 1104, 1103, 1305, 2289, 1453, 113, 4279, 114, 1111,\n",
      "               1103, 1410, 1265, 119, 1109, 1237, 2289, 3047, 113, 10402, 114,\n",
      "               3628, 7068, 14722, 2378, 1103, 1305, 2289, 3047, 113, 24743, 114,\n",
      "               3628, 2938, 13598, 1572, 782, 1275, 1106, 7379, 1147, 1503, 3198,\n",
      "               5308, 1641, 119, 1109, 1342, 1108, 1307, 1113, 1428, 128, 117,\n",
      "               1446, 117, 1120, 12388, 112, 188, 3339, 1107, 1103, 1727, 2948,\n",
      "               2410, 3894, 1120, 3364, 10200, 117, 1756, 119, 1249, 1142, 1108,\n",
      "               1103, 13163, 3198, 5308, 117, 1103, 2074, 13463, 1103, 107, 5404,\n",
      "               5453, 107, 1114, 1672, 2284, 118, 12005, 11751, 117, 1112, 1218,\n",
      "               1112, 7818, 28117, 20080, 16264, 1103, 3904, 1104, 10505, 1296,\n",
      "               3198, 5308, 1342, 1114, 2264, 183, 15447, 16179, 113, 1223, 1134,\n",
      "               1103, 1342, 1156, 1138, 1151, 1227, 1112, 107, 3198, 5308, 149,\n",
      "               107, 114, 117, 1177, 1115, 1103, 7998, 1180, 15199, 2672, 1103,\n",
      "               4944, 183, 15447, 16179, 1851, 119, 102],\n",
      " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
      " 'title': 'Super_Bowl_50',\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0]}\n"
     ]
    }
   ],
   "source": [
    "# Now let's batch tokenize our dataset 'context'\n",
    "encoded_dataset = dataset.map(lambda example: tokenizer(example['context']), batched=True)\n",
    "\n",
    "print(\"encoded_dataset[0]\")\n",
    "pprint(encoded_dataset[0], compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answers', 'context', 'id', 'question', 'title']\n"
     ]
    }
   ],
   "source": [
    "# we have added additional columns\n",
    "pprint(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-7d12784efbf12a37.arrow\n"
     ]
    }
   ],
   "source": [
    "# Let show a more complex processing with the full preparation of the SQuAD dataset\n",
    "# for training a model from Transformers\n",
    "def convert_to_features(batch):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    input_pairs = list(zip())\n",
    "    encodings = tokenizer(batch['context'], batch['question'], truncation=True)\n",
    "\n",
    "    # Compute start and end tokens for labels\n",
    "    start_positions, end_positions = [], []\n",
    "    for i, answer in enumerate(batch['answers']):\n",
    "        first_char = answer['answer_start'][0]\n",
    "        last_char = first_char + len(answer['text'][0]) - 1\n",
    "        start_positions.append(encodings.char_to_token(i, first_char))\n",
    "        end_positions.append(encodings.char_to_token(i, last_char))\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "    return encodings\n",
    "\n",
    "encoded_dataset = dataset.map(convert_to_features, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_names ['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions', 'title', 'token_type_ids']\n",
      "start_positions [34, 45, 80, 34, 98]\n"
     ]
    }
   ],
   "source": [
    "# Now our dataset comprise the labels for the start and end position\n",
    "# as well as the offsets for converting back tokens\n",
    "# in span of the original string for evaluation\n",
    "print(\"column_names\", encoded_dataset.column_names)\n",
    "print(\"start_positions\", encoded_dataset[:5]['start_positions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## formatting outputs for PyTorch, Tensorflow, Numpy, Pandas\n",
    "\n",
    "Now that we have tokenized our inputs, we probably want to use this dataset in a `torch.Dataloader` or a `tf.data.Dataset`.\n",
    "\n",
    "To be able to do this we need to tweak two things:\n",
    "\n",
    "- format the indexing (`__getitem__`) to return numpy/pytorch/tensorflow tensors, instead of python objects, and probably\n",
    "- format the indexing (`__getitem__`) to return only the subset of the columns that we need for our model inputs.\n",
    "\n",
    "  We don't want the columns `id` or `title` as inputs to train our model, but we could still want to keep them in the dataset, for instance for the evaluation of the model.\n",
    "    \n",
    "This is handled by the `.set_format(type: Union[None, str], columns: Union[None, str, List[str]])` where:\n",
    "\n",
    "- `type` define the return type for our dataset `__getitem__` method and is one of `[None, 'numpy', 'pandas', 'torch', 'tensorflow']` (`None` means return python objects), and\n",
    "- `columns` define the columns returned by `__getitem__` and takes the name of a column in the dataset or a list of columns to return (`None` means return all columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1]),\n",
      " 'end_positions': tensor(46),\n",
      " 'input_ids': tensor([  101,  3198,  5308,  1851,  1108,  1126,  1237,  1709,  1342,  1106,\n",
      "         4959,  1103,  3628,  1104,  1103,  1305,  2289,  1453,   113,  4279,\n",
      "          114,  1111,  1103,  1410,  1265,   119,  1109,  1237,  2289,  3047,\n",
      "          113, 10402,   114,  3628,  7068, 14722,  2378,  1103,  1305,  2289,\n",
      "         3047,   113, 24743,   114,  3628,  2938, 13598,  1572,   782,  1275,\n",
      "         1106,  7379,  1147,  1503,  3198,  5308,  1641,   119,  1109,  1342,\n",
      "         1108,  1307,  1113,  1428,   128,   117,  1446,   117,  1120, 12388,\n",
      "          112,   188,  3339,  1107,  1103,  1727,  2948,  2410,  3894,  1120,\n",
      "         3364, 10200,   117,  1756,   119,  1249,  1142,  1108,  1103, 13163,\n",
      "         3198,  5308,   117,  1103,  2074, 13463,  1103,   107,  5404,  5453,\n",
      "          107,  1114,  1672,  2284,   118, 12005, 11751,   117,  1112,  1218,\n",
      "         1112,  7818, 28117, 20080, 16264,  1103,  3904,  1104, 10505,  1296,\n",
      "         3198,  5308,  1342,  1114,  2264,   183, 15447, 16179,   113,  1223,\n",
      "         1134,  1103,  1342,  1156,  1138,  1151,  1227,  1112,   107,  3198,\n",
      "         5308,   149,   107,   114,   117,  1177,  1115,  1103,  7998,  1180,\n",
      "        15199,  2672,  1103,  4944,   183, 15447, 16179,  1851,   119,   102,\n",
      "         5979,  4279,  1264,  2533,  1103, 24743,  1120,  3198,  5308,  1851,\n",
      "          136,   102]),\n",
      " 'start_positions': tensor(45),\n",
      " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "columns_to_return = ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "\n",
    "encoded_dataset.set_format(type='torch', columns=columns_to_return)\n",
    "\n",
    "# Our dataset indexing output is now ready for being used in a pytorch dataloader\n",
    "pprint(encoded_dataset[1], compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answers', 'attention_mask', 'context', 'end_positions', 'id', 'input_ids', 'question', 'start_positions', 'title', 'token_type_ids']\n"
     ]
    }
   ],
   "source": [
    "# Note that the columns are not removed from the dataset, just not returned when calling __getitem__\n",
    "# Similarly the inner type of the dataset is not changed to torch.Tensor, the conversion and filtering is done on-the-fly when querying the dataset\n",
    "print(encoded_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [249, 249, 249],\n",
      "             'text': ['Carolina Panthers', 'Carolina Panthers',\n",
      "                      'Carolina Panthers']},\n",
      " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'context': 'Super Bowl 50 was an American football game to determine the '\n",
      "            'champion of the National Football League (NFL) for the 2015 '\n",
      "            'season. The American Football Conference (AFC) champion Denver '\n",
      "            'Broncos defeated the National Football Conference (NFC) champion '\n",
      "            'Carolina Panthers 24â€“10 to earn their third Super Bowl title. The '\n",
      "            \"game was played on February 7, 2016, at Levi's Stadium in the San \"\n",
      "            'Francisco Bay Area at Santa Clara, California. As this was the '\n",
      "            '50th Super Bowl, the league emphasized the \"golden anniversary\" '\n",
      "            'with various gold-themed initiatives, as well as temporarily '\n",
      "            'suspending the tradition of naming each Super Bowl game with '\n",
      "            'Roman numerals (under which the game would have been known as '\n",
      "            '\"Super Bowl L\"), so that the logo could prominently feature the '\n",
      "            'Arabic numerals 50.',\n",
      " 'end_positions': 46,\n",
      " 'id': '56be4db0acb8001400a502ed',\n",
      " 'input_ids': [101, 3198, 5308, 1851, 1108, 1126, 1237, 1709, 1342, 1106, 4959,\n",
      "               1103, 3628, 1104, 1103, 1305, 2289, 1453, 113, 4279, 114, 1111,\n",
      "               1103, 1410, 1265, 119, 1109, 1237, 2289, 3047, 113, 10402, 114,\n",
      "               3628, 7068, 14722, 2378, 1103, 1305, 2289, 3047, 113, 24743, 114,\n",
      "               3628, 2938, 13598, 1572, 782, 1275, 1106, 7379, 1147, 1503, 3198,\n",
      "               5308, 1641, 119, 1109, 1342, 1108, 1307, 1113, 1428, 128, 117,\n",
      "               1446, 117, 1120, 12388, 112, 188, 3339, 1107, 1103, 1727, 2948,\n",
      "               2410, 3894, 1120, 3364, 10200, 117, 1756, 119, 1249, 1142, 1108,\n",
      "               1103, 13163, 3198, 5308, 117, 1103, 2074, 13463, 1103, 107, 5404,\n",
      "               5453, 107, 1114, 1672, 2284, 118, 12005, 11751, 117, 1112, 1218,\n",
      "               1112, 7818, 28117, 20080, 16264, 1103, 3904, 1104, 10505, 1296,\n",
      "               3198, 5308, 1342, 1114, 2264, 183, 15447, 16179, 113, 1223, 1134,\n",
      "               1103, 1342, 1156, 1138, 1151, 1227, 1112, 107, 3198, 5308, 149,\n",
      "               107, 114, 117, 1177, 1115, 1103, 7998, 1180, 15199, 2672, 1103,\n",
      "               4944, 183, 15447, 16179, 1851, 119, 102, 5979, 4279, 1264, 2533,\n",
      "               1103, 24743, 1120, 3198, 5308, 1851, 136, 102],\n",
      " 'question': 'Which NFL team represented the NFC at Super Bowl 50?',\n",
      " 'start_positions': 45,\n",
      " 'title': 'Super_Bowl_50',\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# We can remove the formatting with `.reset_format()`\n",
    "# or, identically, a call to `.set_format()` with no arguments\n",
    "encoded_dataset.reset_format()\n",
    "\n",
    "pprint(encoded_dataset[1], compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columns': ['answers',\n",
      "             'attention_mask',\n",
      "             'context',\n",
      "             'end_positions',\n",
      "             'id',\n",
      "             'input_ids',\n",
      "             'question',\n",
      "             'start_positions',\n",
      "             'title',\n",
      "             'token_type_ids'],\n",
      " 'format_kwargs': {},\n",
      " 'output_all_columns': False,\n",
      " 'type': None}\n"
     ]
    }
   ],
   "source": [
    "# The current format can be checked with `.format`,\n",
    "# which is a dict of the type and formatting\n",
    "pprint(encoded_dataset.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping this all up (PyTorch)\n",
    "\n",
    "Let's wrap this all up with the full code to load and prepare SQuAD for training a PyTorch model from HuggingFace `transformers` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n",
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-79b1c52fc2135264.arrow\n",
      "Loading cached processed dataset at /.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41/cache-dfd96949f14699ec.arrow\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load our training dataset and tokenizer\n",
    "dataset = load_dataset('squad')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "def get_correct_alignement(context, answer):\n",
    "    \"\"\" Some original examples in SQuAD have indices wrong by 1 or 2 character. We test and fix this here. \"\"\"\n",
    "    gold_text = answer['text'][0]\n",
    "    start_idx = answer['answer_start'][0]\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "    if context[start_idx:end_idx] == gold_text:\n",
    "        return start_idx, end_idx       # When the gold label position is good\n",
    "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "        return start_idx-1, end_idx-1   # When the gold label is off by one character\n",
    "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "        return start_idx-2, end_idx-2   # When the gold label is off by two character\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "# Tokenize our training dataset\n",
    "def convert_to_features(example_batch):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    encodings = tokenizer(example_batch['context'], example_batch['question'], truncation=True)\n",
    "\n",
    "    # Compute start and end tokens for labels using Transformers's fast tokenizers alignement methods.\n",
    "    start_positions, end_positions = [], []\n",
    "    for i, (context, answer) in enumerate(zip(example_batch['context'], example_batch['answers'])):\n",
    "        start_idx, end_idx = get_correct_alignement(context, answer)\n",
    "        start_positions.append(encodings.char_to_token(i, start_idx))\n",
    "        end_positions.append(encodings.char_to_token(i, end_idx-1))\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "    return encodings\n",
    "\n",
    "encoded_dataset = dataset.map(convert_to_features, batched=True)\n",
    "\n",
    "# Format our dataset to outputs torch.Tensor to train a pytorch model\n",
    "columns = ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "encoded_dataset.set_format(type='torch', columns=columns)\n",
    "\n",
    "# Instantiate a PyTorch Dataloader around our dataset\n",
    "# Let's do dynamic batching (pad on the fly with our own collate_fn)\n",
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, return_tensors='pt')\n",
    "dataloader = torch.utils.data.DataLoader(encoded_dataset['train'], collate_fn=collate_fn, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing BertForQuestionAnswering: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Let's load a pretrained Bert model and a simple optimizer\n",
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('distilbert-base-cased', return_dict=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - loss: 5.88\n",
      "Step 1 - loss: 5.69\n",
      "Step 2 - loss: 5.22\n",
      "Step 3 - loss: 5.61\n",
      "Step 4 - loss: 5.21\n",
      "Step 5 - loss: 5.6\n",
      "Step 6 - loss: 5.54\n"
     ]
    }
   ],
   "source": [
    "# Now let's train our model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model.train().to(device)\n",
    "for i, batch in enumerate(dataloader):\n",
    "    batch.to(device)\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "    print(f'Step {i} - loss: {loss:.3}')\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "sacrebleu_metric = load_metric('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'end_positions': tensor([126,  45,  69,  96,  27,  53,  89, 117]), 'input_ids': tensor([[  101, 22182,  1193,  ...,     0,     0,     0],\n",
       "        [  101, 22182,  1193,  ...,     0,     0,     0],\n",
       "        [  101, 22182,  1193,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1249,  1120,  ...,  5550,   136,   102],\n",
       "        [  101,  1249,  1120,  ...,   136,   102,     0],\n",
       "        [  101,  1249,  1120,  ...,     0,     0,     0]]), 'start_positions': tensor([120,  41,  67,  90,  21,  52,  89, 116]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-93c24c520590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   2964\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2965\u001b[0m             )\n\u001b[0;32m-> 2966\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2967\u001b[0m         ]\n\u001b[1;32m   2968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2964\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2965\u001b[0m             )\n\u001b[0;32m-> 2966\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2967\u001b[0m         ]\n\u001b[1;32m   2968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3000\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3001\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3002\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3003\u001b[0m         )\n\u001b[1;32m   3004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "sacrebleu_metric = load_metric('sacrebleu')\n",
    " \n",
    "# If you only have a single iteration, you can easily compute the score like this\n",
    "predictions = model(inputs)\n",
    "score = sacrebleu_metric.compute(predictions, references)\n",
    " \n",
    "# If you have a loop, you can \"add\" your predictions and references at each iteration instead of having to save them yourself (the metric object store them efficiently for you)\n",
    "for batch in dataloader:\n",
    "    model_input, targets = batch\n",
    "    predictions = model(model_inputs)\n",
    "    sacrebleu_metric.add_batch(predictions, targets)\n",
    "score = sacrebleu_metric.compute()  # Compute the score from all the stored predictions/references"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
