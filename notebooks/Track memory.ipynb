{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 17:18:07,664:INFO: hello\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import sys,logging\n",
    "logging.root.handlers = []\n",
    "logging.basicConfig(level=\"INFO\", format = '%(asctime)s:%(levelname)s: %(message)s' ,stream = sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory():\n",
    "    logger.info('GPU memory: %.1f' % (torch.cuda.memory_allocated() // 1024 ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 17:18:14,725:INFO: GPU memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:46:27,983:INFO: Lock 139878498884944 acquired on /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
      "2020-10-19 11:46:27,985:INFO: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /.cache/torch/transformers/tmpvuzuom97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611e25c14b384f86ab6bf2e672198948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-19 11:46:28,438:INFO: storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2020-10-19 11:46:28,440:INFO: creating metadata file for /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2020-10-19 11:46:28,441:INFO: Lock 139878498884944 released on /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
      "2020-10-19 11:46:28,442:INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2020-10-19 11:46:28,443:INFO: Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-19 11:46:28,585:INFO: Lock 139878323310416 acquired on /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
      "2020-10-19 11:46:28,588:INFO: https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /.cache/torch/transformers/tmpnresv4kv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4eab1e262c404785df15532f2a04b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-19 11:46:40,673:INFO: storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-10-19 11:46:40,674:INFO: creating metadata file for /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-10-19 11:46:40,675:INFO: Lock 139878323310416 released on /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
      "2020-10-19 11:46:40,676:INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-10-19 11:46:43,435:WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2020-10-19 11:46:43,436:WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-10-19 11:46:43,437:INFO: moving model to GPU\n",
      "2020-10-19 11:46:46,555:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "logger.info('moving model to GPU')\n",
    "gpu_model = model.to(device)\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run classification for a batch of 64 tensors\n",
    "def run_bert(x):\n",
    "    check_memory()\n",
    "    logger.info('moving tensors to GPU')\n",
    "    x = x.to(device)\n",
    "    check_memory()\n",
    "    logger.info('Running bert forward on x')\n",
    "    yhat = gpu_model(x)\n",
    "    check_memory()\n",
    "    logger.info(f'yhat[0].requires_grad = {yhat[0].requires_grad} . Detaching yhat')\n",
    "    yhat = yhat[0].detach()\n",
    "    logger.info(f'x shape = {x.shape}, yhat.shape = {yhat.shape}')\n",
    "    check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:47:16,402:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:16,403:INFO: moving tensors to GPU\n",
      "2020-10-19 11:47:16,420:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:16,421:INFO: Running bert forward on x\n",
      "2020-10-19 11:47:16,796:INFO: GPU memory: 1013.0\n",
      "2020-10-19 11:47:16,797:INFO: yhat[0].requires_grad = True . Detaching yhat\n",
      "2020-10-19 11:47:16,799:INFO: x shape = torch.Size([1, 512]), yhat.shape = torch.Size([1, 2])\n",
      "2020-10-19 11:47:16,800:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low =1000, high = 30000 , size = (1,512))\n",
    "run_bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:47:37,874:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:37,876:INFO: moving tensors to GPU\n",
      "2020-10-19 11:47:37,892:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:37,892:INFO: Running bert forward on x\n",
      "2020-10-19 11:47:37,909:INFO: GPU memory: 1013.0\n",
      "2020-10-19 11:47:37,909:INFO: yhat[0].requires_grad = True . Detaching yhat\n",
      "2020-10-19 11:47:37,911:INFO: x shape = torch.Size([1, 512]), yhat.shape = torch.Size([1, 2])\n",
      "2020-10-19 11:47:37,912:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "gpu_model.eval()\n",
    "run_bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With no grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:47:55,452:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:55,454:INFO: moving tensors to GPU\n",
      "2020-10-19 11:47:55,477:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:47:55,477:INFO: Running bert forward on x\n",
      "2020-10-19 11:47:55,492:INFO: GPU memory: 1013.0\n",
      "2020-10-19 11:47:55,493:INFO: yhat[0].requires_grad = True . Detaching yhat\n",
      "2020-10-19 11:47:55,494:INFO: x shape = torch.Size([1, 512]), yhat.shape = torch.Size([1, 2])\n",
      "2020-10-19 11:47:55,495:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad=False\n",
    "run_bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:51:58,340:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:51:58,341:INFO: moving tensors to GPU\n",
      "2020-10-19 11:51:58,372:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:51:58,373:INFO: Running bert forward on x\n",
      "2020-10-19 11:51:58,404:INFO: GPU memory: 636.0\n",
      "2020-10-19 11:51:58,405:INFO: yhat[0].requires_grad = True . Detaching yhat\n",
      "2020-10-19 11:51:58,406:INFO: x shape = torch.Size([1, 256]), yhat.shape = torch.Size([1, 2])\n",
      "2020-10-19 11:51:58,407:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low =1000, high = 30000 , size = (1,256))\n",
    "run_bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max len 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:52:30,793:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:52:30,794:INFO: moving tensors to GPU\n",
      "2020-10-19 11:52:30,811:INFO: GPU memory: 418.0\n",
      "2020-10-19 11:52:30,812:INFO: Running bert forward on x\n",
      "2020-10-19 11:52:30,828:INFO: GPU memory: 518.0\n",
      "2020-10-19 11:52:30,829:INFO: yhat[0].requires_grad = True . Detaching yhat\n",
      "2020-10-19 11:52:30,830:INFO: x shape = torch.Size([1, 128]), yhat.shape = torch.Size([1, 2])\n",
      "2020-10-19 11:52:30,831:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low =1000, high = 30000 , size = (1,128))\n",
    "run_bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkin max batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run classification for a batch of 64 tensors\n",
    "def run_max_batch_analysis(gpu_model,  nograd = False, seq_len = 512):\n",
    "    def run_bert(x):\n",
    "        check_memory()\n",
    "        x = x.to(device)\n",
    "        yhat = gpu_model(x)\n",
    "        logger.info(f'x shape = {x.shape}, yhat.shape = {yhat[0].shape}')\n",
    "        check_memory()\n",
    "        \n",
    "    def run_bert_nograd(x):\n",
    "        with torch.no_grad():\n",
    "            check_memory()\n",
    "            x = x.to(device)\n",
    "            yhat = gpu_model(x)\n",
    "            logger.info(f'x shape = {x.shape}, yhat.shape = {yhat[0].shape}')\n",
    "            check_memory()\n",
    "\n",
    "\n",
    "    for batch in (4,8,16,32,64,128,256,512):\n",
    "        try:\n",
    "            x = torch.randint(low =1000, high = 30000 , size = (batch,seq_len))\n",
    "            run_bert_nograd(x) if nograd else run_bert(x)\n",
    "            logger.info(f'batch size {batch} successful.')\n",
    "        except Exception as e:\n",
    "            print(f'exception {type(e)} : {e}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:53:54,140:INFO: GPU memory: 418.0\n"
     ]
    }
   ],
   "source": [
    "del gpu_model\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:54:03,919:INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2020-10-19 11:54:03,921:INFO: Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-19 11:54:04,077:INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-10-19 11:54:06,941:WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2020-10-19 11:54:06,944:WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-10-19 11:54:07,074:INFO: GPU memory: 837.0\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "gpu_model = model.to(device)\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:54:13,735:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:13,778:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:54:13,779:INFO: GPU memory: 3154.0\n",
      "2020-10-19 11:54:13,780:INFO: batch size 4 successful.\n",
      "2020-10-19 11:54:13,782:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:13,819:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:54:13,819:INFO: GPU memory: 5470.0\n",
      "2020-10-19 11:54:13,820:INFO: batch size 8 successful.\n",
      "2020-10-19 11:54:13,822:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:13,919:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:54:13,920:INFO: GPU memory: 10103.0\n",
      "2020-10-19 11:54:13,921:INFO: batch size 16 successful.\n",
      "2020-10-19 11:54:13,922:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:14,120:INFO: x shape = torch.Size([32, 512]), yhat.shape = torch.Size([32, 2])\n",
      "2020-10-19 11:54:14,122:INFO: GPU memory: 19368.0\n",
      "2020-10-19 11:54:14,123:INFO: batch size 32 successful.\n",
      "2020-10-19 11:54:14,124:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:14,467:INFO: x shape = torch.Size([64, 512]), yhat.shape = torch.Size([64, 2])\n",
      "2020-10-19 11:54:14,469:INFO: GPU memory: 37900.0\n",
      "2020-10-19 11:54:14,470:INFO: batch size 64 successful.\n",
      "2020-10-19 11:54:14,471:INFO: GPU memory: 837.0\n",
      "exception <class 'RuntimeError'> : CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 47.46 GiB total capacity; 45.64 GiB already allocated; 847.00 MiB free; 45.72 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### seq len 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:54:53,871:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:53,902:INFO: x shape = torch.Size([4, 128]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:54:53,903:INFO: GPU memory: 1218.0\n",
      "2020-10-19 11:54:53,904:INFO: batch size 4 successful.\n",
      "2020-10-19 11:54:53,905:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:53,918:INFO: x shape = torch.Size([8, 128]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:54:53,919:INFO: GPU memory: 1564.0\n",
      "2020-10-19 11:54:53,920:INFO: batch size 8 successful.\n",
      "2020-10-19 11:54:53,921:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:53,941:INFO: x shape = torch.Size([16, 128]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:54:53,942:INFO: GPU memory: 2290.0\n",
      "2020-10-19 11:54:53,943:INFO: batch size 16 successful.\n",
      "2020-10-19 11:54:53,945:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:53,986:INFO: x shape = torch.Size([32, 128]), yhat.shape = torch.Size([32, 2])\n",
      "2020-10-19 11:54:53,987:INFO: GPU memory: 3742.0\n",
      "2020-10-19 11:54:53,988:INFO: batch size 32 successful.\n",
      "2020-10-19 11:54:53,989:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:54,068:INFO: x shape = torch.Size([64, 128]), yhat.shape = torch.Size([64, 2])\n",
      "2020-10-19 11:54:54,069:INFO: GPU memory: 6647.0\n",
      "2020-10-19 11:54:54,070:INFO: batch size 64 successful.\n",
      "2020-10-19 11:54:54,071:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:54,225:INFO: x shape = torch.Size([128, 128]), yhat.shape = torch.Size([128, 2])\n",
      "2020-10-19 11:54:54,226:INFO: GPU memory: 12457.0\n",
      "2020-10-19 11:54:54,227:INFO: batch size 128 successful.\n",
      "2020-10-19 11:54:54,229:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:54,503:INFO: x shape = torch.Size([256, 128]), yhat.shape = torch.Size([256, 2])\n",
      "2020-10-19 11:54:54,504:INFO: GPU memory: 24076.0\n",
      "2020-10-19 11:54:54,505:INFO: batch size 256 successful.\n",
      "2020-10-19 11:54:54,507:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:54:55,070:INFO: x shape = torch.Size([512, 128]), yhat.shape = torch.Size([512, 2])\n",
      "2020-10-19 11:54:55,071:INFO: GPU memory: 47316.0\n",
      "2020-10-19 11:54:55,072:INFO: batch size 512 successful.\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model,False,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lesser sequence length, the memory usage decreases with same ratio for all batch sizes. For example,\n",
    "\n",
    "Batch size 4 : memory consumed in forward pass\n",
    "\n",
    "512 seq length = 3610-418 = 3192\n",
    "\n",
    "128 seq length = 1009-418 = 591\n",
    "\n",
    "3192/591 = 5.4\n",
    "\n",
    "512/128 = 4\n",
    "\n",
    "Batch size 8 : memory consumed in forward pass\n",
    "\n",
    "512 seq length = 6803-418 = 6385\n",
    "\n",
    "128 seq length = 1582 -418 = 1164\n",
    "\n",
    "6384/1187 = 5.48\n",
    "\n",
    "512/128 = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### No grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:55:38,478:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,504:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:55:38,505:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,506:INFO: batch size 4 successful.\n",
      "2020-10-19 11:55:38,508:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,560:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:55:38,561:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,562:INFO: batch size 8 successful.\n",
      "2020-10-19 11:55:38,563:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,659:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:55:38,660:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,661:INFO: batch size 16 successful.\n",
      "2020-10-19 11:55:38,662:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,844:INFO: x shape = torch.Size([32, 512]), yhat.shape = torch.Size([32, 2])\n",
      "2020-10-19 11:55:38,845:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:38,846:INFO: batch size 32 successful.\n",
      "2020-10-19 11:55:38,848:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:39,185:INFO: x shape = torch.Size([64, 512]), yhat.shape = torch.Size([64, 2])\n",
      "2020-10-19 11:55:39,186:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:39,187:INFO: batch size 64 successful.\n",
      "2020-10-19 11:55:39,188:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:39,876:INFO: x shape = torch.Size([128, 512]), yhat.shape = torch.Size([128, 2])\n",
      "2020-10-19 11:55:39,877:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:39,877:INFO: batch size 128 successful.\n",
      "2020-10-19 11:55:39,880:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:41,637:INFO: x shape = torch.Size([256, 512]), yhat.shape = torch.Size([256, 2])\n",
      "2020-10-19 11:55:41,639:INFO: GPU memory: 838.0\n",
      "2020-10-19 11:55:41,640:INFO: batch size 256 successful.\n",
      "2020-10-19 11:55:41,644:INFO: GPU memory: 837.0\n",
      "2020-10-19 11:55:44,389:INFO: x shape = torch.Size([512, 512]), yhat.shape = torch.Size([512, 2])\n",
      "2020-10-19 11:55:44,390:INFO: GPU memory: 839.0\n",
      "2020-10-19 11:55:44,391:INFO: batch size 512 successful.\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model, nograd = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-2658f35f5b4e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-2658f35f5b4e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Bert Large\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Bert Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:56:12,991:INFO: GPU memory: 837.0\n"
     ]
    }
   ],
   "source": [
    "del gpu_model\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:56:23,050:INFO: Lock 139878315749008 acquired on /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8.lock\n",
      "2020-10-19 11:56:23,053:INFO: https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json not found in cache or force_download set to True, downloading to /.cache/torch/transformers/tmppp97817j\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef49d5616eb34af09eda395bf889359f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-19 11:56:23,531:INFO: storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json in cache at /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "2020-10-19 11:56:23,532:INFO: creating metadata file for /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "2020-10-19 11:56:23,533:INFO: Lock 139878315749008 released on /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8.lock\n",
      "2020-10-19 11:56:23,534:INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "2020-10-19 11:56:23,535:INFO: Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-19 11:56:23,614:INFO: Lock 139878315351888 acquired on /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6.lock\n",
      "2020-10-19 11:56:23,616:INFO: https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /.cache/torch/transformers/tmpxjkorbm8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf780dc59ba4767b3b82852452b3e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-19 11:57:00,835:INFO: storing https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin in cache at /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "2020-10-19 11:57:00,835:INFO: creating metadata file for /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "2020-10-19 11:57:00,836:INFO: Lock 139878315351888 released on /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6.lock\n",
      "2020-10-19 11:57:00,837:INFO: loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "2020-10-19 11:57:09,347:WARNING: Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2020-10-19 11:57:09,348:WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-10-19 11:57:09,701:INFO: GPU memory: 1697.0\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-large-uncased')\n",
    "gpu_model = model.to(device)\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:57:09,725:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:09,856:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:57:09,856:INFO: GPU memory: 7858.0\n",
      "2020-10-19 11:57:09,858:INFO: batch size 4 successful.\n",
      "2020-10-19 11:57:09,859:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:09,922:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:57:09,922:INFO: GPU memory: 14019.0\n",
      "2020-10-19 11:57:09,924:INFO: batch size 8 successful.\n",
      "2020-10-19 11:57:09,925:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:10,222:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:57:10,223:INFO: GPU memory: 26341.0\n",
      "2020-10-19 11:57:10,224:INFO: batch size 16 successful.\n",
      "2020-10-19 11:57:10,226:INFO: GPU memory: 1697.0\n",
      "exception <class 'RuntimeError'> : CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 47.46 GiB total capacity; 46.10 GiB already allocated; 417.00 MiB free; 46.14 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 128 seq len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:57:11,780:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:11,881:INFO: x shape = torch.Size([4, 128]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:57:11,881:INFO: GPU memory: 2662.0\n",
      "2020-10-19 11:57:11,883:INFO: batch size 4 successful.\n",
      "2020-10-19 11:57:11,884:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:11,912:INFO: x shape = torch.Size([8, 128]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:57:11,913:INFO: GPU memory: 3626.0\n",
      "2020-10-19 11:57:11,914:INFO: batch size 8 successful.\n",
      "2020-10-19 11:57:11,916:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:11,974:INFO: x shape = torch.Size([16, 128]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:57:11,975:INFO: GPU memory: 5554.0\n",
      "2020-10-19 11:57:11,976:INFO: batch size 16 successful.\n",
      "2020-10-19 11:57:11,977:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:12,097:INFO: x shape = torch.Size([32, 128]), yhat.shape = torch.Size([32, 2])\n",
      "2020-10-19 11:57:12,098:INFO: GPU memory: 9411.0\n",
      "2020-10-19 11:57:12,100:INFO: batch size 32 successful.\n",
      "2020-10-19 11:57:12,102:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:12,339:INFO: x shape = torch.Size([64, 128]), yhat.shape = torch.Size([64, 2])\n",
      "2020-10-19 11:57:12,340:INFO: GPU memory: 17125.0\n",
      "2020-10-19 11:57:12,341:INFO: batch size 64 successful.\n",
      "2020-10-19 11:57:12,343:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:12,813:INFO: x shape = torch.Size([128, 128]), yhat.shape = torch.Size([128, 2])\n",
      "2020-10-19 11:57:12,814:INFO: GPU memory: 32552.0\n",
      "2020-10-19 11:57:12,815:INFO: batch size 128 successful.\n",
      "2020-10-19 11:57:12,816:INFO: GPU memory: 1697.0\n",
      "exception <class 'RuntimeError'> : CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 47.46 GiB total capacity; 46.17 GiB already allocated; 221.00 MiB free; 46.33 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model,False,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### No grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:57:24,786:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:24,813:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 2])\n",
      "2020-10-19 11:57:24,815:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:24,815:INFO: batch size 4 successful.\n",
      "2020-10-19 11:57:24,817:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:24,968:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 2])\n",
      "2020-10-19 11:57:24,968:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:24,969:INFO: batch size 8 successful.\n",
      "2020-10-19 11:57:24,971:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:25,262:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 2])\n",
      "2020-10-19 11:57:25,263:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:25,263:INFO: batch size 16 successful.\n",
      "2020-10-19 11:57:25,265:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:25,817:INFO: x shape = torch.Size([32, 512]), yhat.shape = torch.Size([32, 2])\n",
      "2020-10-19 11:57:25,818:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:25,818:INFO: batch size 32 successful.\n",
      "2020-10-19 11:57:25,820:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:27,291:INFO: x shape = torch.Size([64, 512]), yhat.shape = torch.Size([64, 2])\n",
      "2020-10-19 11:57:27,293:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:27,294:INFO: batch size 64 successful.\n",
      "2020-10-19 11:57:27,296:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:29,475:INFO: x shape = torch.Size([128, 512]), yhat.shape = torch.Size([128, 2])\n",
      "2020-10-19 11:57:29,476:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:29,477:INFO: batch size 128 successful.\n",
      "2020-10-19 11:57:29,479:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:33,834:INFO: x shape = torch.Size([256, 512]), yhat.shape = torch.Size([256, 2])\n",
      "2020-10-19 11:57:33,836:INFO: GPU memory: 1698.0\n",
      "2020-10-19 11:57:33,837:INFO: batch size 256 successful.\n",
      "2020-10-19 11:57:33,841:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:57:42,638:INFO: x shape = torch.Size([512, 512]), yhat.shape = torch.Size([512, 2])\n",
      "2020-10-19 11:57:42,640:INFO: GPU memory: 1699.0\n",
      "2020-10-19 11:57:42,641:INFO: batch size 512 successful.\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model,nograd = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT for pretraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:58:18,628:INFO: GPU memory: 1697.0\n"
     ]
    }
   ],
   "source": [
    "del gpu_model\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:58:55,006:INFO: GPU memory: 1697.0\n",
      "2020-10-19 11:58:55,577:INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "2020-10-19 11:58:55,579:INFO: Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-19 11:58:55,759:INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "2020-10-19 11:58:58,731:INFO: All model checkpoint weights were used when initializing BertForPreTraining.\n",
      "\n",
      "2020-10-19 11:58:58,732:WARNING: Some weights of BertForPreTraining were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-10-19 11:58:58,918:INFO: GPU memory: 2118.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForPreTraining\n",
    "check_memory()\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "gpu_model = model.to(device)\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 11:59:07,219:INFO: GPU memory: 2118.0\n",
      "2020-10-19 11:59:07,257:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 512, 30522])\n",
      "2020-10-19 11:59:07,258:INFO: GPU memory: 4691.0\n",
      "2020-10-19 11:59:07,259:INFO: batch size 4 successful.\n",
      "2020-10-19 11:59:07,261:INFO: GPU memory: 2118.0\n",
      "2020-10-19 11:59:07,307:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 512, 30522])\n",
      "2020-10-19 11:59:07,308:INFO: GPU memory: 7264.0\n",
      "2020-10-19 11:59:07,309:INFO: batch size 8 successful.\n",
      "2020-10-19 11:59:07,310:INFO: GPU memory: 2118.0\n",
      "2020-10-19 11:59:07,470:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 512, 30522])\n",
      "2020-10-19 11:59:07,471:INFO: GPU memory: 12410.0\n",
      "2020-10-19 11:59:07,472:INFO: batch size 16 successful.\n",
      "2020-10-19 11:59:07,474:INFO: GPU memory: 2118.0\n",
      "2020-10-19 11:59:07,664:INFO: x shape = torch.Size([32, 512]), yhat.shape = torch.Size([32, 512, 30522])\n",
      "2020-10-19 11:59:07,665:INFO: GPU memory: 22702.0\n",
      "2020-10-19 11:59:07,666:INFO: batch size 32 successful.\n",
      "2020-10-19 11:59:07,667:INFO: GPU memory: 2118.0\n",
      "2020-10-19 11:59:08,085:INFO: x shape = torch.Size([64, 512]), yhat.shape = torch.Size([64, 512, 30522])\n",
      "2020-10-19 11:59:08,086:INFO: GPU memory: 43286.0\n",
      "2020-10-19 11:59:08,087:INFO: batch size 64 successful.\n",
      "2020-10-19 11:59:08,090:INFO: GPU memory: 2118.0\n",
      "exception <class 'RuntimeError'> : CUDA out of memory. Tried to allocate 1.50 GiB (GPU 0; 47.46 GiB total capacity; 45.39 GiB already allocated; 747.00 MiB free; 45.82 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpu_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-55ffa89eb38e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mgpu_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheck_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpu_model' is not defined"
     ]
    }
   ],
   "source": [
    "del gpu_model\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 12:00:07,219:INFO: GPU memory: 2118.0\n"
     ]
    }
   ],
   "source": [
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 12:00:11,821:INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "2020-10-19 12:00:11,823:INFO: Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-19 12:00:11,901:INFO: loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at /.cache/torch/transformers/73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "2020-10-19 12:00:20,885:INFO: All model checkpoint weights were used when initializing BertForPreTraining.\n",
      "\n",
      "2020-10-19 12:00:20,887:WARNING: Some weights of BertForPreTraining were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2020-10-19 12:00:20,891:INFO: GPU memory: 2118.0\n",
      "2020-10-19 12:00:21,365:INFO: GPU memory: 3402.0\n"
     ]
    }
   ],
   "source": [
    "model = BertForPreTraining.from_pretrained('bert-large-uncased')\n",
    "check_memory()\n",
    "gpu_model = model.to(device)\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 12:00:25,867:INFO: GPU memory: 3402.0\n",
      "2020-10-19 12:00:25,942:INFO: x shape = torch.Size([4, 512]), yhat.shape = torch.Size([4, 512, 30522])\n",
      "2020-10-19 12:00:25,943:INFO: GPU memory: 9825.0\n",
      "2020-10-19 12:00:25,945:INFO: batch size 4 successful.\n",
      "2020-10-19 12:00:25,947:INFO: GPU memory: 3402.0\n",
      "2020-10-19 12:00:26,079:INFO: x shape = torch.Size([8, 512]), yhat.shape = torch.Size([8, 512, 30522])\n",
      "2020-10-19 12:00:26,080:INFO: GPU memory: 16248.0\n",
      "2020-10-19 12:00:26,081:INFO: batch size 8 successful.\n",
      "2020-10-19 12:00:26,082:INFO: GPU memory: 3402.0\n",
      "2020-10-19 12:00:26,392:INFO: x shape = torch.Size([16, 512]), yhat.shape = torch.Size([16, 512, 30522])\n",
      "2020-10-19 12:00:26,393:INFO: GPU memory: 29095.0\n",
      "2020-10-19 12:00:26,395:INFO: batch size 16 successful.\n",
      "2020-10-19 12:00:26,396:INFO: GPU memory: 3402.0\n",
      "exception <class 'RuntimeError'> : CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 47.46 GiB total capacity; 46.27 GiB already allocated; 155.00 MiB free; 46.40 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "run_max_batch_analysis(gpu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ReformerForQuestionAnswering\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import LongformerForQuestionAnswering\n",
    "from transformers import RobertaForQuestionAnswering\n",
    "from transformers import XLMRobertaForQuestionAnswering\n",
    "from transformers import TransfoXLPreTrainedModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
