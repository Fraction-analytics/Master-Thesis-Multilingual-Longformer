{"n_gpu": 1, "model_name_or_path": "xlm-roberta-base", "max_len": 512, "output_dir": "./models", "overwrite_output_dir": true, "per_device_train_batch_size": 1, "per_device_eval_batch_size": 1, "train_batch_size": 1, "gradient_accumulation_steps": 4, "learning_rate": 0.0001, "num_train_epochs": 3, "do_train": true, "do_eval": true, "max_steps": 100, "logging_steps": 50, "eval_steps": 50, "prediction_loss_only": true, "seed": 42, "max_seq_length": 384, "doc_stride": 128, "evaluate_during_training": true, "fp16": true, "do_lower_case": true}